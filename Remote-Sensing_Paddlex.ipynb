{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 飞浆常规赛：遥感影像地块分割 - 12月第9名方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 比赛链接： [常规赛：遥感影像地块分割](https://aistudio.baidu.com/aistudio/competition/detail/63)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 赛题说明\n",
    "### 赛题介绍\n",
    "本赛题由 2020 CCF BDCI 遥感影像地块分割 初赛赛题改编而来。遥感影像地块分割, 旨在对遥感影像进行像素级内容解析，对遥感影像中感兴趣的类别进行提取和分类，在城乡规划、防汛救灾等领域具有很高的实用价值，在工业界也受到了广泛关注。现有的遥感影像地块分割数据处理方法局限于特定的场景和特定的数据来源，且精度无法满足需求。因此在实际应用中，仍然大量依赖于人工处理，需要消耗大量的人力、物力、财力。本赛题旨在衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果，利用人工智能技术，对多来源、多场景的异构遥感影像数据进行充分挖掘，打造高效、实用的算法，提高遥感影像的分析提取能力。\n",
    "赛题任务\n",
    "本赛题旨在对遥感影像进行像素级内容解析，并对遥感影像中感兴趣的类别进行提取和分类，以衡量遥感影像地块分割模型在多个类别（如建筑、道路、林地等）上的效果。\n",
    "\n",
    "### 数据说明\n",
    "本赛题提供了多个地区已脱敏的遥感影像数据，各参赛选手可以基于这些数据构建自己的地块分割模型。\n",
    "\n",
    "### 训练数据集\n",
    "样例图片及其标注如下图所示：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/8087a965609d48a19a5e60f0330fa9054d04097644de48ffa3d557e7a8ad64ad)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d18664ecf0514cb686c95958d30bbf8a2f5efb0691bc4d66a5f6317ab511d6d0)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e42f2c222f204094ac3a0ea8582ca331b0452fb2b1704eabaae379d499906977)\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/d5260bd5a820486a85aeb2105adfb6fa10284bd94453459f892755bc43e10b8a)\n",
    "\n",
    "\n",
    "训练数据集文件名称：train_and_label.zip\n",
    "\n",
    "包含2个子文件，分别为：训练数据集（原始图片）文件、训练数据集（标注图片）文件，详细介绍如下：\n",
    "\n",
    "* **训练数据集**（原始图片）文件名称：img_train\n",
    "\n",
    "\t包含66,653张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，每张图片的名称形如T000123.jpg。\n",
    "* **训练数据集**（标注图片）文件名称：lab_train\n",
    "\n",
    "\t包含66,653张分辨率为2m/pixel，尺寸为256 * 256的PNG图片，每张图片的名称形如T000123.png。\n",
    "* **备注**： 全部PNG图片共包括4种分类，像素值分别为0、1、2、3。此外，像素值255为未标注区域，表示对应区域的所属类别并不确定，在评测中也不会考虑这部分区域。\n",
    "\n",
    "### 测试数据集\n",
    "测试数据集文件名称：img_test.zip，详细介绍如下：\n",
    "\n",
    "包含4,609张分辨率为2m/pixel，尺寸为256 * 256的JPG图片，文件名称形如123.jpg。、\n",
    "### 数据增强工具\n",
    "PaTTA：由第三方开发者组织AgentMaker维护的Test-Time Augmentation库，可在测试时通过数据增强方式产生额外的推理结果，在此基础上进行投票即可获得更稳定的成绩表现。 https://github.com/AgentMaker/PaTTA\n",
    "\n",
    "RIFLE：由第三方开发者对ICML 2020中的《RIFLE: Backpropagation in Depth for Deep Transfer Learning through Re-Initializing the Fully-connected LayEr》论文所提供的封装版本，其通过对输出层多次重新初始化来使得深层backbone得到更充分的更新。 https://github.com/GT-ZhangAcer/RIFLE_Module\n",
    "\n",
    "### 提交内容及格式\n",
    "* 以zip压缩包形式提交结果文件，文件命名为 result.zip；\n",
    "* zip压缩包中的图片格式必须为单通道PNG；\n",
    "* PNG文件数需要与测试数据集中的文件数相同，且zip压缩包文件名需要与测试数据集中的文件名一一对应；\n",
    "* 单通道PNG图片中的像素值必须介于0~3之间，像素值不能为255。如果存在未标注区域，评测系统会自动忽略对应区域的提交结果。\n",
    "### 提交示例\n",
    "提交文件命名为：result.zip，zip文件的组织方式如下所示：\n",
    "\n",
    "```\n",
    "主目录                                                                        \n",
    "├── 1.png         #每个结果文件命名为：测试数据集图片名称+.png                      \n",
    "├── 2.png                                                              \n",
    "├── 3.png                                                    \n",
    "├── ...     \n",
    "```                                                \n",
    "    \n",
    "**备注**： 主目录中必须包含与测试数据集相同数目、名称相对应的单通道PNG图片，且每张单通道PNG图片中的像素值必须介于0~3之间，像素值不能为255。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 一、环境安装\n",
    "## 1.1 安装Paddlex及相关环境\n",
    "* 注意numpy和paddlex的版本兼容问题，应选择合适的版本进行安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Collecting numpy<=1.19.5\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/08/d6/a6aaa29fea945bc6c61d11f6e0697b325ff7446de5ffd62c2fa02f627048/numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8MB)\n",
      "\u001b[K     |████████████████████████████████| 14.8MB 5.9MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "Successfully installed numpy-1.19.5\n",
      "Looking in indexes: https://mirror.baidu.com/pypi/simple\n",
      "Collecting paddlex<2.0.0\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d6/a2/07435f4aa1e51fe22bdf06c95d03bf1b78b7bc6625adbb51e35dc0804cc7/paddlex-1.3.11-py3-none-any.whl (516kB)\n",
      "\u001b[K     |████████████████████████████████| 522kB 4.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: visualdl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (2.2.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (0.4.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (4.36.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (5.7.2)\n",
      "Collecting xlwt (from paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 14.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting paddlehub==2.1.0 (from paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/7a/29/3bd0ca43c787181e9c22fe44b944b64d7fcb14ce66d3bf4602d9ad2ac76c/paddlehub-2.1.0-py3-none-any.whl (211kB)\n",
      "\u001b[K     |████████████████████████████████| 215kB 28.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (4.1.1.26)\n",
      "Requirement already satisfied: sklearn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (5.1.2)\n",
      "Requirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex<2.0.0) (3.0.8)\n",
      "Collecting pycocotools; platform_system != \"Windows\" (from paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/2e/1c/4fd663fc57be418cecf6f89d0d141ffa815d0fd6538ccddeccf767e8aace/pycocotools-2.0.3.tar.gz (106kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 11.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shapely>=1.7.0 (from paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/ae/20/33ce377bd24d122a4d54e22ae2c445b9b1be8240edb50040b40add950cd9/Shapely-1.8.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 14.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting paddleslim==1.1.1 (from paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/d1/77/e257227bed9a70ff0d35a4a3c4e70ac2d2362c803834c4c52018f7c4b762/paddleslim-1.1.1-py2.py3-none-any.whl (145kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 46.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.15.0)\n",
      "Requirement already satisfied: flake8>=3.7.9 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (3.8.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (2.2.3)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.1.1)\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (7.1.2)\n",
      "Requirement already satisfied: shellcheck-py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (0.7.1.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.1.5)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.0.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (0.8.53)\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.19.5)\n",
      "Requirement already satisfied: pre-commit in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (1.21.0)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (3.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.0.0->paddlex<2.0.0) (2.22.0)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (18.1.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (3.0.12)\n",
      "Requirement already satisfied: easydict in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (1.9)\n",
      "Requirement already satisfied: rarfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (3.1)\n",
      "Requirement already satisfied: paddlenlp>=2.0.0rc5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (2.0.7)\n",
      "Requirement already satisfied: gunicorn>=19.10.0; sys_platform != \"win32\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (20.0.4)\n",
      "Requirement already satisfied: gitpython in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (3.1.14)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (20.9)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlehub==2.1.0->paddlex<2.0.0) (4.1.0)\n",
      "Collecting paddle2onnx>=0.5.1 (from paddlehub==2.1.0->paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/db/72/69812b9f56028f6ce46cf4d11540d40d75474b3ac861fcbf439b92877add/paddle2onnx-0.9.0-py3-none-any.whl (84kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 10.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from sklearn->paddlex<2.0.0) (0.24.2)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pycocotools; platform_system != \"Windows\"->paddlex<2.0.0) (56.2.0)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pycocotools; platform_system != \"Windows\"->paddlex<2.0.0) (0.29)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (0.23)\n",
      "Requirement already satisfied: pycodestyle<2.7.0,>=2.6.0a1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (2.6.0)\n",
      "Requirement already satisfied: pyflakes<2.3.0,>=2.2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (2.2.0)\n",
      "Requirement already satisfied: mccabe<0.7.0,>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (0.6.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddlex<2.0.0) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddlex<2.0.0) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddlex<2.0.0) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddlex<2.0.0) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl>=2.0.0->paddlex<2.0.0) (0.10.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddlex<2.0.0) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddlex<2.0.0) (2.11.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddlex<2.0.0) (0.16.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.0.0->paddlex<2.0.0) (1.1.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.0.0->paddlex<2.0.0) (2.8.0)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex<2.0.0) (0.18.0)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.0.0->paddlex<2.0.0) (3.9.9)\n",
      "Requirement already satisfied: aspy.yaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (1.3.0)\n",
      "Requirement already satisfied: virtualenv>=15.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (16.7.9)\n",
      "Requirement already satisfied: identify>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (1.4.10)\n",
      "Requirement already satisfied: nodeenv>=0.11.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (1.3.4)\n",
      "Requirement already satisfied: toml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (0.10.0)\n",
      "Requirement already satisfied: cfgv>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pre-commit->visualdl>=2.0.0->paddlex<2.0.0) (2.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (1.25.6)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.0.0->paddlex<2.0.0) (3.0.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (0.70.11.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (2.9.0)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (0.42.1)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (1.2.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitpython->paddlehub==2.1.0->paddlex<2.0.0) (4.0.5)\n",
      "Collecting onnx<=1.9.0 (from paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex<2.0.0)\n",
      "\u001b[?25l  Downloading https://mirror.baidu.com/pypi/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2MB 10.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlex<2.0.0) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlex<2.0.0) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn->sklearn->paddlex<2.0.0) (2.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->flake8>=3.7.9->visualdl>=2.0.0->paddlex<2.0.0) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.0.0->paddlex<2.0.0) (1.1.1)\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->paddlenlp>=2.0.0rc5->paddlehub==2.1.0->paddlex<2.0.0) (0.3.3)\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython->paddlehub==2.1.0->paddlex<2.0.0) (3.0.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from onnx<=1.9.0->paddle2onnx>=0.5.1->paddlehub==2.1.0->paddlex<2.0.0) (3.10.0.2)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.3-cp37-cp37m-linux_x86_64.whl size=273732 sha256=17ec9aefbf28365e4a19560dbbd4a8dd26c7e7aef08439dd43ff5e379832baca\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/9e/91/9a/477bc4f11f7c3401f57d769e611d474ba93f81841ee92007e7\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: xlwt, onnx, paddle2onnx, paddlehub, pycocotools, shapely, paddleslim, paddlex\n",
      "  Found existing installation: paddlehub 2.0.4\n",
      "    Uninstalling paddlehub-2.0.4:\n",
      "      Successfully uninstalled paddlehub-2.0.4\n",
      "Successfully installed onnx-1.9.0 paddle2onnx-0.9.0 paddlehub-2.1.0 paddleslim-1.1.1 paddlex-1.3.11 pycocotools-2.0.3 shapely-1.8.0 xlwt-1.3.0\n"
     ]
    }
   ],
   "source": [
    "# 安装paddlex\r\n",
    "# 需要注意paddlex1对于版本有所要求，所以最好更新对应的包版本\r\n",
    "!pip install \"numpy<=1.19.5\" -i https://mirror.baidu.com/pypi/simple\r\n",
    "!pip install \"paddlex<2.0.0\" -i https://mirror.baidu.com/pypi/simple\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting imgaug\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/66/b1/af3142c4a85cba6da9f4ebb5ff4e21e2616309552caca5e8acefe9840622/imgaug-0.4.0-py2.py3-none-any.whl (948kB)\n",
      "\u001b[K     |████████████████████████████████| 952kB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (7.1.2)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (4.1.1.26)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.15.0)\n",
      "Requirement already satisfied: imageio in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.6.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.6.3)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (2.2.3)\n",
      "Requirement already satisfied: Shapely in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.8.0)\n",
      "Collecting scikit-image>=0.14.2 (from imgaug)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/9a/44/8f8c7f9c9de7fde70587a656d7df7d056e6f05192a74491f7bc074a724d0/scikit_image-0.19.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.3MB)\n",
      "\u001b[K     |████████████████████████████████| 13.3MB 26.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from imgaug) (1.19.5)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2019.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->imgaug) (0.10.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (2.4)\n",
      "Collecting tifffile>=2019.7.26 (from scikit-image>=0.14.2->imgaug)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d8/38/85ae5ed77598ca90558c17a2f79ddaba33173b31cf8d8f545d34d9134f0d/tifffile-2021.11.2-py3-none-any.whl (178kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 10.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image>=0.14.2->imgaug)\n",
      "\u001b[?25l  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a1/9c/564511b6e1c4e1d835ed2d146670436036960d09339a8fa2921fe42dad08/PyWavelets-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (6.1MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2MB 10.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-image>=0.14.2->imgaug) (20.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->imgaug) (56.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from networkx>=2.2->scikit-image>=0.14.2->imgaug) (4.4.2)\n",
      "Installing collected packages: tifffile, PyWavelets, scikit-image, imgaug\n",
      "Successfully installed PyWavelets-1.2.0 imgaug-0.4.0 scikit-image-0.19.1 tifffile-2021.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install imgaug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 设置使用0号GPU卡（如无GPU，执行此代码后仍然会使用CPU训练模型）\r\n",
    "import matplotlib\r\n",
    "import os\r\n",
    "import paddlex as pdx\r\n",
    "\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 二、数据处理\n",
    "## 2.1 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -q data/data80164/train_and_label.zip\r\n",
    "!unzip -q data/data80164/img_test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.2 数据增广\n",
    "项目使用**PaddleX**进行数据处理和训练，详情请查看**PaddleX**的[API说明文档](https://paddlex.readthedocs.io/zh_CN/develop/apis/index.html)\n",
    "\n",
    "对用于分割任务的数据进行操作。可以利用[paddlex.seg.transforms](https://paddlex.readthedocs.io/zh_CN/develop/apis/transforms/seg_transforms.html#paddlex-seg-transforms)中的Compose类将图像预处理/增强操作进行组合。\n",
    "\n",
    "* **RandomHorizontalFlip** 以一定的概率对图像进行水平翻转。\n",
    "* **Resize** 调整图像大小，本项目的插值方式选用 **“RANDOM”**，随机选取一种插值方式进行resize，作为模型训练时的数据增强操作。\n",
    "* **RandomPaddingCrop** 对图像和标注图进行随机裁剪，当所需要的裁剪尺寸大于原图时，则进行padding操作，模型训练时的数据增强操作。\n",
    "* **RandomBlur** 以一定的概率对图像进行高斯模糊。\n",
    "* **RandomRotate** 对图像进行随机旋转，模型训练时的数据增强操作。目前支持多通道的RGB图像，例如支持多张RGB图像沿通道轴做concatenate后的图像数据，不支持通道数量不是3的倍数的图像数据。\n",
    "* **Normalize** 对图像进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlex.seg import transforms\r\n",
    "import imgaug.augmenters as iaa\r\n",
    "\r\n",
    "# 定义训练和验证时的transforms\r\n",
    "train_transforms = transforms.Compose([\r\n",
    "    transforms.RandomHorizontalFlip(),\r\n",
    "    transforms.Resize(target_size=300, interp='RANDOM'),\r\n",
    "    transforms.RandomPaddingCrop(crop_size=256),\r\n",
    "    transforms.RandomBlur(prob=0.1),\r\n",
    "    transforms.RandomRotate(rotate_range=15),\r\n",
    "    # transforms.RandomDistort(brightness_range=0.5),\r\n",
    "    transforms.Normalize()\r\n",
    "])\r\n",
    "eval_transforms = transforms.Compose([\r\n",
    "    transforms.Resize(256),\r\n",
    "    transforms.Normalize()\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.3 数据准备\n",
    "* 训练前的一些准备\n",
    "* 将训练集的图像集和标签路径写入datas中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 66652\n",
      "img_train/T059538.jpg\n",
      "lab_train/T059538.png\n",
      "('img_train/T054539.jpg', 'lab_train/T054539.png')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "datas = []\r\n",
    "image_base = 'img_train'   # 训练集原图路径\r\n",
    "annos_base = 'lab_train'   # 训练集标签路径\r\n",
    "\r\n",
    "# 读取原图文件名\r\n",
    "ids_ = [v.split('.')[0] for v in os.listdir(image_base)]\r\n",
    "\r\n",
    "# 将训练集的图像集和标签路径写入datas中\r\n",
    "for id_ in ids_:\r\n",
    "    img_pt0 = os.path.join(image_base, '{}.jpg'.format(id_))\r\n",
    "    img_pt1 = os.path.join(annos_base, '{}.png'.format(id_))\r\n",
    "    datas.append((img_pt0.replace('/home/aistudio', ''), img_pt1.replace('/home/aistudio', '')))\r\n",
    "    if os.path.exists(img_pt0) and os.path.exists(img_pt1):\r\n",
    "        pass\r\n",
    "    else:\r\n",
    "        raise \"path invalid!\"\r\n",
    "\r\n",
    "# 打印datas的长度和具体存储例子\r\n",
    "print('total:', len(datas))\r\n",
    "print(datas[0][0])\r\n",
    "print(datas[0][1])\r\n",
    "print(datas[10][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2.4 划分数据集\n",
    "* 以0.05的比率划分训练集和验证集，其中95%作为训练集，5%作为验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 63320\n",
      "valid: 3332\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "# 四类标签，这里用处不大，比赛评测是以0、1、2、3类来对比评测的\r\n",
    "labels = ['建筑', '耕地', '林地',  '其他']\r\n",
    "\r\n",
    "# 将labels写入标签文件\r\n",
    "with open('labels.txt', 'w') as f:\r\n",
    "    for v in labels:\r\n",
    "        f.write(v+'\\n')\r\n",
    "\r\n",
    "# 随机打乱datas\r\n",
    "np.random.seed(5)\r\n",
    "np.random.shuffle(datas)\r\n",
    "\r\n",
    "# 验证集与训练集的划分，0.05表示5%为验证集，95%为训练集\r\n",
    "split_num = int(0.05*len(datas))\r\n",
    "\r\n",
    "# 划分训练集和验证集\r\n",
    "train_data = datas[:-split_num]\r\n",
    "valid_data = datas[-split_num:]\r\n",
    "\r\n",
    "# 写入训练集list\r\n",
    "with open('train_list.txt', 'w') as f:\r\n",
    "    for img, lbl in train_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 写入验证集list\r\n",
    "with open('valid_list.txt', 'w') as f:\r\n",
    "    for img, lbl in valid_data:\r\n",
    "        f.write(img + ' ' + lbl + '\\n')\r\n",
    "\r\n",
    "# 打印训练集和测试集大小\r\n",
    "print('train:', len(train_data))\r\n",
    "print('valid:', len(valid_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "读取语义分割任务数据集，可使用[paddlex.datasets.SegDataset](https://paddlex.readthedocs.io/zh_CN/develop/apis/datasets.html#paddlex-datasets-segdataset)\n",
    "\n",
    "**paddlex.datasets.SegDataset**参数说明：\n",
    "* **data_dir (str)**: 数据集所在的目录路径。\n",
    "* **file_list (str)**: 描述数据集图片文件和对应标注文件的文件路径（文本内每行路径为相对data_dir的相对路径）。\n",
    "* **label_list (str)**: 描述数据集包含的类别信息文件路径。\n",
    "* **transforms (paddlex.seg.transforms)**: 数据集中每个样本的预处理/增强算子，详见[paddlex.seg.transforms](https://paddlex.readthedocs.io/zh_CN/develop/apis/transforms/seg_transforms.html#paddlex-seg-transforms)。\n",
    "* **num_workers (int|str)**：数据集中样本在预处理过程中的线程或进程数。默认为’auto’。当设为’auto’时，根据系统的实际CPU核数设置num_workers: 如果CPU核数的一半大于8，则num_workers为8，否则为CPU核数的一半。\n",
    "* **buffer_size (int)**: 数据集中样本在预处理过程中队列的缓存长度，以样本数为单位。默认为100。\n",
    "* **parallel_method (str)**: 数据集中样本在预处理过程中并行处理的方式，支持’thread’线程和’process’进程两种方式。默认为’process’（Windows和Mac下会强制使用thread，该参数无效）。\n",
    "* **shuffle (bool)**: 是否需要对数据集中样本打乱顺序。默认为False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 01:28:03 [INFO]\t63320 samples in file train_list.txt\n",
      "2021-12-24 01:28:03 [INFO]\t3332 samples in file valid_list.txt\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\r\n",
    "\r\n",
    "# 定义训练和验证数据集\r\n",
    "train_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,                # 数据集路径\r\n",
    "    file_list='train_list.txt',       # 训练集图片文件list路径\r\n",
    "    label_list='labels.txt',          # 训练集标签文件list路径\r\n",
    "    transforms=train_transforms,      # train_transforms\r\n",
    "    shuffle=True)                     # 数据集是否打乱\r\n",
    "    \r\n",
    "eval_dataset = pdx.datasets.SegDataset(\r\n",
    "    data_dir=data_dir,                # 数据集路径\r\n",
    "    file_list='valid_list.txt',       # 验证集图片文件list路径\r\n",
    "    label_list='labels.txt',          # 验证集标签文件list路径\r\n",
    "    transforms=eval_transforms)       # eval_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 三、模型训练、评估及预测\n",
    "\n",
    "利用[paddlex.seg.DeepLabv3p](https://paddlex.readthedocs.io/zh_CN/develop/apis/models/semantic_segmentation.html)构建DeepLabv3p分割器。\n",
    "\n",
    "**paddlex.seg.DeepLabv3p**参数说明：\n",
    "* num_classes (int): 类别数。\n",
    "* backbone (str): DeepLabv3+的backbone网络，实现特征图的计算，取值范围为[’Xception65’, ‘Xception41’, ‘MobileNetV2_x0.25’, ‘MobileNetV2_x0.5’, ‘MobileNetV2_x1.0’, ‘MobileNetV2_x1.5’, ‘MobileNetV2_x2.0’, ‘MobileNetV3_large_x1_0_ssld’]，默认值为’MobileNetV2_x1.0’。\n",
    "* output_stride (int): backbone 输出特征图相对于输入的下采样倍数，一般取值为8或16。默认16。\n",
    "* aspp_with_sep_conv (bool): aspp模块是否采用separable convolutions。默认True。\n",
    "* decoder_use_sep_conv (bool)： decoder模块是否采用separable convolutions。默认True。\n",
    "* encoder_with_aspp (bool): 是否在encoder阶段采用aspp模块。默认True。\n",
    "* enable_decoder (bool): 是否使用decoder模块。默认True。\n",
    "* use_bce_loss (bool): 是否使用bce loss作为网络的损失函数，只能用于两类分割。可与dice loss同时使用。默认False。\n",
    "* use_dice_loss (bool): 是否使用dice loss作为网络的损失函数，只能用于两类分割，可与bce loss同时使用，当use_bce_loss和use_dice_loss都为False时，使用交叉熵损失函数。默认False。\n",
    "* class_weight (list/str): 交叉熵损失函数各类损失的权重。当class_weight为list的时候，长度应为num_classes。当class_weight为str时， weight.lower()应为’dynamic’，这时会根据每一轮各类像素的比重自行计算相应的权重，每一类的权重为：每类的比例 * num_classes。class_weight取默认值None是，各类的权重1，即平时使用的交叉熵损失函数。\n",
    "* ignore_index (int): label上忽略的值，label为ignore_index的像素不参与损失函数的计算。默认255。\n",
    "* pooling_crop_size (int)：当backbone为MobileNetV3_large_x1_0_ssld时，需设置为训练过程中模型输入大小，格式为[W, H]。例如模型输入大小为[512, 512], 则pooling_crop_size应该设置为[512, 512]。在encoder模块中获取图像平均值时被用到，若为None，则直接求平均值；若为模型输入大小，则使用avg_pool算子得到平均值。默认值None。\n",
    "* input_channel (int): 输入图像通道数。默认值3。\n",
    "\n",
    "**DeepLabv3p**模型的训练接口，函数内置了**polynomial**学习率衰减策略和**momentum**优化器。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**train**参数说明：\n",
    "* **num_epochs (int)**: 训练迭代轮数。\n",
    "* **train_dataset (paddlex.datasets)**: 训练数据读取器。\n",
    "* **train_batch_size (int)**: 训练数据batch大小。同时作为验证数据batch大小。默认2。\n",
    "* **eval_dataset (paddlex.datasets)**: 评估数据读取器。\n",
    "* **save_interval_epochs (int)**: 模型保存间隔（单位：迭代轮数）。默认为1。\n",
    "* **log_interval_steps (int)**: 训练日志输出间隔（单位：迭代次数）。默认为2。\n",
    "* **save_dir (str)**: 模型保存路径。默认’output’\n",
    "* **pretrain_weights (str)**: 若指定为路径时，则加载路径下预训练模型；若为字符串’IMAGENET’，则自动下载在ImageNet图片数据上预训练的模型权重；若为字符串’COCO’，则自动下载在COCO数据集上预训练的模型权重（注意：暂未提供Xception41、MobileNetV2_x0.25、MobileNetV2_x0.5、MobileNetV2_x1.5、MobileNetV2_x2.0的COCO预训练模型）；若为字符串’CITYSCAPES’，则自动下载在CITYSCAPES数据集上预训练的模型权重（注意：暂未提供Xception41、MobileNetV2_x0.25、MobileNetV2_x0.5、MobileNetV2_x1.5、MobileNetV2_x2.0的CITYSCAPES预训练模型）；若为None，则不使用预训练模型。默认’IMAGENET’。\n",
    "* **optimizer (paddle.fluid.optimizer)**: 优化器。当该参数为None时，使用默认的优化器：使用fluid.optimizer.Momentum优化方法，polynomial的学习率衰减策略。\n",
    "* **learning_rate (float)**: 默认优化器的初始学习率。默认0.01。\n",
    "* **lr_decay_power (float)**: 默认优化器学习率衰减指数。默认0.9。\n",
    "* **use_vdl (bool)**: 是否使用VisualDL进行可视化。默认False。\n",
    "* **sensitivities_file (str)**: 若指定为路径时，则加载路径下敏感度信息进行裁剪；若为字符串’DEFAULT’，则自动下载在Cityscapes图片数据上获得的敏感度信息进行裁剪；若为None，则不进行裁剪。默认为None。\n",
    "* **eval_metric_loss (float)**: 可容忍的精度损失。默认为0.05。\n",
    "* **early_stop (bool)**: 是否使用提前终止训练策略。默认值为False。\n",
    "* **early_stop_patience (int)**: 当使用提前终止训练策略时，如果验证集精度在early_stop_patience个epoch内连续下降或持平，则终止训练。默认值为5。\n",
    "* **resume_checkpoint (str)**: 恢复训练时指定上次训练保存的模型路径。若为None，则不会恢复训练。默认值为None。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.1 模型训练\n",
    "* 本方案训练使用学习率为0.0001，训练轮数为35轮（Epoch1到Epoch35）\n",
    "* 根据GPU显存设定训练时批处理图片数为8，太大容易爆显存\n",
    "* 模型保存在output/deeplab文件下，设定为每进行一轮保存一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/xception.py:316\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:298: UserWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddlex/cv/nets/segmentation/model_utils/loss.py:74\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  op_type, op_type, EXPRESSION_MAP[method_name]))\n",
      "2021-12-24 01:28:28,246 - INFO - If regularizer of a Parameter has been set by 'fluid.ParamAttr' or 'fluid.WeightNormParamAttr' already. The Regularization[L2Decay, regularization_coeff=0.000040] in Optimizer will not take effect, and it will only be applied to other Parameters!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 01:28:32 [WARNING]\tPath of pretrain_weights('output/deeplab/best_model') is not exists!\n",
      "2021-12-24 01:28:32 [WARNING]\tPretrain_weights will be forced to set as 'IMAGENET', if you don't want to use pretrain weights, set pretrain_weights=None.\n",
      "2021-12-24 01:28:32 [INFO]\tDownloading Xception65_deeplab_pretrained.tar from https://paddle-imagenet-models-name.bj.bcebos.com/Xception65_deeplab_pretrained.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157790/157790 [00:04<00:00, 36617.67KB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 01:28:36 [INFO]\tDecompressing output/deeplab/pretrain/Xception65_deeplab_pretrained.tar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1224 01:28:37.310618   102 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1224 01:28:37.315716   102 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 01:28:42 [INFO]\tLoad pretrain weights from output/deeplab/pretrain/Xception65_deeplab_pretrained.\n",
      "2021-12-24 01:28:43 [INFO]\tThere are 660 varaibles in output/deeplab/pretrain/Xception65_deeplab_pretrained are loaded.\n",
      "2021-12-24 01:29:21 [INFO]\t[TRAIN] Epoch=1/35, Step=200/7915, loss=1.405337, lr=0.0001, time_each_step=0.16s, eta=13:21:10\n",
      "2021-12-24 01:29:54 [INFO]\t[TRAIN] Epoch=1/35, Step=400/7915, loss=1.293303, lr=0.0001, time_each_step=0.16s, eta=12:55:25\n",
      "2021-12-24 01:30:26 [INFO]\t[TRAIN] Epoch=1/35, Step=600/7915, loss=1.38135, lr=0.0001, time_each_step=0.16s, eta=13:9:45\n",
      "2021-12-24 01:30:59 [INFO]\t[TRAIN] Epoch=1/35, Step=800/7915, loss=1.322818, lr=0.0001, time_each_step=0.16s, eta=13:8:23\n",
      "2021-12-24 01:31:32 [INFO]\t[TRAIN] Epoch=1/35, Step=1000/7915, loss=0.779293, lr=0.0001, time_each_step=0.16s, eta=13:7:21\n",
      "2021-12-24 01:32:05 [INFO]\t[TRAIN] Epoch=1/35, Step=1200/7915, loss=1.242281, lr=0.0001, time_each_step=0.16s, eta=13:8:5\n",
      "2021-12-24 01:32:38 [INFO]\t[TRAIN] Epoch=1/35, Step=1400/7915, loss=0.82195, lr=0.0001, time_each_step=0.17s, eta=13:20:9\n",
      "2021-12-24 01:33:11 [INFO]\t[TRAIN] Epoch=1/35, Step=1600/7915, loss=1.443307, lr=9.9e-05, time_each_step=0.17s, eta=13:19:24\n",
      "2021-12-24 01:33:44 [INFO]\t[TRAIN] Epoch=1/35, Step=1800/7915, loss=0.687394, lr=9.9e-05, time_each_step=0.17s, eta=13:20:32\n",
      "2021-12-24 01:34:17 [INFO]\t[TRAIN] Epoch=1/35, Step=2000/7915, loss=1.550979, lr=9.9e-05, time_each_step=0.17s, eta=13:19:45\n",
      "2021-12-24 01:34:50 [INFO]\t[TRAIN] Epoch=1/35, Step=2200/7915, loss=1.057619, lr=9.9e-05, time_each_step=0.16s, eta=13:8:22\n",
      "2021-12-24 01:35:23 [INFO]\t[TRAIN] Epoch=1/35, Step=2400/7915, loss=1.011665, lr=9.9e-05, time_each_step=0.17s, eta=13:22:2\n",
      "2021-12-24 01:35:56 [INFO]\t[TRAIN] Epoch=1/35, Step=2600/7915, loss=1.258654, lr=9.9e-05, time_each_step=0.17s, eta=13:17:39\n",
      "2021-12-24 01:36:29 [INFO]\t[TRAIN] Epoch=1/35, Step=2800/7915, loss=1.284914, lr=9.9e-05, time_each_step=0.16s, eta=12:52:14\n",
      "2021-12-24 01:37:02 [INFO]\t[TRAIN] Epoch=1/35, Step=3000/7915, loss=0.84004, lr=9.9e-05, time_each_step=0.17s, eta=13:18:35\n",
      "2021-12-24 01:37:35 [INFO]\t[TRAIN] Epoch=1/35, Step=3200/7915, loss=1.009039, lr=9.9e-05, time_each_step=0.17s, eta=13:16:43\n",
      "2021-12-24 01:38:08 [INFO]\t[TRAIN] Epoch=1/35, Step=3400/7915, loss=1.372284, lr=9.9e-05, time_each_step=0.17s, eta=13:17:55\n",
      "2021-12-24 01:38:41 [INFO]\t[TRAIN] Epoch=1/35, Step=3600/7915, loss=0.663452, lr=9.9e-05, time_each_step=0.16s, eta=13:3:27\n",
      "2021-12-24 01:39:14 [INFO]\t[TRAIN] Epoch=1/35, Step=3800/7915, loss=1.006877, lr=9.9e-05, time_each_step=0.17s, eta=13:12:52\n",
      "2021-12-24 01:39:47 [INFO]\t[TRAIN] Epoch=1/35, Step=4000/7915, loss=0.6643, lr=9.9e-05, time_each_step=0.17s, eta=13:15:46\n",
      "2021-12-24 01:40:19 [INFO]\t[TRAIN] Epoch=1/35, Step=4200/7915, loss=1.491832, lr=9.9e-05, time_each_step=0.16s, eta=13:2:28\n",
      "2021-12-24 01:40:53 [INFO]\t[TRAIN] Epoch=1/35, Step=4400/7915, loss=2.328695, lr=9.9e-05, time_each_step=0.16s, eta=13:6:48\n",
      "2021-12-24 01:41:26 [INFO]\t[TRAIN] Epoch=1/35, Step=4600/7915, loss=0.990378, lr=9.9e-05, time_each_step=0.16s, eta=12:54:33\n",
      "2021-12-24 01:41:59 [INFO]\t[TRAIN] Epoch=1/35, Step=4800/7915, loss=1.058473, lr=9.8e-05, time_each_step=0.17s, eta=13:26:23\n",
      "2021-12-24 01:42:32 [INFO]\t[TRAIN] Epoch=1/35, Step=5000/7915, loss=0.994401, lr=9.8e-05, time_each_step=0.17s, eta=13:13:30\n",
      "2021-12-24 01:43:05 [INFO]\t[TRAIN] Epoch=1/35, Step=5200/7915, loss=0.289653, lr=9.8e-05, time_each_step=0.16s, eta=12:59:40\n",
      "2021-12-24 01:43:38 [INFO]\t[TRAIN] Epoch=1/35, Step=5400/7915, loss=0.914976, lr=9.8e-05, time_each_step=0.16s, eta=12:56:3\n",
      "2021-12-24 01:44:11 [INFO]\t[TRAIN] Epoch=1/35, Step=5600/7915, loss=0.96909, lr=9.8e-05, time_each_step=0.17s, eta=13:12:55\n",
      "2021-12-24 01:44:44 [INFO]\t[TRAIN] Epoch=1/35, Step=5800/7915, loss=1.072846, lr=9.8e-05, time_each_step=0.17s, eta=13:11:58\n",
      "2021-12-24 01:45:17 [INFO]\t[TRAIN] Epoch=1/35, Step=6000/7915, loss=1.226084, lr=9.8e-05, time_each_step=0.16s, eta=12:58:40\n",
      "2021-12-24 01:45:49 [INFO]\t[TRAIN] Epoch=1/35, Step=6200/7915, loss=0.805379, lr=9.8e-05, time_each_step=0.17s, eta=13:11:41\n",
      "2021-12-24 01:46:23 [INFO]\t[TRAIN] Epoch=1/35, Step=6400/7915, loss=0.71672, lr=9.8e-05, time_each_step=0.16s, eta=13:3:59\n",
      "2021-12-24 01:46:56 [INFO]\t[TRAIN] Epoch=1/35, Step=6600/7915, loss=1.467104, lr=9.8e-05, time_each_step=0.16s, eta=12:55:26\n",
      "2021-12-24 01:47:28 [INFO]\t[TRAIN] Epoch=1/35, Step=6800/7915, loss=0.656269, lr=9.8e-05, time_each_step=0.16s, eta=12:50:27\n",
      "2021-12-24 01:48:01 [INFO]\t[TRAIN] Epoch=1/35, Step=7000/7915, loss=0.918976, lr=9.8e-05, time_each_step=0.16s, eta=13:0:59\n",
      "2021-12-24 01:48:35 [INFO]\t[TRAIN] Epoch=1/35, Step=7200/7915, loss=1.022555, lr=9.8e-05, time_each_step=0.16s, eta=12:52:51\n",
      "2021-12-24 01:49:07 [INFO]\t[TRAIN] Epoch=1/35, Step=7400/7915, loss=0.470571, lr=9.8e-05, time_each_step=0.17s, eta=13:4:48\n",
      "2021-12-24 01:49:41 [INFO]\t[TRAIN] Epoch=1/35, Step=7600/7915, loss=1.255861, lr=9.8e-05, time_each_step=0.17s, eta=13:7:5\n",
      "2021-12-24 01:50:14 [INFO]\t[TRAIN] Epoch=1/35, Step=7800/7915, loss=0.576888, lr=9.7e-05, time_each_step=0.17s, eta=13:2:58\n",
      "2021-12-24 01:50:32 [INFO]\t[TRAIN] Epoch 1 finished, loss=1.061368, lr=9.9e-05 .\n",
      "2021-12-24 01:50:32 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/417 [00:00<?, ?it/s]share_vars_from is set, scope is ignored.\n",
      "100%|██████████| 417/417 [00:23<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 01:50:56 [INFO]\t[EVAL] Finished, Epoch=1, miou=0.418961, category_iou=[0.44915711 0.65011153 0.3955535  0.18102042], oacc=0.631246, category_acc=[0.50693199 0.85079779 0.5685412  0.66202098], kappa=0.48297, category_F1-score=[0.61988739 0.78796071 0.56687687 0.30654918] .\n",
      "2021-12-24 01:51:00 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 01:51:03 [INFO]\tModel saved in output/deeplab/epoch_1.\n",
      "2021-12-24 01:51:03 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_1, miou=0.41896063820718243\n",
      "2021-12-24 01:51:20 [INFO]\t[TRAIN] Epoch=2/35, Step=85/7915, loss=2.275247, lr=9.7e-05, time_each_step=0.16s, eta=12:39:2\n",
      "2021-12-24 01:51:53 [INFO]\t[TRAIN] Epoch=2/35, Step=285/7915, loss=0.80898, lr=9.7e-05, time_each_step=0.16s, eta=12:38:34\n",
      "2021-12-24 01:52:26 [INFO]\t[TRAIN] Epoch=2/35, Step=485/7915, loss=1.053346, lr=9.7e-05, time_each_step=0.16s, eta=12:38:13\n",
      "2021-12-24 01:52:58 [INFO]\t[TRAIN] Epoch=2/35, Step=685/7915, loss=0.454218, lr=9.7e-05, time_each_step=0.16s, eta=12:37:34\n",
      "2021-12-24 01:53:31 [INFO]\t[TRAIN] Epoch=2/35, Step=885/7915, loss=0.905546, lr=9.7e-05, time_each_step=0.17s, eta=12:37:17\n",
      "2021-12-24 01:54:04 [INFO]\t[TRAIN] Epoch=2/35, Step=1085/7915, loss=1.012863, lr=9.7e-05, time_each_step=0.17s, eta=12:36:40\n",
      "2021-12-24 01:54:36 [INFO]\t[TRAIN] Epoch=2/35, Step=1285/7915, loss=0.879873, lr=9.7e-05, time_each_step=0.17s, eta=12:36:12\n",
      "2021-12-24 01:55:09 [INFO]\t[TRAIN] Epoch=2/35, Step=1485/7915, loss=1.093594, lr=9.7e-05, time_each_step=0.16s, eta=12:35:8\n",
      "2021-12-24 01:55:42 [INFO]\t[TRAIN] Epoch=2/35, Step=1685/7915, loss=0.994421, lr=9.7e-05, time_each_step=0.16s, eta=12:34:44\n",
      "2021-12-24 01:56:15 [INFO]\t[TRAIN] Epoch=2/35, Step=1885/7915, loss=0.850103, lr=9.7e-05, time_each_step=0.16s, eta=12:34:3\n",
      "2021-12-24 01:56:48 [INFO]\t[TRAIN] Epoch=2/35, Step=2085/7915, loss=0.628738, lr=9.7e-05, time_each_step=0.16s, eta=12:33:39\n",
      "2021-12-24 01:57:20 [INFO]\t[TRAIN] Epoch=2/35, Step=2285/7915, loss=0.984772, lr=9.7e-05, time_each_step=0.16s, eta=12:33:16\n",
      "2021-12-24 01:57:53 [INFO]\t[TRAIN] Epoch=2/35, Step=2485/7915, loss=1.075264, lr=9.7e-05, time_each_step=0.16s, eta=12:32:29\n",
      "2021-12-24 01:58:26 [INFO]\t[TRAIN] Epoch=2/35, Step=2685/7915, loss=0.792944, lr=9.7e-05, time_each_step=0.17s, eta=12:32:20\n",
      "2021-12-24 01:58:58 [INFO]\t[TRAIN] Epoch=2/35, Step=2885/7915, loss=1.056586, lr=9.6e-05, time_each_step=0.16s, eta=12:31:34\n",
      "2021-12-24 01:59:31 [INFO]\t[TRAIN] Epoch=2/35, Step=3085/7915, loss=0.725037, lr=9.6e-05, time_each_step=0.17s, eta=12:31:9\n",
      "2021-12-24 02:00:04 [INFO]\t[TRAIN] Epoch=2/35, Step=3285/7915, loss=1.049645, lr=9.6e-05, time_each_step=0.16s, eta=12:30:26\n",
      "2021-12-24 02:00:36 [INFO]\t[TRAIN] Epoch=2/35, Step=3485/7915, loss=1.197093, lr=9.6e-05, time_each_step=0.16s, eta=12:29:42\n",
      "2021-12-24 02:01:09 [INFO]\t[TRAIN] Epoch=2/35, Step=3685/7915, loss=1.114739, lr=9.6e-05, time_each_step=0.16s, eta=12:29:29\n",
      "2021-12-24 02:01:42 [INFO]\t[TRAIN] Epoch=2/35, Step=3885/7915, loss=0.963497, lr=9.6e-05, time_each_step=0.17s, eta=12:29:3\n",
      "2021-12-24 02:02:15 [INFO]\t[TRAIN] Epoch=2/35, Step=4085/7915, loss=1.03047, lr=9.6e-05, time_each_step=0.16s, eta=12:28:20\n",
      "2021-12-24 02:02:48 [INFO]\t[TRAIN] Epoch=2/35, Step=4285/7915, loss=1.176616, lr=9.6e-05, time_each_step=0.16s, eta=12:27:48\n",
      "2021-12-24 02:03:20 [INFO]\t[TRAIN] Epoch=2/35, Step=4485/7915, loss=0.681918, lr=9.6e-05, time_each_step=0.16s, eta=12:27:10\n",
      "2021-12-24 02:03:53 [INFO]\t[TRAIN] Epoch=2/35, Step=4685/7915, loss=0.456113, lr=9.6e-05, time_each_step=0.16s, eta=12:26:42\n",
      "2021-12-24 02:04:26 [INFO]\t[TRAIN] Epoch=2/35, Step=4885/7915, loss=1.041111, lr=9.6e-05, time_each_step=0.16s, eta=12:26:6\n",
      "2021-12-24 02:04:58 [INFO]\t[TRAIN] Epoch=2/35, Step=5085/7915, loss=1.040058, lr=9.6e-05, time_each_step=0.16s, eta=12:25:34\n",
      "2021-12-24 02:05:31 [INFO]\t[TRAIN] Epoch=2/35, Step=5285/7915, loss=1.159823, lr=9.6e-05, time_each_step=0.17s, eta=12:25:9\n",
      "2021-12-24 02:06:04 [INFO]\t[TRAIN] Epoch=2/35, Step=5485/7915, loss=0.820751, lr=9.6e-05, time_each_step=0.16s, eta=12:24:32\n",
      "2021-12-24 02:06:37 [INFO]\t[TRAIN] Epoch=2/35, Step=5685/7915, loss=1.832485, lr=9.6e-05, time_each_step=0.17s, eta=12:24:2\n",
      "2021-12-24 02:07:10 [INFO]\t[TRAIN] Epoch=2/35, Step=5885/7915, loss=0.504713, lr=9.6e-05, time_each_step=0.16s, eta=12:23:25\n",
      "2021-12-24 02:07:43 [INFO]\t[TRAIN] Epoch=2/35, Step=6085/7915, loss=1.28597, lr=9.5e-05, time_each_step=0.16s, eta=12:22:53\n",
      "2021-12-24 02:08:16 [INFO]\t[TRAIN] Epoch=2/35, Step=6285/7915, loss=1.093286, lr=9.5e-05, time_each_step=0.16s, eta=12:22:13\n",
      "2021-12-24 02:08:48 [INFO]\t[TRAIN] Epoch=2/35, Step=6485/7915, loss=0.765929, lr=9.5e-05, time_each_step=0.16s, eta=12:21:46\n",
      "2021-12-24 02:09:21 [INFO]\t[TRAIN] Epoch=2/35, Step=6685/7915, loss=1.211756, lr=9.5e-05, time_each_step=0.16s, eta=12:21:14\n",
      "2021-12-24 02:09:54 [INFO]\t[TRAIN] Epoch=2/35, Step=6885/7915, loss=0.827067, lr=9.5e-05, time_each_step=0.16s, eta=12:20:41\n",
      "2021-12-24 02:10:27 [INFO]\t[TRAIN] Epoch=2/35, Step=7085/7915, loss=0.631537, lr=9.5e-05, time_each_step=0.16s, eta=12:20:7\n",
      "2021-12-24 02:11:00 [INFO]\t[TRAIN] Epoch=2/35, Step=7285/7915, loss=1.016165, lr=9.5e-05, time_each_step=0.17s, eta=12:19:36\n",
      "2021-12-24 02:11:33 [INFO]\t[TRAIN] Epoch=2/35, Step=7485/7915, loss=0.454962, lr=9.5e-05, time_each_step=0.17s, eta=12:19:3\n",
      "2021-12-24 02:12:06 [INFO]\t[TRAIN] Epoch=2/35, Step=7685/7915, loss=0.717476, lr=9.5e-05, time_each_step=0.16s, eta=12:18:29\n",
      "2021-12-24 02:12:39 [INFO]\t[TRAIN] Epoch=2/35, Step=7885/7915, loss=1.159213, lr=9.5e-05, time_each_step=0.16s, eta=12:17:57\n",
      "2021-12-24 02:12:44 [INFO]\t[TRAIN] Epoch 2 finished, loss=0.895786, lr=9.6e-05 .\n",
      "2021-12-24 02:12:44 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 02:13:08 [INFO]\t[EVAL] Finished, Epoch=2, miou=0.455014, category_iou=[0.47951118 0.6598851  0.44658321 0.23407538], oacc=0.659056, category_acc=[0.53163195 0.87108162 0.62263307 0.68855739], kappa=0.523263, category_F1-score=[0.64820217 0.79509732 0.61743176 0.37935345] .\n",
      "2021-12-24 02:13:11 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 02:13:15 [INFO]\tModel saved in output/deeplab/epoch_2.\n",
      "2021-12-24 02:13:15 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_2, miou=0.45501371662662093\n",
      "2021-12-24 02:13:46 [INFO]\t[TRAIN] Epoch=3/35, Step=170/7915, loss=1.034045, lr=9.5e-05, time_each_step=0.16s, eta=12:11:43\n",
      "2021-12-24 02:14:19 [INFO]\t[TRAIN] Epoch=3/35, Step=370/7915, loss=0.497218, lr=9.5e-05, time_each_step=0.16s, eta=12:11:27\n",
      "2021-12-24 02:14:51 [INFO]\t[TRAIN] Epoch=3/35, Step=570/7915, loss=1.173553, lr=9.5e-05, time_each_step=0.16s, eta=12:10:42\n",
      "2021-12-24 02:15:24 [INFO]\t[TRAIN] Epoch=3/35, Step=770/7915, loss=1.031846, lr=9.5e-05, time_each_step=0.16s, eta=12:10:13\n",
      "2021-12-24 02:15:57 [INFO]\t[TRAIN] Epoch=3/35, Step=970/7915, loss=0.860259, lr=9.5e-05, time_each_step=0.16s, eta=12:9:37\n",
      "2021-12-24 02:16:30 [INFO]\t[TRAIN] Epoch=3/35, Step=1170/7915, loss=0.843554, lr=9.4e-05, time_each_step=0.16s, eta=12:9:13\n",
      "2021-12-24 02:17:02 [INFO]\t[TRAIN] Epoch=3/35, Step=1370/7915, loss=0.506514, lr=9.4e-05, time_each_step=0.16s, eta=12:8:27\n",
      "2021-12-24 02:17:35 [INFO]\t[TRAIN] Epoch=3/35, Step=1570/7915, loss=0.57586, lr=9.4e-05, time_each_step=0.17s, eta=12:8:21\n",
      "2021-12-24 02:18:08 [INFO]\t[TRAIN] Epoch=3/35, Step=1770/7915, loss=0.549133, lr=9.4e-05, time_each_step=0.16s, eta=12:7:28\n",
      "2021-12-24 02:18:41 [INFO]\t[TRAIN] Epoch=3/35, Step=1970/7915, loss=0.549687, lr=9.4e-05, time_each_step=0.17s, eta=12:7:19\n",
      "2021-12-24 02:19:14 [INFO]\t[TRAIN] Epoch=3/35, Step=2170/7915, loss=0.598952, lr=9.4e-05, time_each_step=0.16s, eta=12:6:7\n",
      "2021-12-24 02:19:47 [INFO]\t[TRAIN] Epoch=3/35, Step=2370/7915, loss=0.566578, lr=9.4e-05, time_each_step=0.17s, eta=12:6:2\n",
      "2021-12-24 02:20:20 [INFO]\t[TRAIN] Epoch=3/35, Step=2570/7915, loss=0.849058, lr=9.4e-05, time_each_step=0.17s, eta=12:5:34\n",
      "2021-12-24 02:20:53 [INFO]\t[TRAIN] Epoch=3/35, Step=2770/7915, loss=0.593112, lr=9.4e-05, time_each_step=0.16s, eta=12:4:40\n",
      "2021-12-24 02:21:25 [INFO]\t[TRAIN] Epoch=3/35, Step=2970/7915, loss=0.614121, lr=9.4e-05, time_each_step=0.16s, eta=12:4:6\n",
      "2021-12-24 02:21:58 [INFO]\t[TRAIN] Epoch=3/35, Step=3170/7915, loss=0.851833, lr=9.4e-05, time_each_step=0.16s, eta=12:3:31\n",
      "2021-12-24 02:22:31 [INFO]\t[TRAIN] Epoch=3/35, Step=3370/7915, loss=0.748474, lr=9.4e-05, time_each_step=0.16s, eta=12:3:7\n",
      "2021-12-24 02:23:04 [INFO]\t[TRAIN] Epoch=3/35, Step=3570/7915, loss=0.979214, lr=9.4e-05, time_each_step=0.16s, eta=12:2:31\n",
      "2021-12-24 02:23:37 [INFO]\t[TRAIN] Epoch=3/35, Step=3770/7915, loss=0.975434, lr=9.4e-05, time_each_step=0.16s, eta=12:1:51\n",
      "2021-12-24 02:24:09 [INFO]\t[TRAIN] Epoch=3/35, Step=3970/7915, loss=0.825279, lr=9.4e-05, time_each_step=0.16s, eta=12:1:26\n",
      "2021-12-24 02:24:42 [INFO]\t[TRAIN] Epoch=3/35, Step=4170/7915, loss=0.852398, lr=9.3e-05, time_each_step=0.16s, eta=12:0:46\n",
      "2021-12-24 02:25:15 [INFO]\t[TRAIN] Epoch=3/35, Step=4370/7915, loss=1.57272, lr=9.3e-05, time_each_step=0.17s, eta=12:0:31\n",
      "2021-12-24 02:25:47 [INFO]\t[TRAIN] Epoch=3/35, Step=4570/7915, loss=1.125494, lr=9.3e-05, time_each_step=0.16s, eta=11:59:41\n",
      "2021-12-24 02:26:20 [INFO]\t[TRAIN] Epoch=3/35, Step=4770/7915, loss=0.712646, lr=9.3e-05, time_each_step=0.17s, eta=11:59:24\n",
      "2021-12-24 02:26:53 [INFO]\t[TRAIN] Epoch=3/35, Step=4970/7915, loss=0.303062, lr=9.3e-05, time_each_step=0.16s, eta=11:58:43\n",
      "2021-12-24 02:27:26 [INFO]\t[TRAIN] Epoch=3/35, Step=5170/7915, loss=0.882129, lr=9.3e-05, time_each_step=0.16s, eta=11:58:16\n",
      "2021-12-24 02:27:59 [INFO]\t[TRAIN] Epoch=3/35, Step=5370/7915, loss=2.091632, lr=9.3e-05, time_each_step=0.16s, eta=11:57:38\n",
      "2021-12-24 02:28:31 [INFO]\t[TRAIN] Epoch=3/35, Step=5570/7915, loss=0.853904, lr=9.3e-05, time_each_step=0.17s, eta=11:57:15\n",
      "2021-12-24 02:29:04 [INFO]\t[TRAIN] Epoch=3/35, Step=5770/7915, loss=1.556789, lr=9.3e-05, time_each_step=0.16s, eta=11:56:36\n",
      "2021-12-24 02:29:37 [INFO]\t[TRAIN] Epoch=3/35, Step=5970/7915, loss=0.843314, lr=9.3e-05, time_each_step=0.16s, eta=11:55:58\n",
      "2021-12-24 02:30:10 [INFO]\t[TRAIN] Epoch=3/35, Step=6170/7915, loss=1.333782, lr=9.3e-05, time_each_step=0.16s, eta=11:55:26\n",
      "2021-12-24 02:30:42 [INFO]\t[TRAIN] Epoch=3/35, Step=6370/7915, loss=1.027998, lr=9.3e-05, time_each_step=0.16s, eta=11:54:54\n",
      "2021-12-24 02:31:15 [INFO]\t[TRAIN] Epoch=3/35, Step=6570/7915, loss=1.244104, lr=9.3e-05, time_each_step=0.16s, eta=11:54:24\n",
      "2021-12-24 02:31:48 [INFO]\t[TRAIN] Epoch=3/35, Step=6770/7915, loss=0.681454, lr=9.3e-05, time_each_step=0.16s, eta=11:53:51\n",
      "2021-12-24 02:32:21 [INFO]\t[TRAIN] Epoch=3/35, Step=6970/7915, loss=0.79787, lr=9.3e-05, time_each_step=0.16s, eta=11:53:17\n",
      "2021-12-24 02:32:54 [INFO]\t[TRAIN] Epoch=3/35, Step=7170/7915, loss=1.295923, lr=9.2e-05, time_each_step=0.17s, eta=11:52:46\n",
      "2021-12-24 02:33:27 [INFO]\t[TRAIN] Epoch=3/35, Step=7370/7915, loss=0.554294, lr=9.2e-05, time_each_step=0.16s, eta=11:52:13\n",
      "2021-12-24 02:33:59 [INFO]\t[TRAIN] Epoch=3/35, Step=7570/7915, loss=0.873644, lr=9.2e-05, time_each_step=0.16s, eta=11:51:39\n",
      "2021-12-24 02:34:32 [INFO]\t[TRAIN] Epoch=3/35, Step=7770/7915, loss=1.17337, lr=9.2e-05, time_each_step=0.16s, eta=11:51:6\n",
      "2021-12-24 02:34:55 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.833854, lr=9.4e-05 .\n",
      "2021-12-24 02:34:55 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 02:35:19 [INFO]\t[EVAL] Finished, Epoch=3, miou=0.488412, category_iou=[0.51728574 0.71231503 0.47570562 0.24834008], oacc=0.694609, category_acc=[0.57528661 0.8372757  0.70679207 0.68647872], kappa=0.56961, category_F1-score=[0.68185672 0.83199063 0.64471614 0.39787248] .\n",
      "2021-12-24 02:35:23 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 02:35:26 [INFO]\tModel saved in output/deeplab/epoch_3.\n",
      "2021-12-24 02:35:26 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_3, miou=0.4884116150172881\n",
      "2021-12-24 02:35:39 [INFO]\t[TRAIN] Epoch=4/35, Step=55/7915, loss=0.469168, lr=9.2e-05, time_each_step=0.16s, eta=11:49:57\n",
      "2021-12-24 02:36:12 [INFO]\t[TRAIN] Epoch=4/35, Step=255/7915, loss=0.515074, lr=9.2e-05, time_each_step=0.16s, eta=11:49:17\n",
      "2021-12-24 02:36:45 [INFO]\t[TRAIN] Epoch=4/35, Step=455/7915, loss=0.31934, lr=9.2e-05, time_each_step=0.17s, eta=11:49:10\n",
      "2021-12-24 02:37:18 [INFO]\t[TRAIN] Epoch=4/35, Step=655/7915, loss=1.460991, lr=9.2e-05, time_each_step=0.17s, eta=11:48:35\n",
      "2021-12-24 02:37:51 [INFO]\t[TRAIN] Epoch=4/35, Step=855/7915, loss=0.907103, lr=9.2e-05, time_each_step=0.16s, eta=11:47:39\n",
      "2021-12-24 02:38:24 [INFO]\t[TRAIN] Epoch=4/35, Step=1055/7915, loss=1.289131, lr=9.2e-05, time_each_step=0.17s, eta=11:47:19\n",
      "2021-12-24 02:38:57 [INFO]\t[TRAIN] Epoch=4/35, Step=1255/7915, loss=0.899921, lr=9.2e-05, time_each_step=0.16s, eta=11:46:43\n",
      "2021-12-24 02:39:30 [INFO]\t[TRAIN] Epoch=4/35, Step=1455/7915, loss=0.96085, lr=9.2e-05, time_each_step=0.17s, eta=11:46:16\n",
      "2021-12-24 02:40:03 [INFO]\t[TRAIN] Epoch=4/35, Step=1655/7915, loss=0.447308, lr=9.2e-05, time_each_step=0.16s, eta=11:45:24\n",
      "2021-12-24 02:40:36 [INFO]\t[TRAIN] Epoch=4/35, Step=1855/7915, loss=0.420175, lr=9.2e-05, time_each_step=0.16s, eta=11:44:55\n",
      "2021-12-24 02:41:09 [INFO]\t[TRAIN] Epoch=4/35, Step=2055/7915, loss=0.5661, lr=9.2e-05, time_each_step=0.16s, eta=11:44:19\n",
      "2021-12-24 02:41:42 [INFO]\t[TRAIN] Epoch=4/35, Step=2255/7915, loss=0.270477, lr=9.2e-05, time_each_step=0.17s, eta=11:44:12\n",
      "2021-12-24 02:42:15 [INFO]\t[TRAIN] Epoch=4/35, Step=2455/7915, loss=0.374875, lr=9.1e-05, time_each_step=0.17s, eta=11:43:37\n",
      "2021-12-24 02:42:48 [INFO]\t[TRAIN] Epoch=4/35, Step=2655/7915, loss=0.322312, lr=9.1e-05, time_each_step=0.17s, eta=11:43:0\n",
      "2021-12-24 02:43:21 [INFO]\t[TRAIN] Epoch=4/35, Step=2855/7915, loss=0.752276, lr=9.1e-05, time_each_step=0.17s, eta=11:42:26\n",
      "2021-12-24 02:43:54 [INFO]\t[TRAIN] Epoch=4/35, Step=3055/7915, loss=0.408916, lr=9.1e-05, time_each_step=0.16s, eta=11:41:44\n",
      "2021-12-24 02:44:28 [INFO]\t[TRAIN] Epoch=4/35, Step=3255/7915, loss=0.264313, lr=9.1e-05, time_each_step=0.17s, eta=11:41:25\n",
      "2021-12-24 02:45:01 [INFO]\t[TRAIN] Epoch=4/35, Step=3455/7915, loss=1.15173, lr=9.1e-05, time_each_step=0.17s, eta=11:40:41\n",
      "2021-12-24 02:45:34 [INFO]\t[TRAIN] Epoch=4/35, Step=3655/7915, loss=0.710761, lr=9.1e-05, time_each_step=0.17s, eta=11:40:14\n",
      "2021-12-24 02:46:07 [INFO]\t[TRAIN] Epoch=4/35, Step=3855/7915, loss=0.822017, lr=9.1e-05, time_each_step=0.17s, eta=11:39:43\n",
      "2021-12-24 02:46:40 [INFO]\t[TRAIN] Epoch=4/35, Step=4055/7915, loss=0.861984, lr=9.1e-05, time_each_step=0.16s, eta=11:38:57\n",
      "2021-12-24 02:47:12 [INFO]\t[TRAIN] Epoch=4/35, Step=4255/7915, loss=0.679906, lr=9.1e-05, time_each_step=0.16s, eta=11:38:27\n",
      "2021-12-24 02:47:46 [INFO]\t[TRAIN] Epoch=4/35, Step=4455/7915, loss=0.558265, lr=9.1e-05, time_each_step=0.17s, eta=11:37:58\n",
      "2021-12-24 02:48:18 [INFO]\t[TRAIN] Epoch=4/35, Step=4655/7915, loss=0.531802, lr=9.1e-05, time_each_step=0.17s, eta=11:37:24\n",
      "2021-12-24 02:48:52 [INFO]\t[TRAIN] Epoch=4/35, Step=4855/7915, loss=0.755884, lr=9.1e-05, time_each_step=0.16s, eta=11:36:44\n",
      "2021-12-24 02:49:25 [INFO]\t[TRAIN] Epoch=4/35, Step=5055/7915, loss=0.782766, lr=9.1e-05, time_each_step=0.17s, eta=11:36:21\n",
      "2021-12-24 02:49:58 [INFO]\t[TRAIN] Epoch=4/35, Step=5255/7915, loss=0.277646, lr=9.1e-05, time_each_step=0.16s, eta=11:35:44\n",
      "2021-12-24 02:50:31 [INFO]\t[TRAIN] Epoch=4/35, Step=5455/7915, loss=1.677391, lr=9e-05, time_each_step=0.16s, eta=11:35:10\n",
      "2021-12-24 02:51:04 [INFO]\t[TRAIN] Epoch=4/35, Step=5655/7915, loss=0.329652, lr=9e-05, time_each_step=0.17s, eta=11:34:38\n",
      "2021-12-24 02:51:37 [INFO]\t[TRAIN] Epoch=4/35, Step=5855/7915, loss=0.933122, lr=9e-05, time_each_step=0.16s, eta=11:34:4\n",
      "2021-12-24 02:52:10 [INFO]\t[TRAIN] Epoch=4/35, Step=6055/7915, loss=0.498062, lr=9e-05, time_each_step=0.16s, eta=11:33:31\n",
      "2021-12-24 02:52:43 [INFO]\t[TRAIN] Epoch=4/35, Step=6255/7915, loss=0.867419, lr=9e-05, time_each_step=0.17s, eta=11:33:2\n",
      "2021-12-24 02:53:16 [INFO]\t[TRAIN] Epoch=4/35, Step=6455/7915, loss=0.796008, lr=9e-05, time_each_step=0.17s, eta=11:32:30\n",
      "2021-12-24 02:53:49 [INFO]\t[TRAIN] Epoch=4/35, Step=6655/7915, loss=0.799975, lr=9e-05, time_each_step=0.17s, eta=11:31:54\n",
      "2021-12-24 02:54:22 [INFO]\t[TRAIN] Epoch=4/35, Step=6855/7915, loss=0.679703, lr=9e-05, time_each_step=0.17s, eta=11:31:21\n",
      "2021-12-24 02:54:55 [INFO]\t[TRAIN] Epoch=4/35, Step=7055/7915, loss=0.834612, lr=9e-05, time_each_step=0.17s, eta=11:30:49\n",
      "2021-12-24 02:55:28 [INFO]\t[TRAIN] Epoch=4/35, Step=7255/7915, loss=1.076881, lr=9e-05, time_each_step=0.17s, eta=11:30:15\n",
      "2021-12-24 02:56:01 [INFO]\t[TRAIN] Epoch=4/35, Step=7455/7915, loss=1.089892, lr=9e-05, time_each_step=0.17s, eta=11:29:41\n",
      "2021-12-24 02:56:34 [INFO]\t[TRAIN] Epoch=4/35, Step=7655/7915, loss=0.544605, lr=9e-05, time_each_step=0.16s, eta=11:29:7\n",
      "2021-12-24 02:57:07 [INFO]\t[TRAIN] Epoch=4/35, Step=7855/7915, loss=0.424273, lr=9e-05, time_each_step=0.16s, eta=11:28:35\n",
      "2021-12-24 02:57:16 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.792964, lr=9.1e-05 .\n",
      "2021-12-24 02:57:16 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 02:57:40 [INFO]\t[EVAL] Finished, Epoch=4, miou=0.506612, category_iou=[0.53411951 0.71823859 0.50613951 0.26795061], oacc=0.707587, category_acc=[0.60462401 0.8444208  0.67619328 0.69619939], kappa=0.590141, category_F1-score=[0.6963206  0.83601729 0.67210177 0.4226515 ] .\n",
      "2021-12-24 02:57:44 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 02:57:47 [INFO]\tModel saved in output/deeplab/epoch_4.\n",
      "2021-12-24 02:57:47 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_4, miou=0.5066120553056023\n",
      "2021-12-24 02:58:14 [INFO]\t[TRAIN] Epoch=5/35, Step=140/7915, loss=0.510206, lr=9e-05, time_each_step=0.16s, eta=11:32:22\n",
      "2021-12-24 02:58:46 [INFO]\t[TRAIN] Epoch=5/35, Step=340/7915, loss=0.559436, lr=9e-05, time_each_step=0.16s, eta=11:31:34\n",
      "2021-12-24 02:59:19 [INFO]\t[TRAIN] Epoch=5/35, Step=540/7915, loss=0.359122, lr=8.9e-05, time_each_step=0.16s, eta=11:30:48\n",
      "2021-12-24 02:59:52 [INFO]\t[TRAIN] Epoch=5/35, Step=740/7915, loss=0.865524, lr=8.9e-05, time_each_step=0.17s, eta=11:30:49\n",
      "2021-12-24 03:00:25 [INFO]\t[TRAIN] Epoch=5/35, Step=940/7915, loss=0.730793, lr=8.9e-05, time_each_step=0.16s, eta=11:30:11\n",
      "2021-12-24 03:00:58 [INFO]\t[TRAIN] Epoch=5/35, Step=1140/7915, loss=0.776696, lr=8.9e-05, time_each_step=0.17s, eta=11:29:41\n",
      "2021-12-24 03:01:31 [INFO]\t[TRAIN] Epoch=5/35, Step=1340/7915, loss=1.190182, lr=8.9e-05, time_each_step=0.16s, eta=11:29:3\n",
      "2021-12-24 03:02:04 [INFO]\t[TRAIN] Epoch=5/35, Step=1540/7915, loss=0.909715, lr=8.9e-05, time_each_step=0.16s, eta=11:28:22\n",
      "2021-12-24 03:02:37 [INFO]\t[TRAIN] Epoch=5/35, Step=1740/7915, loss=0.864165, lr=8.9e-05, time_each_step=0.17s, eta=11:28:1\n",
      "2021-12-24 03:03:09 [INFO]\t[TRAIN] Epoch=5/35, Step=1940/7915, loss=1.006287, lr=8.9e-05, time_each_step=0.17s, eta=11:27:32\n",
      "2021-12-24 03:03:42 [INFO]\t[TRAIN] Epoch=5/35, Step=2140/7915, loss=1.362257, lr=8.9e-05, time_each_step=0.16s, eta=11:26:46\n",
      "2021-12-24 03:04:15 [INFO]\t[TRAIN] Epoch=5/35, Step=2340/7915, loss=0.75768, lr=8.9e-05, time_each_step=0.17s, eta=11:26:22\n",
      "2021-12-24 03:04:48 [INFO]\t[TRAIN] Epoch=5/35, Step=2540/7915, loss=0.680867, lr=8.9e-05, time_each_step=0.16s, eta=11:25:47\n",
      "2021-12-24 03:05:21 [INFO]\t[TRAIN] Epoch=5/35, Step=2740/7915, loss=0.727353, lr=8.9e-05, time_each_step=0.17s, eta=11:25:17\n",
      "2021-12-24 03:05:54 [INFO]\t[TRAIN] Epoch=5/35, Step=2940/7915, loss=0.476871, lr=8.9e-05, time_each_step=0.16s, eta=11:24:29\n",
      "2021-12-24 03:06:27 [INFO]\t[TRAIN] Epoch=5/35, Step=3140/7915, loss=0.786982, lr=8.9e-05, time_each_step=0.16s, eta=11:24:1\n",
      "2021-12-24 03:07:00 [INFO]\t[TRAIN] Epoch=5/35, Step=3340/7915, loss=1.052629, lr=8.9e-05, time_each_step=0.16s, eta=11:23:27\n",
      "2021-12-24 03:07:33 [INFO]\t[TRAIN] Epoch=5/35, Step=3540/7915, loss=1.560786, lr=8.8e-05, time_each_step=0.16s, eta=11:23:2\n",
      "2021-12-24 03:08:06 [INFO]\t[TRAIN] Epoch=5/35, Step=3740/7915, loss=1.094483, lr=8.8e-05, time_each_step=0.17s, eta=11:22:36\n",
      "2021-12-24 03:08:39 [INFO]\t[TRAIN] Epoch=5/35, Step=3940/7915, loss=0.450135, lr=8.8e-05, time_each_step=0.16s, eta=11:21:51\n",
      "2021-12-24 03:09:12 [INFO]\t[TRAIN] Epoch=5/35, Step=4140/7915, loss=1.201237, lr=8.8e-05, time_each_step=0.16s, eta=11:21:17\n",
      "2021-12-24 03:09:44 [INFO]\t[TRAIN] Epoch=5/35, Step=4340/7915, loss=1.312325, lr=8.8e-05, time_each_step=0.16s, eta=11:20:45\n",
      "2021-12-24 03:10:17 [INFO]\t[TRAIN] Epoch=5/35, Step=4540/7915, loss=0.941175, lr=8.8e-05, time_each_step=0.16s, eta=11:20:6\n",
      "2021-12-24 03:10:50 [INFO]\t[TRAIN] Epoch=5/35, Step=4740/7915, loss=0.723184, lr=8.8e-05, time_each_step=0.17s, eta=11:19:47\n",
      "2021-12-24 03:11:23 [INFO]\t[TRAIN] Epoch=5/35, Step=4940/7915, loss=0.903212, lr=8.8e-05, time_each_step=0.16s, eta=11:19:4\n",
      "2021-12-24 03:11:56 [INFO]\t[TRAIN] Epoch=5/35, Step=5140/7915, loss=0.718539, lr=8.8e-05, time_each_step=0.16s, eta=11:18:39\n",
      "2021-12-24 03:12:29 [INFO]\t[TRAIN] Epoch=5/35, Step=5340/7915, loss=0.227821, lr=8.8e-05, time_each_step=0.17s, eta=11:18:10\n",
      "2021-12-24 03:13:02 [INFO]\t[TRAIN] Epoch=5/35, Step=5540/7915, loss=0.653817, lr=8.8e-05, time_each_step=0.17s, eta=11:17:35\n",
      "2021-12-24 03:13:35 [INFO]\t[TRAIN] Epoch=5/35, Step=5740/7915, loss=0.707135, lr=8.8e-05, time_each_step=0.17s, eta=11:17:4\n",
      "2021-12-24 03:14:08 [INFO]\t[TRAIN] Epoch=5/35, Step=5940/7915, loss=0.978935, lr=8.8e-05, time_each_step=0.17s, eta=11:16:28\n",
      "2021-12-24 03:14:41 [INFO]\t[TRAIN] Epoch=5/35, Step=6140/7915, loss=0.460339, lr=8.8e-05, time_each_step=0.17s, eta=11:15:54\n",
      "2021-12-24 03:15:14 [INFO]\t[TRAIN] Epoch=5/35, Step=6340/7915, loss=0.459967, lr=8.8e-05, time_each_step=0.16s, eta=11:15:19\n",
      "2021-12-24 03:15:47 [INFO]\t[TRAIN] Epoch=5/35, Step=6540/7915, loss=0.917023, lr=8.7e-05, time_each_step=0.17s, eta=11:14:48\n",
      "2021-12-24 03:16:20 [INFO]\t[TRAIN] Epoch=5/35, Step=6740/7915, loss=0.760407, lr=8.7e-05, time_each_step=0.17s, eta=11:14:16\n",
      "2021-12-24 03:16:53 [INFO]\t[TRAIN] Epoch=5/35, Step=6940/7915, loss=0.759063, lr=8.7e-05, time_each_step=0.17s, eta=11:13:44\n",
      "2021-12-24 03:17:26 [INFO]\t[TRAIN] Epoch=5/35, Step=7140/7915, loss=0.674724, lr=8.7e-05, time_each_step=0.17s, eta=11:13:10\n",
      "2021-12-24 03:17:59 [INFO]\t[TRAIN] Epoch=5/35, Step=7340/7915, loss=0.99897, lr=8.7e-05, time_each_step=0.16s, eta=11:12:36\n",
      "2021-12-24 03:18:32 [INFO]\t[TRAIN] Epoch=5/35, Step=7540/7915, loss=0.668602, lr=8.7e-05, time_each_step=0.17s, eta=11:12:3\n",
      "2021-12-24 03:19:05 [INFO]\t[TRAIN] Epoch=5/35, Step=7740/7915, loss=1.028527, lr=8.7e-05, time_each_step=0.16s, eta=11:11:29\n",
      "2021-12-24 03:19:33 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.761496, lr=8.8e-05 .\n",
      "2021-12-24 03:19:33 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 03:19:56 [INFO]\t[EVAL] Finished, Epoch=5, miou=0.522229, category_iou=[0.53987733 0.72538099 0.5166911  0.30696628], oacc=0.714657, category_acc=[0.63452974 0.84120336 0.70072488 0.59504837], kappa=0.60191, category_F1-score=[0.70119524 0.84083573 0.68133993 0.46973863] .\n",
      "2021-12-24 03:20:00 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 03:20:04 [INFO]\tModel saved in output/deeplab/epoch_5.\n",
      "2021-12-24 03:20:04 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_5, miou=0.5222289239052683\n",
      "2021-12-24 03:20:11 [INFO]\t[TRAIN] Epoch=6/35, Step=25/7915, loss=0.336304, lr=8.7e-05, time_each_step=0.19s, eta=11:11:20\n",
      "2021-12-24 03:20:44 [INFO]\t[TRAIN] Epoch=6/35, Step=225/7915, loss=0.940169, lr=8.7e-05, time_each_step=0.17s, eta=11:7:49\n",
      "2021-12-24 03:21:17 [INFO]\t[TRAIN] Epoch=6/35, Step=425/7915, loss=0.345424, lr=8.7e-05, time_each_step=0.16s, eta=11:6:57\n",
      "2021-12-24 03:21:50 [INFO]\t[TRAIN] Epoch=6/35, Step=625/7915, loss=1.086991, lr=8.7e-05, time_each_step=0.17s, eta=11:6:44\n",
      "2021-12-24 03:22:23 [INFO]\t[TRAIN] Epoch=6/35, Step=825/7915, loss=0.613406, lr=8.7e-05, time_each_step=0.16s, eta=11:5:57\n",
      "2021-12-24 03:22:56 [INFO]\t[TRAIN] Epoch=6/35, Step=1025/7915, loss=0.942638, lr=8.7e-05, time_each_step=0.16s, eta=11:5:26\n",
      "2021-12-24 03:23:29 [INFO]\t[TRAIN] Epoch=6/35, Step=1225/7915, loss=0.681803, lr=8.7e-05, time_each_step=0.16s, eta=11:4:46\n",
      "2021-12-24 03:24:02 [INFO]\t[TRAIN] Epoch=6/35, Step=1425/7915, loss=1.095526, lr=8.7e-05, time_each_step=0.16s, eta=11:4:28\n",
      "2021-12-24 03:24:35 [INFO]\t[TRAIN] Epoch=6/35, Step=1625/7915, loss=0.586805, lr=8.7e-05, time_each_step=0.17s, eta=11:4:10\n",
      "2021-12-24 03:25:08 [INFO]\t[TRAIN] Epoch=6/35, Step=1825/7915, loss=0.72972, lr=8.6e-05, time_each_step=0.17s, eta=11:3:36\n",
      "2021-12-24 03:25:41 [INFO]\t[TRAIN] Epoch=6/35, Step=2025/7915, loss=0.368928, lr=8.6e-05, time_each_step=0.17s, eta=11:2:58\n",
      "2021-12-24 03:26:13 [INFO]\t[TRAIN] Epoch=6/35, Step=2225/7915, loss=0.782842, lr=8.6e-05, time_each_step=0.16s, eta=11:2:8\n",
      "2021-12-24 03:26:46 [INFO]\t[TRAIN] Epoch=6/35, Step=2425/7915, loss=0.727273, lr=8.6e-05, time_each_step=0.17s, eta=11:1:45\n",
      "2021-12-24 03:27:20 [INFO]\t[TRAIN] Epoch=6/35, Step=2625/7915, loss=0.509194, lr=8.6e-05, time_each_step=0.17s, eta=11:1:18\n",
      "2021-12-24 03:27:53 [INFO]\t[TRAIN] Epoch=6/35, Step=2825/7915, loss=0.851457, lr=8.6e-05, time_each_step=0.17s, eta=11:0:47\n",
      "2021-12-24 03:28:26 [INFO]\t[TRAIN] Epoch=6/35, Step=3025/7915, loss=0.411441, lr=8.6e-05, time_each_step=0.17s, eta=11:0:7\n",
      "2021-12-24 03:28:59 [INFO]\t[TRAIN] Epoch=6/35, Step=3225/7915, loss=1.611462, lr=8.6e-05, time_each_step=0.16s, eta=10:59:30\n",
      "2021-12-24 03:29:32 [INFO]\t[TRAIN] Epoch=6/35, Step=3425/7915, loss=0.617745, lr=8.6e-05, time_each_step=0.17s, eta=10:59:2\n",
      "2021-12-24 03:30:05 [INFO]\t[TRAIN] Epoch=6/35, Step=3625/7915, loss=0.674859, lr=8.6e-05, time_each_step=0.17s, eta=10:58:29\n",
      "2021-12-24 03:30:38 [INFO]\t[TRAIN] Epoch=6/35, Step=3825/7915, loss=0.957632, lr=8.6e-05, time_each_step=0.16s, eta=10:57:51\n",
      "2021-12-24 03:31:11 [INFO]\t[TRAIN] Epoch=6/35, Step=4025/7915, loss=0.593949, lr=8.6e-05, time_each_step=0.16s, eta=10:57:17\n",
      "2021-12-24 03:31:44 [INFO]\t[TRAIN] Epoch=6/35, Step=4225/7915, loss=0.618103, lr=8.6e-05, time_each_step=0.16s, eta=10:56:46\n",
      "2021-12-24 03:32:17 [INFO]\t[TRAIN] Epoch=6/35, Step=4425/7915, loss=0.616946, lr=8.6e-05, time_each_step=0.17s, eta=10:56:21\n",
      "2021-12-24 03:32:50 [INFO]\t[TRAIN] Epoch=6/35, Step=4625/7915, loss=1.099823, lr=8.6e-05, time_each_step=0.16s, eta=10:55:37\n",
      "2021-12-24 03:33:23 [INFO]\t[TRAIN] Epoch=6/35, Step=4825/7915, loss=0.957528, lr=8.5e-05, time_each_step=0.16s, eta=10:55:5\n",
      "2021-12-24 03:33:56 [INFO]\t[TRAIN] Epoch=6/35, Step=5025/7915, loss=1.295223, lr=8.5e-05, time_each_step=0.17s, eta=10:54:39\n",
      "2021-12-24 03:34:29 [INFO]\t[TRAIN] Epoch=6/35, Step=5225/7915, loss=0.532206, lr=8.5e-05, time_each_step=0.17s, eta=10:54:3\n",
      "2021-12-24 03:35:02 [INFO]\t[TRAIN] Epoch=6/35, Step=5425/7915, loss=0.544303, lr=8.5e-05, time_each_step=0.17s, eta=10:53:34\n",
      "2021-12-24 03:35:35 [INFO]\t[TRAIN] Epoch=6/35, Step=5625/7915, loss=0.511515, lr=8.5e-05, time_each_step=0.17s, eta=10:53:1\n",
      "2021-12-24 03:36:08 [INFO]\t[TRAIN] Epoch=6/35, Step=5825/7915, loss=0.78315, lr=8.5e-05, time_each_step=0.17s, eta=10:52:27\n",
      "2021-12-24 03:36:41 [INFO]\t[TRAIN] Epoch=6/35, Step=6025/7915, loss=0.305825, lr=8.5e-05, time_each_step=0.16s, eta=10:51:45\n",
      "2021-12-24 03:37:14 [INFO]\t[TRAIN] Epoch=6/35, Step=6225/7915, loss=0.912853, lr=8.5e-05, time_each_step=0.16s, eta=10:51:17\n",
      "2021-12-24 03:37:47 [INFO]\t[TRAIN] Epoch=6/35, Step=6425/7915, loss=1.20452, lr=8.5e-05, time_each_step=0.16s, eta=10:50:43\n",
      "2021-12-24 03:38:20 [INFO]\t[TRAIN] Epoch=6/35, Step=6625/7915, loss=0.262748, lr=8.5e-05, time_each_step=0.17s, eta=10:50:13\n",
      "2021-12-24 03:38:53 [INFO]\t[TRAIN] Epoch=6/35, Step=6825/7915, loss=0.5309, lr=8.5e-05, time_each_step=0.17s, eta=10:49:40\n",
      "2021-12-24 03:39:26 [INFO]\t[TRAIN] Epoch=6/35, Step=7025/7915, loss=0.539745, lr=8.5e-05, time_each_step=0.17s, eta=10:49:6\n",
      "2021-12-24 03:39:59 [INFO]\t[TRAIN] Epoch=6/35, Step=7225/7915, loss=0.632798, lr=8.5e-05, time_each_step=0.17s, eta=10:48:35\n",
      "2021-12-24 03:40:32 [INFO]\t[TRAIN] Epoch=6/35, Step=7425/7915, loss=1.280898, lr=8.5e-05, time_each_step=0.17s, eta=10:48:1\n",
      "2021-12-24 03:41:05 [INFO]\t[TRAIN] Epoch=6/35, Step=7625/7915, loss=1.101638, lr=8.5e-05, time_each_step=0.17s, eta=10:47:27\n",
      "2021-12-24 03:41:38 [INFO]\t[TRAIN] Epoch=6/35, Step=7825/7915, loss=1.281752, lr=8.4e-05, time_each_step=0.16s, eta=10:46:53\n",
      "2021-12-24 03:41:53 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.729578, lr=8.6e-05 .\n",
      "2021-12-24 03:41:53 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 03:42:16 [INFO]\t[EVAL] Finished, Epoch=6, miou=0.52461, category_iou=[0.53310497 0.71960494 0.52145065 0.32427877], oacc=0.713571, category_acc=[0.62209195 0.85601673 0.69853231 0.61214225], kappa=0.601275, category_F1-score=[0.69545789 0.83694216 0.68546509 0.48974396] .\n",
      "2021-12-24 03:42:20 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 03:42:24 [INFO]\tModel saved in output/deeplab/epoch_6.\n",
      "2021-12-24 03:42:24 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_6, miou=0.5246098320772671\n",
      "2021-12-24 03:42:46 [INFO]\t[TRAIN] Epoch=7/35, Step=110/7915, loss=1.275256, lr=8.4e-05, time_each_step=0.16s, eta=10:46:57\n",
      "2021-12-24 03:43:19 [INFO]\t[TRAIN] Epoch=7/35, Step=310/7915, loss=0.383568, lr=8.4e-05, time_each_step=0.16s, eta=10:46:18\n",
      "2021-12-24 03:43:52 [INFO]\t[TRAIN] Epoch=7/35, Step=510/7915, loss=0.631141, lr=8.4e-05, time_each_step=0.17s, eta=10:45:59\n",
      "2021-12-24 03:44:24 [INFO]\t[TRAIN] Epoch=7/35, Step=710/7915, loss=1.368718, lr=8.4e-05, time_each_step=0.17s, eta=10:45:30\n",
      "2021-12-24 03:44:57 [INFO]\t[TRAIN] Epoch=7/35, Step=910/7915, loss=0.34685, lr=8.4e-05, time_each_step=0.16s, eta=10:44:46\n",
      "2021-12-24 03:45:30 [INFO]\t[TRAIN] Epoch=7/35, Step=1110/7915, loss=0.43136, lr=8.4e-05, time_each_step=0.17s, eta=10:44:27\n",
      "2021-12-24 03:46:03 [INFO]\t[TRAIN] Epoch=7/35, Step=1310/7915, loss=0.307832, lr=8.4e-05, time_each_step=0.16s, eta=10:43:44\n",
      "2021-12-24 03:46:36 [INFO]\t[TRAIN] Epoch=7/35, Step=1510/7915, loss=1.118625, lr=8.4e-05, time_each_step=0.16s, eta=10:43:11\n",
      "2021-12-24 03:47:09 [INFO]\t[TRAIN] Epoch=7/35, Step=1710/7915, loss=1.10586, lr=8.4e-05, time_each_step=0.16s, eta=10:42:20\n",
      "2021-12-24 03:47:42 [INFO]\t[TRAIN] Epoch=7/35, Step=1910/7915, loss=0.574339, lr=8.4e-05, time_each_step=0.17s, eta=10:42:19\n",
      "2021-12-24 03:48:16 [INFO]\t[TRAIN] Epoch=7/35, Step=2110/7915, loss=0.191339, lr=8.4e-05, time_each_step=0.16s, eta=10:41:27\n",
      "2021-12-24 03:48:48 [INFO]\t[TRAIN] Epoch=7/35, Step=2310/7915, loss=1.341325, lr=8.4e-05, time_each_step=0.17s, eta=10:41:14\n",
      "2021-12-24 03:49:22 [INFO]\t[TRAIN] Epoch=7/35, Step=2510/7915, loss=1.12539, lr=8.4e-05, time_each_step=0.17s, eta=10:40:29\n",
      "2021-12-24 03:49:55 [INFO]\t[TRAIN] Epoch=7/35, Step=2710/7915, loss=0.537218, lr=8.4e-05, time_each_step=0.17s, eta=10:39:59\n",
      "2021-12-24 03:50:28 [INFO]\t[TRAIN] Epoch=7/35, Step=2910/7915, loss=0.461938, lr=8.3e-05, time_each_step=0.17s, eta=10:39:26\n",
      "2021-12-24 03:51:01 [INFO]\t[TRAIN] Epoch=7/35, Step=3110/7915, loss=0.602407, lr=8.3e-05, time_each_step=0.17s, eta=10:38:53\n",
      "2021-12-24 03:51:34 [INFO]\t[TRAIN] Epoch=7/35, Step=3310/7915, loss=0.450818, lr=8.3e-05, time_each_step=0.17s, eta=10:38:17\n",
      "2021-12-24 03:52:07 [INFO]\t[TRAIN] Epoch=7/35, Step=3510/7915, loss=0.844874, lr=8.3e-05, time_each_step=0.17s, eta=10:37:46\n",
      "2021-12-24 03:52:40 [INFO]\t[TRAIN] Epoch=7/35, Step=3710/7915, loss=0.614633, lr=8.3e-05, time_each_step=0.17s, eta=10:37:16\n",
      "2021-12-24 03:53:13 [INFO]\t[TRAIN] Epoch=7/35, Step=3910/7915, loss=0.850559, lr=8.3e-05, time_each_step=0.17s, eta=10:36:48\n",
      "2021-12-24 03:53:46 [INFO]\t[TRAIN] Epoch=7/35, Step=4110/7915, loss=1.128291, lr=8.3e-05, time_each_step=0.17s, eta=10:36:5\n",
      "2021-12-24 03:54:19 [INFO]\t[TRAIN] Epoch=7/35, Step=4310/7915, loss=1.003958, lr=8.3e-05, time_each_step=0.17s, eta=10:35:35\n",
      "2021-12-24 03:54:52 [INFO]\t[TRAIN] Epoch=7/35, Step=4510/7915, loss=1.32906, lr=8.3e-05, time_each_step=0.16s, eta=10:34:54\n",
      "2021-12-24 03:55:25 [INFO]\t[TRAIN] Epoch=7/35, Step=4710/7915, loss=0.20317, lr=8.3e-05, time_each_step=0.17s, eta=10:34:30\n",
      "2021-12-24 03:55:58 [INFO]\t[TRAIN] Epoch=7/35, Step=4910/7915, loss=0.569876, lr=8.3e-05, time_each_step=0.16s, eta=10:33:50\n",
      "2021-12-24 03:56:31 [INFO]\t[TRAIN] Epoch=7/35, Step=5110/7915, loss=0.73001, lr=8.3e-05, time_each_step=0.17s, eta=10:33:20\n",
      "2021-12-24 03:57:05 [INFO]\t[TRAIN] Epoch=7/35, Step=5310/7915, loss=0.500103, lr=8.3e-05, time_each_step=0.17s, eta=10:32:49\n",
      "2021-12-24 03:57:38 [INFO]\t[TRAIN] Epoch=7/35, Step=5510/7915, loss=1.419304, lr=8.3e-05, time_each_step=0.17s, eta=10:32:16\n",
      "2021-12-24 03:58:11 [INFO]\t[TRAIN] Epoch=7/35, Step=5710/7915, loss=1.416531, lr=8.3e-05, time_each_step=0.16s, eta=10:31:36\n",
      "2021-12-24 03:58:44 [INFO]\t[TRAIN] Epoch=7/35, Step=5910/7915, loss=0.555966, lr=8.2e-05, time_each_step=0.17s, eta=10:31:8\n",
      "2021-12-24 03:59:17 [INFO]\t[TRAIN] Epoch=7/35, Step=6110/7915, loss=1.170502, lr=8.2e-05, time_each_step=0.17s, eta=10:30:38\n",
      "2021-12-24 03:59:50 [INFO]\t[TRAIN] Epoch=7/35, Step=6310/7915, loss=1.197523, lr=8.2e-05, time_each_step=0.16s, eta=10:30:1\n",
      "2021-12-24 04:00:23 [INFO]\t[TRAIN] Epoch=7/35, Step=6510/7915, loss=0.399216, lr=8.2e-05, time_each_step=0.17s, eta=10:29:30\n",
      "2021-12-24 04:00:56 [INFO]\t[TRAIN] Epoch=7/35, Step=6710/7915, loss=0.65414, lr=8.2e-05, time_each_step=0.16s, eta=10:28:53\n",
      "2021-12-24 04:01:29 [INFO]\t[TRAIN] Epoch=7/35, Step=6910/7915, loss=0.20049, lr=8.2e-05, time_each_step=0.17s, eta=10:28:25\n",
      "2021-12-24 04:02:02 [INFO]\t[TRAIN] Epoch=7/35, Step=7110/7915, loss=0.275975, lr=8.2e-05, time_each_step=0.17s, eta=10:27:50\n",
      "2021-12-24 04:02:35 [INFO]\t[TRAIN] Epoch=7/35, Step=7310/7915, loss=0.649398, lr=8.2e-05, time_each_step=0.16s, eta=10:27:16\n",
      "2021-12-24 04:03:08 [INFO]\t[TRAIN] Epoch=7/35, Step=7510/7915, loss=0.431442, lr=8.2e-05, time_each_step=0.17s, eta=10:26:43\n",
      "2021-12-24 04:03:41 [INFO]\t[TRAIN] Epoch=7/35, Step=7710/7915, loss=0.94927, lr=8.2e-05, time_each_step=0.16s, eta=10:26:10\n",
      "2021-12-24 04:04:14 [INFO]\t[TRAIN] Epoch=7/35, Step=7910/7915, loss=0.579049, lr=8.2e-05, time_each_step=0.16s, eta=10:25:37\n",
      "2021-12-24 04:04:15 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.700888, lr=8.3e-05 .\n",
      "2021-12-24 04:04:15 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 04:04:38 [INFO]\t[EVAL] Finished, Epoch=7, miou=0.526962, category_iou=[0.53836044 0.72666273 0.51537681 0.32744815], oacc=0.715332, category_acc=[0.61819628 0.86372924 0.73632561 0.58739381], kappa=0.603255, category_F1-score=[0.69991457 0.8416962  0.68019625 0.49334981] .\n",
      "2021-12-24 04:04:42 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 04:04:46 [INFO]\tModel saved in output/deeplab/epoch_7.\n",
      "2021-12-24 04:04:46 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_7, miou=0.5269620325430352\n",
      "2021-12-24 04:05:21 [INFO]\t[TRAIN] Epoch=8/35, Step=195/7915, loss=0.567962, lr=8.2e-05, time_each_step=0.16s, eta=10:25:28\n",
      "2021-12-24 04:05:54 [INFO]\t[TRAIN] Epoch=8/35, Step=395/7915, loss=0.634858, lr=8.2e-05, time_each_step=0.16s, eta=10:24:55\n",
      "2021-12-24 04:06:27 [INFO]\t[TRAIN] Epoch=8/35, Step=595/7915, loss=0.386429, lr=8.2e-05, time_each_step=0.16s, eta=10:24:9\n",
      "2021-12-24 04:07:00 [INFO]\t[TRAIN] Epoch=8/35, Step=795/7915, loss=1.012895, lr=8.2e-05, time_each_step=0.16s, eta=10:23:53\n",
      "2021-12-24 04:07:32 [INFO]\t[TRAIN] Epoch=8/35, Step=995/7915, loss=0.676383, lr=8.1e-05, time_each_step=0.16s, eta=10:23:17\n",
      "2021-12-24 04:08:06 [INFO]\t[TRAIN] Epoch=8/35, Step=1195/7915, loss=0.168225, lr=8.1e-05, time_each_step=0.16s, eta=10:22:44\n",
      "2021-12-24 04:08:38 [INFO]\t[TRAIN] Epoch=8/35, Step=1395/7915, loss=0.761126, lr=8.1e-05, time_each_step=0.17s, eta=10:22:27\n",
      "2021-12-24 04:09:11 [INFO]\t[TRAIN] Epoch=8/35, Step=1595/7915, loss=0.252119, lr=8.1e-05, time_each_step=0.17s, eta=10:21:51\n",
      "2021-12-24 04:09:44 [INFO]\t[TRAIN] Epoch=8/35, Step=1795/7915, loss=0.523199, lr=8.1e-05, time_each_step=0.16s, eta=10:21:11\n",
      "2021-12-24 04:10:17 [INFO]\t[TRAIN] Epoch=8/35, Step=1995/7915, loss=0.931819, lr=8.1e-05, time_each_step=0.17s, eta=10:20:41\n",
      "2021-12-24 04:10:50 [INFO]\t[TRAIN] Epoch=8/35, Step=2195/7915, loss=0.819592, lr=8.1e-05, time_each_step=0.17s, eta=10:20:13\n",
      "2021-12-24 04:11:23 [INFO]\t[TRAIN] Epoch=8/35, Step=2395/7915, loss=0.451948, lr=8.1e-05, time_each_step=0.17s, eta=10:19:39\n",
      "2021-12-24 04:11:57 [INFO]\t[TRAIN] Epoch=8/35, Step=2595/7915, loss=1.140628, lr=8.1e-05, time_each_step=0.17s, eta=10:19:7\n",
      "2021-12-24 04:12:29 [INFO]\t[TRAIN] Epoch=8/35, Step=2795/7915, loss=0.3324, lr=8.1e-05, time_each_step=0.16s, eta=10:18:14\n",
      "2021-12-24 04:13:02 [INFO]\t[TRAIN] Epoch=8/35, Step=2995/7915, loss=0.320463, lr=8.1e-05, time_each_step=0.16s, eta=10:17:52\n",
      "2021-12-24 04:13:35 [INFO]\t[TRAIN] Epoch=8/35, Step=3195/7915, loss=0.689851, lr=8.1e-05, time_each_step=0.17s, eta=10:17:22\n",
      "2021-12-24 04:14:08 [INFO]\t[TRAIN] Epoch=8/35, Step=3395/7915, loss=1.137362, lr=8.1e-05, time_each_step=0.17s, eta=10:16:55\n",
      "2021-12-24 04:14:41 [INFO]\t[TRAIN] Epoch=8/35, Step=3595/7915, loss=0.686947, lr=8.1e-05, time_each_step=0.17s, eta=10:16:18\n",
      "2021-12-24 04:15:14 [INFO]\t[TRAIN] Epoch=8/35, Step=3795/7915, loss=0.733248, lr=8.1e-05, time_each_step=0.16s, eta=10:15:32\n",
      "2021-12-24 04:15:48 [INFO]\t[TRAIN] Epoch=8/35, Step=3995/7915, loss=0.262299, lr=8e-05, time_each_step=0.17s, eta=10:15:16\n",
      "2021-12-24 04:16:20 [INFO]\t[TRAIN] Epoch=8/35, Step=4195/7915, loss=1.076259, lr=8e-05, time_each_step=0.16s, eta=10:14:25\n",
      "2021-12-24 04:16:53 [INFO]\t[TRAIN] Epoch=8/35, Step=4395/7915, loss=0.941137, lr=8e-05, time_each_step=0.17s, eta=10:14:8\n",
      "2021-12-24 04:17:26 [INFO]\t[TRAIN] Epoch=8/35, Step=4595/7915, loss=0.860872, lr=8e-05, time_each_step=0.16s, eta=10:13:21\n",
      "2021-12-24 04:17:59 [INFO]\t[TRAIN] Epoch=8/35, Step=4795/7915, loss=0.658574, lr=8e-05, time_each_step=0.17s, eta=10:13:7\n",
      "2021-12-24 04:18:32 [INFO]\t[TRAIN] Epoch=8/35, Step=4995/7915, loss=0.660265, lr=8e-05, time_each_step=0.16s, eta=10:12:24\n",
      "2021-12-24 04:19:05 [INFO]\t[TRAIN] Epoch=8/35, Step=5195/7915, loss=0.556104, lr=8e-05, time_each_step=0.16s, eta=10:11:51\n",
      "2021-12-24 04:19:38 [INFO]\t[TRAIN] Epoch=8/35, Step=5395/7915, loss=0.77447, lr=8e-05, time_each_step=0.17s, eta=10:11:19\n",
      "2021-12-24 04:20:11 [INFO]\t[TRAIN] Epoch=8/35, Step=5595/7915, loss=0.988242, lr=8e-05, time_each_step=0.17s, eta=10:10:47\n",
      "2021-12-24 04:20:44 [INFO]\t[TRAIN] Epoch=8/35, Step=5795/7915, loss=0.618529, lr=8e-05, time_each_step=0.17s, eta=10:10:17\n",
      "2021-12-24 04:21:17 [INFO]\t[TRAIN] Epoch=8/35, Step=5995/7915, loss=0.609744, lr=8e-05, time_each_step=0.16s, eta=10:9:39\n",
      "2021-12-24 04:21:50 [INFO]\t[TRAIN] Epoch=8/35, Step=6195/7915, loss=0.762449, lr=8e-05, time_each_step=0.17s, eta=10:9:8\n",
      "2021-12-24 04:22:23 [INFO]\t[TRAIN] Epoch=8/35, Step=6395/7915, loss=0.58544, lr=8e-05, time_each_step=0.16s, eta=10:8:32\n",
      "2021-12-24 04:22:56 [INFO]\t[TRAIN] Epoch=8/35, Step=6595/7915, loss=0.588109, lr=8e-05, time_each_step=0.16s, eta=10:8:1\n",
      "2021-12-24 04:23:29 [INFO]\t[TRAIN] Epoch=8/35, Step=6795/7915, loss=0.980481, lr=8e-05, time_each_step=0.17s, eta=10:7:29\n",
      "2021-12-24 04:24:02 [INFO]\t[TRAIN] Epoch=8/35, Step=6995/7915, loss=0.711481, lr=7.9e-05, time_each_step=0.17s, eta=10:6:55\n",
      "2021-12-24 04:24:35 [INFO]\t[TRAIN] Epoch=8/35, Step=7195/7915, loss=0.603108, lr=7.9e-05, time_each_step=0.17s, eta=10:6:22\n",
      "2021-12-24 04:25:08 [INFO]\t[TRAIN] Epoch=8/35, Step=7395/7915, loss=0.885799, lr=7.9e-05, time_each_step=0.17s, eta=10:5:49\n",
      "2021-12-24 04:25:41 [INFO]\t[TRAIN] Epoch=8/35, Step=7595/7915, loss=0.852804, lr=7.9e-05, time_each_step=0.17s, eta=10:5:16\n",
      "2021-12-24 04:26:14 [INFO]\t[TRAIN] Epoch=8/35, Step=7795/7915, loss=0.618835, lr=7.9e-05, time_each_step=0.16s, eta=10:4:43\n",
      "2021-12-24 04:26:34 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.679254, lr=8e-05 .\n",
      "2021-12-24 04:26:34 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 04:26:57 [INFO]\t[EVAL] Finished, Epoch=8, miou=0.543425, category_iou=[0.55699106 0.73822    0.5264983  0.3519926 ], oacc=0.730261, category_acc=[0.65485602 0.83957845 0.74850721 0.60782742], kappa=0.623484, category_F1-score=[0.71547111 0.84939766 0.68981184 0.52070196] .\n",
      "2021-12-24 04:27:01 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 04:27:05 [INFO]\tModel saved in output/deeplab/epoch_8.\n",
      "2021-12-24 04:27:05 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_8, miou=0.5434254919308531\n",
      "2021-12-24 04:27:21 [INFO]\t[TRAIN] Epoch=9/35, Step=80/7915, loss=1.938525, lr=7.9e-05, time_each_step=0.16s, eta=10:2:10\n",
      "2021-12-24 04:27:54 [INFO]\t[TRAIN] Epoch=9/35, Step=280/7915, loss=0.784441, lr=7.9e-05, time_each_step=0.16s, eta=10:1:6\n",
      "2021-12-24 04:28:27 [INFO]\t[TRAIN] Epoch=9/35, Step=480/7915, loss=0.379827, lr=7.9e-05, time_each_step=0.17s, eta=10:1:14\n",
      "2021-12-24 04:28:59 [INFO]\t[TRAIN] Epoch=9/35, Step=680/7915, loss=0.351465, lr=7.9e-05, time_each_step=0.17s, eta=10:0:35\n",
      "2021-12-24 04:29:33 [INFO]\t[TRAIN] Epoch=9/35, Step=880/7915, loss=0.490246, lr=7.9e-05, time_each_step=0.16s, eta=10:0:1\n",
      "2021-12-24 04:30:06 [INFO]\t[TRAIN] Epoch=9/35, Step=1080/7915, loss=0.724052, lr=7.9e-05, time_each_step=0.17s, eta=9:59:38\n",
      "2021-12-24 04:30:39 [INFO]\t[TRAIN] Epoch=9/35, Step=1280/7915, loss=0.806751, lr=7.9e-05, time_each_step=0.17s, eta=9:59:3\n",
      "2021-12-24 04:31:12 [INFO]\t[TRAIN] Epoch=9/35, Step=1480/7915, loss=0.895235, lr=7.9e-05, time_each_step=0.16s, eta=9:58:18\n",
      "2021-12-24 04:31:45 [INFO]\t[TRAIN] Epoch=9/35, Step=1680/7915, loss=0.362278, lr=7.9e-05, time_each_step=0.16s, eta=9:57:36\n",
      "2021-12-24 04:32:17 [INFO]\t[TRAIN] Epoch=9/35, Step=1880/7915, loss=0.901188, lr=7.9e-05, time_each_step=0.16s, eta=9:57:1\n",
      "2021-12-24 04:32:51 [INFO]\t[TRAIN] Epoch=9/35, Step=2080/7915, loss=0.851372, lr=7.8e-05, time_each_step=0.17s, eta=9:56:47\n",
      "2021-12-24 04:33:24 [INFO]\t[TRAIN] Epoch=9/35, Step=2280/7915, loss=0.593947, lr=7.8e-05, time_each_step=0.17s, eta=9:56:21\n",
      "2021-12-24 04:33:57 [INFO]\t[TRAIN] Epoch=9/35, Step=2480/7915, loss=0.910158, lr=7.8e-05, time_each_step=0.17s, eta=9:55:41\n",
      "2021-12-24 04:34:30 [INFO]\t[TRAIN] Epoch=9/35, Step=2680/7915, loss=0.581695, lr=7.8e-05, time_each_step=0.17s, eta=9:55:6\n",
      "2021-12-24 04:35:03 [INFO]\t[TRAIN] Epoch=9/35, Step=2880/7915, loss=1.085325, lr=7.8e-05, time_each_step=0.17s, eta=9:54:32\n",
      "2021-12-24 04:35:36 [INFO]\t[TRAIN] Epoch=9/35, Step=3080/7915, loss=0.325411, lr=7.8e-05, time_each_step=0.17s, eta=9:54:0\n",
      "2021-12-24 04:36:09 [INFO]\t[TRAIN] Epoch=9/35, Step=3280/7915, loss=0.984165, lr=7.8e-05, time_each_step=0.16s, eta=9:53:22\n",
      "2021-12-24 04:36:42 [INFO]\t[TRAIN] Epoch=9/35, Step=3480/7915, loss=0.613585, lr=7.8e-05, time_each_step=0.16s, eta=9:52:46\n",
      "2021-12-24 04:37:15 [INFO]\t[TRAIN] Epoch=9/35, Step=3680/7915, loss=0.729055, lr=7.8e-05, time_each_step=0.16s, eta=9:52:19\n",
      "2021-12-24 04:37:48 [INFO]\t[TRAIN] Epoch=9/35, Step=3880/7915, loss=0.452408, lr=7.8e-05, time_each_step=0.17s, eta=9:51:56\n",
      "2021-12-24 04:38:21 [INFO]\t[TRAIN] Epoch=9/35, Step=4080/7915, loss=0.870502, lr=7.8e-05, time_each_step=0.16s, eta=9:51:12\n",
      "2021-12-24 04:38:53 [INFO]\t[TRAIN] Epoch=9/35, Step=4280/7915, loss=0.389015, lr=7.8e-05, time_each_step=0.16s, eta=9:50:38\n",
      "2021-12-24 04:39:27 [INFO]\t[TRAIN] Epoch=9/35, Step=4480/7915, loss=0.779825, lr=7.8e-05, time_each_step=0.17s, eta=9:50:15\n",
      "2021-12-24 04:40:00 [INFO]\t[TRAIN] Epoch=9/35, Step=4680/7915, loss=0.699302, lr=7.8e-05, time_each_step=0.17s, eta=9:49:41\n",
      "2021-12-24 04:40:33 [INFO]\t[TRAIN] Epoch=9/35, Step=4880/7915, loss=0.603913, lr=7.8e-05, time_each_step=0.16s, eta=9:48:57\n",
      "2021-12-24 04:41:06 [INFO]\t[TRAIN] Epoch=9/35, Step=5080/7915, loss=0.394125, lr=7.7e-05, time_each_step=0.17s, eta=9:48:34\n",
      "2021-12-24 04:41:39 [INFO]\t[TRAIN] Epoch=9/35, Step=5280/7915, loss=0.783048, lr=7.7e-05, time_each_step=0.17s, eta=9:47:58\n",
      "2021-12-24 04:42:12 [INFO]\t[TRAIN] Epoch=9/35, Step=5480/7915, loss=0.566598, lr=7.7e-05, time_each_step=0.16s, eta=9:47:21\n",
      "2021-12-24 04:42:45 [INFO]\t[TRAIN] Epoch=9/35, Step=5680/7915, loss=0.361697, lr=7.7e-05, time_each_step=0.17s, eta=9:46:54\n",
      "2021-12-24 04:43:18 [INFO]\t[TRAIN] Epoch=9/35, Step=5880/7915, loss=0.656003, lr=7.7e-05, time_each_step=0.16s, eta=9:46:14\n",
      "2021-12-24 04:43:51 [INFO]\t[TRAIN] Epoch=9/35, Step=6080/7915, loss=0.906338, lr=7.7e-05, time_each_step=0.17s, eta=9:45:48\n",
      "2021-12-24 04:44:23 [INFO]\t[TRAIN] Epoch=9/35, Step=6280/7915, loss=0.399209, lr=7.7e-05, time_each_step=0.16s, eta=9:45:7\n",
      "2021-12-24 04:44:56 [INFO]\t[TRAIN] Epoch=9/35, Step=6480/7915, loss=0.816482, lr=7.7e-05, time_each_step=0.17s, eta=9:44:40\n",
      "2021-12-24 04:45:29 [INFO]\t[TRAIN] Epoch=9/35, Step=6680/7915, loss=0.655716, lr=7.7e-05, time_each_step=0.16s, eta=9:44:2\n",
      "2021-12-24 04:46:02 [INFO]\t[TRAIN] Epoch=9/35, Step=6880/7915, loss=1.013555, lr=7.7e-05, time_each_step=0.17s, eta=9:43:32\n",
      "2021-12-24 04:46:35 [INFO]\t[TRAIN] Epoch=9/35, Step=7080/7915, loss=0.490359, lr=7.7e-05, time_each_step=0.16s, eta=9:42:56\n",
      "2021-12-24 04:47:08 [INFO]\t[TRAIN] Epoch=9/35, Step=7280/7915, loss=0.625169, lr=7.7e-05, time_each_step=0.17s, eta=9:42:27\n",
      "2021-12-24 04:47:41 [INFO]\t[TRAIN] Epoch=9/35, Step=7480/7915, loss=1.243693, lr=7.7e-05, time_each_step=0.17s, eta=9:41:53\n",
      "2021-12-24 04:48:14 [INFO]\t[TRAIN] Epoch=9/35, Step=7680/7915, loss=0.646283, lr=7.7e-05, time_each_step=0.16s, eta=9:41:20\n",
      "2021-12-24 04:48:47 [INFO]\t[TRAIN] Epoch=9/35, Step=7880/7915, loss=0.657237, lr=7.7e-05, time_each_step=0.16s, eta=9:40:47\n",
      "2021-12-24 04:48:52 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.662036, lr=7.8e-05 .\n",
      "2021-12-24 04:48:52 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 04:49:16 [INFO]\t[EVAL] Finished, Epoch=9, miou=0.547547, category_iou=[0.55144399 0.73292035 0.53875098 0.3670711 ], oacc=0.727198, category_acc=[0.68163513 0.8535446  0.73624808 0.54283493], kappa=0.622826, category_F1-score=[0.71087837 0.84587887 0.70024453 0.5370183 ] .\n",
      "2021-12-24 04:49:20 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 04:49:23 [INFO]\tModel saved in output/deeplab/epoch_9.\n",
      "2021-12-24 04:49:23 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_9, miou=0.547546603589981\n",
      "2021-12-24 04:49:53 [INFO]\t[TRAIN] Epoch=10/35, Step=165/7915, loss=0.492474, lr=7.6e-05, time_each_step=0.16s, eta=9:39:21\n",
      "2021-12-24 04:50:26 [INFO]\t[TRAIN] Epoch=10/35, Step=365/7915, loss=0.64784, lr=7.6e-05, time_each_step=0.17s, eta=9:39:4\n",
      "2021-12-24 04:50:59 [INFO]\t[TRAIN] Epoch=10/35, Step=565/7915, loss=0.654874, lr=7.6e-05, time_each_step=0.16s, eta=9:38:21\n",
      "2021-12-24 04:51:32 [INFO]\t[TRAIN] Epoch=10/35, Step=765/7915, loss=0.949981, lr=7.6e-05, time_each_step=0.16s, eta=9:37:48\n",
      "2021-12-24 04:52:05 [INFO]\t[TRAIN] Epoch=10/35, Step=965/7915, loss=0.270126, lr=7.6e-05, time_each_step=0.16s, eta=9:37:15\n",
      "2021-12-24 04:52:38 [INFO]\t[TRAIN] Epoch=10/35, Step=1165/7915, loss=1.060606, lr=7.6e-05, time_each_step=0.17s, eta=9:36:55\n",
      "2021-12-24 04:53:11 [INFO]\t[TRAIN] Epoch=10/35, Step=1365/7915, loss=0.347833, lr=7.6e-05, time_each_step=0.16s, eta=9:35:58\n",
      "2021-12-24 04:53:43 [INFO]\t[TRAIN] Epoch=10/35, Step=1565/7915, loss=1.025368, lr=7.6e-05, time_each_step=0.17s, eta=9:35:46\n",
      "2021-12-24 04:54:16 [INFO]\t[TRAIN] Epoch=10/35, Step=1765/7915, loss=0.721618, lr=7.6e-05, time_each_step=0.16s, eta=9:34:59\n",
      "2021-12-24 04:54:49 [INFO]\t[TRAIN] Epoch=10/35, Step=1965/7915, loss=0.663202, lr=7.6e-05, time_each_step=0.17s, eta=9:34:54\n",
      "2021-12-24 04:55:22 [INFO]\t[TRAIN] Epoch=10/35, Step=2165/7915, loss=1.316761, lr=7.6e-05, time_each_step=0.16s, eta=9:33:51\n",
      "2021-12-24 04:55:55 [INFO]\t[TRAIN] Epoch=10/35, Step=2365/7915, loss=0.630272, lr=7.6e-05, time_each_step=0.17s, eta=9:33:38\n",
      "2021-12-24 04:56:28 [INFO]\t[TRAIN] Epoch=10/35, Step=2565/7915, loss=2.337482, lr=7.6e-05, time_each_step=0.17s, eta=9:33:11\n",
      "2021-12-24 04:57:02 [INFO]\t[TRAIN] Epoch=10/35, Step=2765/7915, loss=0.753348, lr=7.6e-05, time_each_step=0.17s, eta=9:32:31\n",
      "2021-12-24 04:57:34 [INFO]\t[TRAIN] Epoch=10/35, Step=2965/7915, loss=0.634847, lr=7.6e-05, time_each_step=0.16s, eta=9:31:48\n",
      "2021-12-24 04:58:07 [INFO]\t[TRAIN] Epoch=10/35, Step=3165/7915, loss=0.774539, lr=7.5e-05, time_each_step=0.17s, eta=9:31:21\n",
      "2021-12-24 04:58:40 [INFO]\t[TRAIN] Epoch=10/35, Step=3365/7915, loss=0.53444, lr=7.5e-05, time_each_step=0.16s, eta=9:30:38\n",
      "2021-12-24 04:59:13 [INFO]\t[TRAIN] Epoch=10/35, Step=3565/7915, loss=0.596964, lr=7.5e-05, time_each_step=0.16s, eta=9:30:4\n",
      "2021-12-24 04:59:46 [INFO]\t[TRAIN] Epoch=10/35, Step=3765/7915, loss=0.367444, lr=7.5e-05, time_each_step=0.16s, eta=9:29:30\n",
      "2021-12-24 05:00:19 [INFO]\t[TRAIN] Epoch=10/35, Step=3965/7915, loss=0.699002, lr=7.5e-05, time_each_step=0.17s, eta=9:29:15\n",
      "2021-12-24 05:00:52 [INFO]\t[TRAIN] Epoch=10/35, Step=4165/7915, loss=0.604886, lr=7.5e-05, time_each_step=0.16s, eta=9:28:22\n",
      "2021-12-24 05:01:25 [INFO]\t[TRAIN] Epoch=10/35, Step=4365/7915, loss=1.032509, lr=7.5e-05, time_each_step=0.17s, eta=9:28:8\n",
      "2021-12-24 05:01:58 [INFO]\t[TRAIN] Epoch=10/35, Step=4565/7915, loss=0.518814, lr=7.5e-05, time_each_step=0.17s, eta=9:27:30\n",
      "2021-12-24 05:02:31 [INFO]\t[TRAIN] Epoch=10/35, Step=4765/7915, loss=1.186089, lr=7.5e-05, time_each_step=0.17s, eta=9:27:3\n",
      "2021-12-24 05:03:04 [INFO]\t[TRAIN] Epoch=10/35, Step=4965/7915, loss=0.609169, lr=7.5e-05, time_each_step=0.17s, eta=9:26:22\n",
      "2021-12-24 05:03:37 [INFO]\t[TRAIN] Epoch=10/35, Step=5165/7915, loss=0.845354, lr=7.5e-05, time_each_step=0.17s, eta=9:25:53\n",
      "2021-12-24 05:04:10 [INFO]\t[TRAIN] Epoch=10/35, Step=5365/7915, loss=0.352202, lr=7.5e-05, time_each_step=0.17s, eta=9:25:19\n",
      "2021-12-24 05:04:43 [INFO]\t[TRAIN] Epoch=10/35, Step=5565/7915, loss=0.586998, lr=7.5e-05, time_each_step=0.16s, eta=9:24:42\n",
      "2021-12-24 05:05:16 [INFO]\t[TRAIN] Epoch=10/35, Step=5765/7915, loss=0.443189, lr=7.5e-05, time_each_step=0.16s, eta=9:24:8\n",
      "2021-12-24 05:05:49 [INFO]\t[TRAIN] Epoch=10/35, Step=5965/7915, loss=0.959231, lr=7.5e-05, time_each_step=0.16s, eta=9:23:36\n",
      "2021-12-24 05:06:22 [INFO]\t[TRAIN] Epoch=10/35, Step=6165/7915, loss=0.395835, lr=7.4e-05, time_each_step=0.16s, eta=9:23:1\n",
      "2021-12-24 05:06:55 [INFO]\t[TRAIN] Epoch=10/35, Step=6365/7915, loss=0.715027, lr=7.4e-05, time_each_step=0.16s, eta=9:22:30\n",
      "2021-12-24 05:07:28 [INFO]\t[TRAIN] Epoch=10/35, Step=6565/7915, loss=0.846963, lr=7.4e-05, time_each_step=0.17s, eta=9:22:1\n",
      "2021-12-24 05:08:01 [INFO]\t[TRAIN] Epoch=10/35, Step=6765/7915, loss=0.661094, lr=7.4e-05, time_each_step=0.17s, eta=9:21:26\n",
      "2021-12-24 05:08:34 [INFO]\t[TRAIN] Epoch=10/35, Step=6965/7915, loss=0.600623, lr=7.4e-05, time_each_step=0.16s, eta=9:20:52\n",
      "2021-12-24 05:09:07 [INFO]\t[TRAIN] Epoch=10/35, Step=7165/7915, loss=0.813816, lr=7.4e-05, time_each_step=0.17s, eta=9:20:22\n",
      "2021-12-24 05:09:41 [INFO]\t[TRAIN] Epoch=10/35, Step=7365/7915, loss=0.39796, lr=7.4e-05, time_each_step=0.17s, eta=9:19:46\n",
      "2021-12-24 05:10:14 [INFO]\t[TRAIN] Epoch=10/35, Step=7565/7915, loss=0.588854, lr=7.4e-05, time_each_step=0.16s, eta=9:19:13\n",
      "2021-12-24 05:10:46 [INFO]\t[TRAIN] Epoch=10/35, Step=7765/7915, loss=0.485157, lr=7.4e-05, time_each_step=0.17s, eta=9:18:40\n",
      "2021-12-24 05:11:11 [INFO]\t[TRAIN] Epoch 10 finished, loss=0.633832, lr=7.5e-05 .\n",
      "2021-12-24 05:11:11 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 05:11:34 [INFO]\t[EVAL] Finished, Epoch=10, miou=0.548439, category_iou=[0.55325247 0.73346331 0.53740686 0.36963324], oacc=0.730679, category_acc=[0.68823133 0.83224969 0.72862679 0.5751308 ], kappa=0.626191, category_F1-score=[0.71237932 0.84624036 0.69910819 0.53975506] .\n",
      "2021-12-24 05:11:38 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 05:11:42 [INFO]\tModel saved in output/deeplab/epoch_10.\n",
      "2021-12-24 05:11:42 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_10, miou=0.5484389713830214\n",
      "2021-12-24 05:11:53 [INFO]\t[TRAIN] Epoch=11/35, Step=50/7915, loss=0.732247, lr=7.4e-05, time_each_step=0.16s, eta=9:17:27\n",
      "2021-12-24 05:12:26 [INFO]\t[TRAIN] Epoch=11/35, Step=250/7915, loss=0.435911, lr=7.4e-05, time_each_step=0.16s, eta=9:16:54\n",
      "2021-12-24 05:12:59 [INFO]\t[TRAIN] Epoch=11/35, Step=450/7915, loss=0.504459, lr=7.4e-05, time_each_step=0.16s, eta=9:16:28\n",
      "2021-12-24 05:13:32 [INFO]\t[TRAIN] Epoch=11/35, Step=650/7915, loss=0.768225, lr=7.4e-05, time_each_step=0.16s, eta=9:15:39\n",
      "2021-12-24 05:14:05 [INFO]\t[TRAIN] Epoch=11/35, Step=850/7915, loss=0.372078, lr=7.4e-05, time_each_step=0.16s, eta=9:15:23\n",
      "2021-12-24 05:14:37 [INFO]\t[TRAIN] Epoch=11/35, Step=1050/7915, loss=0.67933, lr=7.4e-05, time_each_step=0.16s, eta=9:14:46\n",
      "2021-12-24 05:15:10 [INFO]\t[TRAIN] Epoch=11/35, Step=1250/7915, loss=0.805081, lr=7.3e-05, time_each_step=0.17s, eta=9:14:25\n",
      "2021-12-24 05:15:43 [INFO]\t[TRAIN] Epoch=11/35, Step=1450/7915, loss=0.34356, lr=7.3e-05, time_each_step=0.16s, eta=9:13:35\n",
      "2021-12-24 05:16:16 [INFO]\t[TRAIN] Epoch=11/35, Step=1650/7915, loss=0.192417, lr=7.3e-05, time_each_step=0.16s, eta=9:12:57\n",
      "2021-12-24 05:16:49 [INFO]\t[TRAIN] Epoch=11/35, Step=1850/7915, loss=1.664767, lr=7.3e-05, time_each_step=0.16s, eta=9:12:22\n",
      "2021-12-24 05:17:22 [INFO]\t[TRAIN] Epoch=11/35, Step=2050/7915, loss=1.069326, lr=7.3e-05, time_each_step=0.16s, eta=9:12:5\n",
      "2021-12-24 05:17:55 [INFO]\t[TRAIN] Epoch=11/35, Step=2250/7915, loss=0.134382, lr=7.3e-05, time_each_step=0.16s, eta=9:11:27\n",
      "2021-12-24 05:18:28 [INFO]\t[TRAIN] Epoch=11/35, Step=2450/7915, loss=0.785002, lr=7.3e-05, time_each_step=0.17s, eta=9:11:17\n",
      "2021-12-24 05:19:01 [INFO]\t[TRAIN] Epoch=11/35, Step=2650/7915, loss=0.489736, lr=7.3e-05, time_each_step=0.17s, eta=9:10:29\n",
      "2021-12-24 05:19:34 [INFO]\t[TRAIN] Epoch=11/35, Step=2850/7915, loss=0.497819, lr=7.3e-05, time_each_step=0.17s, eta=9:9:56\n",
      "2021-12-24 05:20:07 [INFO]\t[TRAIN] Epoch=11/35, Step=3050/7915, loss=0.254576, lr=7.3e-05, time_each_step=0.16s, eta=9:9:18\n",
      "2021-12-24 05:20:40 [INFO]\t[TRAIN] Epoch=11/35, Step=3250/7915, loss=0.500797, lr=7.3e-05, time_each_step=0.16s, eta=9:8:48\n",
      "2021-12-24 05:21:13 [INFO]\t[TRAIN] Epoch=11/35, Step=3450/7915, loss=0.856403, lr=7.3e-05, time_each_step=0.17s, eta=9:8:16\n",
      "2021-12-24 05:21:45 [INFO]\t[TRAIN] Epoch=11/35, Step=3650/7915, loss=0.66492, lr=7.3e-05, time_each_step=0.17s, eta=9:7:47\n",
      "2021-12-24 05:22:18 [INFO]\t[TRAIN] Epoch=11/35, Step=3850/7915, loss=0.400965, lr=7.3e-05, time_each_step=0.17s, eta=9:7:15\n",
      "2021-12-24 05:22:51 [INFO]\t[TRAIN] Epoch=11/35, Step=4050/7915, loss=0.405253, lr=7.3e-05, time_each_step=0.16s, eta=9:6:25\n",
      "2021-12-24 05:23:24 [INFO]\t[TRAIN] Epoch=11/35, Step=4250/7915, loss=1.500209, lr=7.2e-05, time_each_step=0.17s, eta=9:6:5\n",
      "2021-12-24 05:23:57 [INFO]\t[TRAIN] Epoch=11/35, Step=4450/7915, loss=0.279056, lr=7.2e-05, time_each_step=0.17s, eta=9:5:40\n",
      "2021-12-24 05:24:30 [INFO]\t[TRAIN] Epoch=11/35, Step=4650/7915, loss=0.521787, lr=7.2e-05, time_each_step=0.17s, eta=9:4:59\n",
      "2021-12-24 05:25:03 [INFO]\t[TRAIN] Epoch=11/35, Step=4850/7915, loss=0.688833, lr=7.2e-05, time_each_step=0.17s, eta=9:4:30\n",
      "2021-12-24 05:25:36 [INFO]\t[TRAIN] Epoch=11/35, Step=5050/7915, loss=0.09904, lr=7.2e-05, time_each_step=0.17s, eta=9:3:55\n",
      "2021-12-24 05:26:09 [INFO]\t[TRAIN] Epoch=11/35, Step=5250/7915, loss=0.474349, lr=7.2e-05, time_each_step=0.17s, eta=9:3:19\n",
      "2021-12-24 05:26:42 [INFO]\t[TRAIN] Epoch=11/35, Step=5450/7915, loss=0.276706, lr=7.2e-05, time_each_step=0.16s, eta=9:2:43\n",
      "2021-12-24 05:27:15 [INFO]\t[TRAIN] Epoch=11/35, Step=5650/7915, loss=0.901989, lr=7.2e-05, time_each_step=0.17s, eta=9:2:18\n",
      "2021-12-24 05:27:48 [INFO]\t[TRAIN] Epoch=11/35, Step=5850/7915, loss=0.961536, lr=7.2e-05, time_each_step=0.16s, eta=9:1:38\n",
      "2021-12-24 05:28:21 [INFO]\t[TRAIN] Epoch=11/35, Step=6050/7915, loss=0.542329, lr=7.2e-05, time_each_step=0.16s, eta=9:1:5\n",
      "2021-12-24 05:28:54 [INFO]\t[TRAIN] Epoch=11/35, Step=6250/7915, loss=0.75731, lr=7.2e-05, time_each_step=0.17s, eta=9:0:34\n",
      "2021-12-24 05:29:27 [INFO]\t[TRAIN] Epoch=11/35, Step=6450/7915, loss=0.560574, lr=7.2e-05, time_each_step=0.16s, eta=9:0:0\n",
      "2021-12-24 05:30:00 [INFO]\t[TRAIN] Epoch=11/35, Step=6650/7915, loss=0.453002, lr=7.2e-05, time_each_step=0.17s, eta=8:59:30\n",
      "2021-12-24 05:30:33 [INFO]\t[TRAIN] Epoch=11/35, Step=6850/7915, loss=0.517489, lr=7.2e-05, time_each_step=0.16s, eta=8:58:53\n",
      "2021-12-24 05:31:06 [INFO]\t[TRAIN] Epoch=11/35, Step=7050/7915, loss=0.346293, lr=7.2e-05, time_each_step=0.17s, eta=8:58:23\n",
      "2021-12-24 05:31:39 [INFO]\t[TRAIN] Epoch=11/35, Step=7250/7915, loss=1.204539, lr=7.1e-05, time_each_step=0.17s, eta=8:57:49\n",
      "2021-12-24 05:32:13 [INFO]\t[TRAIN] Epoch=11/35, Step=7450/7915, loss=0.6347, lr=7.1e-05, time_each_step=0.16s, eta=8:57:15\n",
      "2021-12-24 05:32:45 [INFO]\t[TRAIN] Epoch=11/35, Step=7650/7915, loss=0.46837, lr=7.1e-05, time_each_step=0.16s, eta=8:56:42\n",
      "2021-12-24 05:33:18 [INFO]\t[TRAIN] Epoch=11/35, Step=7850/7915, loss=0.515496, lr=7.1e-05, time_each_step=0.16s, eta=8:56:10\n",
      "2021-12-24 05:33:29 [INFO]\t[TRAIN] Epoch 11 finished, loss=0.623357, lr=7.3e-05 .\n",
      "2021-12-24 05:33:29 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 05:33:52 [INFO]\t[EVAL] Finished, Epoch=11, miou=0.473357, category_iou=[0.5033286  0.63350236 0.47506536 0.28153246], oacc=0.673941, category_acc=[0.67489723 0.70279736 0.70081639 0.53272642], kappa=0.541338, category_F1-score=[0.66961887 0.77563691 0.64412788 0.43936844] .\n",
      "2021-12-24 05:33:56 [INFO]\tModel saved in output/deeplab/epoch_11.\n",
      "2021-12-24 05:33:56 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_10, miou=0.5484389713830214\n",
      "2021-12-24 05:34:21 [INFO]\t[TRAIN] Epoch=12/35, Step=135/7915, loss=0.817203, lr=7.1e-05, time_each_step=0.16s, eta=8:52:49\n",
      "2021-12-24 05:34:54 [INFO]\t[TRAIN] Epoch=12/35, Step=335/7915, loss=0.251348, lr=7.1e-05, time_each_step=0.16s, eta=8:52:26\n",
      "2021-12-24 05:35:27 [INFO]\t[TRAIN] Epoch=12/35, Step=535/7915, loss=0.600185, lr=7.1e-05, time_each_step=0.16s, eta=8:51:49\n",
      "2021-12-24 05:36:00 [INFO]\t[TRAIN] Epoch=12/35, Step=735/7915, loss=0.391302, lr=7.1e-05, time_each_step=0.17s, eta=8:51:35\n",
      "2021-12-24 05:36:33 [INFO]\t[TRAIN] Epoch=12/35, Step=935/7915, loss=0.397449, lr=7.1e-05, time_each_step=0.16s, eta=8:50:55\n",
      "2021-12-24 05:37:06 [INFO]\t[TRAIN] Epoch=12/35, Step=1135/7915, loss=0.858555, lr=7.1e-05, time_each_step=0.17s, eta=8:50:40\n",
      "2021-12-24 05:37:39 [INFO]\t[TRAIN] Epoch=12/35, Step=1335/7915, loss=0.571768, lr=7.1e-05, time_each_step=0.16s, eta=8:49:29\n",
      "2021-12-24 05:38:11 [INFO]\t[TRAIN] Epoch=12/35, Step=1535/7915, loss=0.797023, lr=7.1e-05, time_each_step=0.17s, eta=8:49:20\n",
      "2021-12-24 05:38:44 [INFO]\t[TRAIN] Epoch=12/35, Step=1735/7915, loss=1.136237, lr=7.1e-05, time_each_step=0.16s, eta=8:48:40\n",
      "2021-12-24 05:39:17 [INFO]\t[TRAIN] Epoch=12/35, Step=1935/7915, loss=0.311644, lr=7.1e-05, time_each_step=0.17s, eta=8:48:15\n",
      "2021-12-24 05:39:50 [INFO]\t[TRAIN] Epoch=12/35, Step=2135/7915, loss=0.393105, lr=7e-05, time_each_step=0.16s, eta=8:47:27\n",
      "2021-12-24 05:40:23 [INFO]\t[TRAIN] Epoch=12/35, Step=2335/7915, loss=0.38751, lr=7e-05, time_each_step=0.16s, eta=8:46:58\n",
      "2021-12-24 05:40:57 [INFO]\t[TRAIN] Epoch=12/35, Step=2535/7915, loss=0.393703, lr=7e-05, time_each_step=0.17s, eta=8:46:34\n",
      "2021-12-24 05:41:30 [INFO]\t[TRAIN] Epoch=12/35, Step=2735/7915, loss=2.221694, lr=7e-05, time_each_step=0.16s, eta=8:45:58\n",
      "2021-12-24 05:42:02 [INFO]\t[TRAIN] Epoch=12/35, Step=2935/7915, loss=0.678703, lr=7e-05, time_each_step=0.16s, eta=8:45:10\n",
      "2021-12-24 05:42:35 [INFO]\t[TRAIN] Epoch=12/35, Step=3135/7915, loss=0.751961, lr=7e-05, time_each_step=0.16s, eta=8:44:42\n",
      "2021-12-24 05:43:08 [INFO]\t[TRAIN] Epoch=12/35, Step=3335/7915, loss=0.507402, lr=7e-05, time_each_step=0.17s, eta=8:44:24\n",
      "2021-12-24 05:43:41 [INFO]\t[TRAIN] Epoch=12/35, Step=3535/7915, loss=0.128353, lr=7e-05, time_each_step=0.16s, eta=8:43:43\n",
      "2021-12-24 05:44:14 [INFO]\t[TRAIN] Epoch=12/35, Step=3735/7915, loss=0.44392, lr=7e-05, time_each_step=0.17s, eta=8:43:26\n",
      "2021-12-24 05:44:47 [INFO]\t[TRAIN] Epoch=12/35, Step=3935/7915, loss=0.666263, lr=7e-05, time_each_step=0.17s, eta=8:42:44\n",
      "2021-12-24 05:45:20 [INFO]\t[TRAIN] Epoch=12/35, Step=4135/7915, loss=0.829202, lr=7e-05, time_each_step=0.17s, eta=8:42:12\n",
      "2021-12-24 05:45:53 [INFO]\t[TRAIN] Epoch=12/35, Step=4335/7915, loss=0.748992, lr=7e-05, time_each_step=0.16s, eta=8:41:26\n",
      "2021-12-24 05:46:26 [INFO]\t[TRAIN] Epoch=12/35, Step=4535/7915, loss=0.21653, lr=7e-05, time_each_step=0.17s, eta=8:41:7\n",
      "2021-12-24 05:46:59 [INFO]\t[TRAIN] Epoch=12/35, Step=4735/7915, loss=1.208518, lr=7e-05, time_each_step=0.17s, eta=8:40:33\n",
      "2021-12-24 05:47:32 [INFO]\t[TRAIN] Epoch=12/35, Step=4935/7915, loss=0.279931, lr=7e-05, time_each_step=0.16s, eta=8:39:54\n",
      "2021-12-24 05:48:05 [INFO]\t[TRAIN] Epoch=12/35, Step=5135/7915, loss=0.459534, lr=6.9e-05, time_each_step=0.16s, eta=8:39:23\n",
      "2021-12-24 05:48:38 [INFO]\t[TRAIN] Epoch=12/35, Step=5335/7915, loss=0.703638, lr=6.9e-05, time_each_step=0.17s, eta=8:38:52\n",
      "2021-12-24 05:49:11 [INFO]\t[TRAIN] Epoch=12/35, Step=5535/7915, loss=0.835901, lr=6.9e-05, time_each_step=0.16s, eta=8:38:14\n",
      "2021-12-24 05:49:44 [INFO]\t[TRAIN] Epoch=12/35, Step=5735/7915, loss=0.64265, lr=6.9e-05, time_each_step=0.16s, eta=8:37:43\n",
      "2021-12-24 05:50:17 [INFO]\t[TRAIN] Epoch=12/35, Step=5935/7915, loss=0.479998, lr=6.9e-05, time_each_step=0.17s, eta=8:37:16\n",
      "2021-12-24 05:50:50 [INFO]\t[TRAIN] Epoch=12/35, Step=6135/7915, loss=0.114077, lr=6.9e-05, time_each_step=0.16s, eta=8:36:37\n",
      "2021-12-24 05:51:23 [INFO]\t[TRAIN] Epoch=12/35, Step=6335/7915, loss=0.627856, lr=6.9e-05, time_each_step=0.16s, eta=8:36:3\n",
      "2021-12-24 05:51:56 [INFO]\t[TRAIN] Epoch=12/35, Step=6535/7915, loss=0.414756, lr=6.9e-05, time_each_step=0.17s, eta=8:35:35\n",
      "2021-12-24 05:52:29 [INFO]\t[TRAIN] Epoch=12/35, Step=6735/7915, loss=0.69418, lr=6.9e-05, time_each_step=0.16s, eta=8:34:59\n",
      "2021-12-24 05:53:02 [INFO]\t[TRAIN] Epoch=12/35, Step=6935/7915, loss=0.568888, lr=6.9e-05, time_each_step=0.17s, eta=8:34:28\n",
      "2021-12-24 05:53:35 [INFO]\t[TRAIN] Epoch=12/35, Step=7135/7915, loss=0.542565, lr=6.9e-05, time_each_step=0.17s, eta=8:33:56\n",
      "2021-12-24 05:54:08 [INFO]\t[TRAIN] Epoch=12/35, Step=7335/7915, loss=1.262888, lr=6.9e-05, time_each_step=0.17s, eta=8:33:22\n",
      "2021-12-24 05:54:41 [INFO]\t[TRAIN] Epoch=12/35, Step=7535/7915, loss=0.511322, lr=6.9e-05, time_each_step=0.16s, eta=8:32:48\n",
      "2021-12-24 05:55:14 [INFO]\t[TRAIN] Epoch=12/35, Step=7735/7915, loss=0.307112, lr=6.9e-05, time_each_step=0.16s, eta=8:32:15\n",
      "2021-12-24 05:55:43 [INFO]\t[TRAIN] Epoch 12 finished, loss=0.59929, lr=7e-05 .\n",
      "2021-12-24 05:55:43 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 05:56:07 [INFO]\t[EVAL] Finished, Epoch=12, miou=0.557781, category_iou=[0.56165379 0.74672705 0.55537011 0.36737173], oacc=0.738118, category_acc=[0.67143564 0.85901229 0.73756121 0.59713979], kappa=0.636443, category_F1-score=[0.71930641 0.85500142 0.71413242 0.53733995] .\n",
      "2021-12-24 05:56:11 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 05:56:14 [INFO]\tModel saved in output/deeplab/epoch_12.\n",
      "2021-12-24 05:56:14 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.5577806704097794\n",
      "2021-12-24 05:56:21 [INFO]\t[TRAIN] Epoch=13/35, Step=20/7915, loss=0.416568, lr=6.9e-05, time_each_step=0.32s, eta=8:53:5\n",
      "2021-12-24 05:56:53 [INFO]\t[TRAIN] Epoch=13/35, Step=220/7915, loss=0.372178, lr=6.8e-05, time_each_step=0.17s, eta=8:32:27\n",
      "2021-12-24 05:57:26 [INFO]\t[TRAIN] Epoch=13/35, Step=420/7915, loss=0.826123, lr=6.8e-05, time_each_step=0.16s, eta=8:31:48\n",
      "2021-12-24 05:57:59 [INFO]\t[TRAIN] Epoch=13/35, Step=620/7915, loss=0.705464, lr=6.8e-05, time_each_step=0.17s, eta=8:31:20\n",
      "2021-12-24 05:58:32 [INFO]\t[TRAIN] Epoch=13/35, Step=820/7915, loss=1.13305, lr=6.8e-05, time_each_step=0.16s, eta=8:30:39\n",
      "2021-12-24 05:59:05 [INFO]\t[TRAIN] Epoch=13/35, Step=1020/7915, loss=0.43592, lr=6.8e-05, time_each_step=0.16s, eta=8:30:4\n",
      "2021-12-24 05:59:38 [INFO]\t[TRAIN] Epoch=13/35, Step=1220/7915, loss=0.689001, lr=6.8e-05, time_each_step=0.16s, eta=8:29:22\n",
      "2021-12-24 06:00:11 [INFO]\t[TRAIN] Epoch=13/35, Step=1420/7915, loss=0.412309, lr=6.8e-05, time_each_step=0.17s, eta=8:29:13\n",
      "2021-12-24 06:00:43 [INFO]\t[TRAIN] Epoch=13/35, Step=1620/7915, loss=0.248546, lr=6.8e-05, time_each_step=0.17s, eta=8:28:47\n",
      "2021-12-24 06:01:16 [INFO]\t[TRAIN] Epoch=13/35, Step=1820/7915, loss=0.51217, lr=6.8e-05, time_each_step=0.17s, eta=8:28:12\n",
      "2021-12-24 06:01:49 [INFO]\t[TRAIN] Epoch=13/35, Step=2020/7915, loss=0.47196, lr=6.8e-05, time_each_step=0.16s, eta=8:27:21\n",
      "2021-12-24 06:02:22 [INFO]\t[TRAIN] Epoch=13/35, Step=2220/7915, loss=0.546005, lr=6.8e-05, time_each_step=0.16s, eta=8:26:45\n",
      "2021-12-24 06:02:55 [INFO]\t[TRAIN] Epoch=13/35, Step=2420/7915, loss=0.832142, lr=6.8e-05, time_each_step=0.17s, eta=8:26:24\n",
      "2021-12-24 06:03:28 [INFO]\t[TRAIN] Epoch=13/35, Step=2620/7915, loss=0.527039, lr=6.8e-05, time_each_step=0.16s, eta=8:25:47\n",
      "2021-12-24 06:04:01 [INFO]\t[TRAIN] Epoch=13/35, Step=2820/7915, loss=0.389209, lr=6.8e-05, time_each_step=0.17s, eta=8:25:22\n",
      "2021-12-24 06:04:34 [INFO]\t[TRAIN] Epoch=13/35, Step=3020/7915, loss=0.227063, lr=6.8e-05, time_each_step=0.17s, eta=8:24:53\n",
      "2021-12-24 06:05:07 [INFO]\t[TRAIN] Epoch=13/35, Step=3220/7915, loss=0.636873, lr=6.7e-05, time_each_step=0.17s, eta=8:24:11\n",
      "2021-12-24 06:05:40 [INFO]\t[TRAIN] Epoch=13/35, Step=3420/7915, loss=0.258177, lr=6.7e-05, time_each_step=0.17s, eta=8:23:38\n",
      "2021-12-24 06:06:13 [INFO]\t[TRAIN] Epoch=13/35, Step=3620/7915, loss=0.378038, lr=6.7e-05, time_each_step=0.16s, eta=8:23:2\n",
      "2021-12-24 06:06:46 [INFO]\t[TRAIN] Epoch=13/35, Step=3820/7915, loss=0.676675, lr=6.7e-05, time_each_step=0.16s, eta=8:22:29\n",
      "2021-12-24 06:07:20 [INFO]\t[TRAIN] Epoch=13/35, Step=4020/7915, loss=0.21116, lr=6.7e-05, time_each_step=0.16s, eta=8:21:50\n",
      "2021-12-24 06:07:52 [INFO]\t[TRAIN] Epoch=13/35, Step=4220/7915, loss=1.080108, lr=6.7e-05, time_each_step=0.16s, eta=8:21:24\n",
      "2021-12-24 06:08:26 [INFO]\t[TRAIN] Epoch=13/35, Step=4420/7915, loss=0.457319, lr=6.7e-05, time_each_step=0.17s, eta=8:20:56\n",
      "2021-12-24 06:08:58 [INFO]\t[TRAIN] Epoch=13/35, Step=4620/7915, loss=0.162603, lr=6.7e-05, time_each_step=0.16s, eta=8:20:16\n",
      "2021-12-24 06:09:31 [INFO]\t[TRAIN] Epoch=13/35, Step=4820/7915, loss=0.409567, lr=6.7e-05, time_each_step=0.16s, eta=8:19:43\n",
      "2021-12-24 06:10:04 [INFO]\t[TRAIN] Epoch=13/35, Step=5020/7915, loss=0.54439, lr=6.7e-05, time_each_step=0.17s, eta=8:19:16\n",
      "2021-12-24 06:10:37 [INFO]\t[TRAIN] Epoch=13/35, Step=5220/7915, loss=0.116552, lr=6.7e-05, time_each_step=0.17s, eta=8:18:42\n",
      "2021-12-24 06:11:10 [INFO]\t[TRAIN] Epoch=13/35, Step=5420/7915, loss=0.319133, lr=6.7e-05, time_each_step=0.17s, eta=8:18:11\n",
      "2021-12-24 06:11:43 [INFO]\t[TRAIN] Epoch=13/35, Step=5620/7915, loss=0.646226, lr=6.7e-05, time_each_step=0.17s, eta=8:17:37\n",
      "2021-12-24 06:12:17 [INFO]\t[TRAIN] Epoch=13/35, Step=5820/7915, loss=0.489039, lr=6.7e-05, time_each_step=0.17s, eta=8:17:8\n",
      "2021-12-24 06:12:50 [INFO]\t[TRAIN] Epoch=13/35, Step=6020/7915, loss=0.822009, lr=6.6e-05, time_each_step=0.16s, eta=8:16:20\n",
      "2021-12-24 06:13:23 [INFO]\t[TRAIN] Epoch=13/35, Step=6220/7915, loss=0.818462, lr=6.6e-05, time_each_step=0.17s, eta=8:15:57\n",
      "2021-12-24 06:13:56 [INFO]\t[TRAIN] Epoch=13/35, Step=6420/7915, loss=0.701487, lr=6.6e-05, time_each_step=0.16s, eta=8:15:21\n",
      "2021-12-24 06:14:29 [INFO]\t[TRAIN] Epoch=13/35, Step=6620/7915, loss=0.242231, lr=6.6e-05, time_each_step=0.16s, eta=8:14:47\n",
      "2021-12-24 06:15:02 [INFO]\t[TRAIN] Epoch=13/35, Step=6820/7915, loss=0.228536, lr=6.6e-05, time_each_step=0.16s, eta=8:14:15\n",
      "2021-12-24 06:15:35 [INFO]\t[TRAIN] Epoch=13/35, Step=7020/7915, loss=0.655029, lr=6.6e-05, time_each_step=0.17s, eta=8:13:44\n",
      "2021-12-24 06:16:08 [INFO]\t[TRAIN] Epoch=13/35, Step=7220/7915, loss=1.460296, lr=6.6e-05, time_each_step=0.17s, eta=8:13:12\n",
      "2021-12-24 06:16:41 [INFO]\t[TRAIN] Epoch=13/35, Step=7420/7915, loss=0.295626, lr=6.6e-05, time_each_step=0.17s, eta=8:12:38\n",
      "2021-12-24 06:17:15 [INFO]\t[TRAIN] Epoch=13/35, Step=7620/7915, loss=0.423683, lr=6.6e-05, time_each_step=0.17s, eta=8:12:4\n",
      "2021-12-24 06:17:47 [INFO]\t[TRAIN] Epoch=13/35, Step=7820/7915, loss=0.266796, lr=6.6e-05, time_each_step=0.16s, eta=8:11:31\n",
      "2021-12-24 06:18:03 [INFO]\t[TRAIN] Epoch 13 finished, loss=0.580129, lr=6.7e-05 .\n",
      "2021-12-24 06:18:03 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 06:18:26 [INFO]\t[EVAL] Finished, Epoch=13, miou=0.550458, category_iou=[0.55239066 0.74501302 0.52624074 0.37818709], oacc=0.732009, category_acc=[0.68526614 0.85051765 0.71245666 0.5760882 ], kappa=0.628774, category_F1-score=[0.7116645  0.85387674 0.68959074 0.54881821] .\n",
      "2021-12-24 06:18:30 [INFO]\tModel saved in output/deeplab/epoch_13.\n",
      "2021-12-24 06:18:30 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.5577806704097794\n",
      "2021-12-24 06:18:50 [INFO]\t[TRAIN] Epoch=14/35, Step=105/7915, loss=0.886765, lr=6.6e-05, time_each_step=0.17s, eta=8:9:31\n",
      "2021-12-24 06:19:23 [INFO]\t[TRAIN] Epoch=14/35, Step=305/7915, loss=0.56482, lr=6.6e-05, time_each_step=0.16s, eta=8:8:31\n",
      "2021-12-24 06:19:56 [INFO]\t[TRAIN] Epoch=14/35, Step=505/7915, loss=0.284329, lr=6.6e-05, time_each_step=0.16s, eta=8:8:20\n",
      "2021-12-24 06:20:29 [INFO]\t[TRAIN] Epoch=14/35, Step=705/7915, loss=0.41722, lr=6.6e-05, time_each_step=0.16s, eta=8:7:50\n",
      "2021-12-24 06:21:02 [INFO]\t[TRAIN] Epoch=14/35, Step=905/7915, loss=0.834408, lr=6.6e-05, time_each_step=0.16s, eta=8:7:4\n",
      "2021-12-24 06:21:34 [INFO]\t[TRAIN] Epoch=14/35, Step=1105/7915, loss=0.733341, lr=6.5e-05, time_each_step=0.16s, eta=8:6:42\n",
      "2021-12-24 06:22:07 [INFO]\t[TRAIN] Epoch=14/35, Step=1305/7915, loss=0.437121, lr=6.5e-05, time_each_step=0.16s, eta=8:6:8\n",
      "2021-12-24 06:22:40 [INFO]\t[TRAIN] Epoch=14/35, Step=1505/7915, loss=0.532081, lr=6.5e-05, time_each_step=0.16s, eta=8:5:24\n",
      "2021-12-24 06:23:13 [INFO]\t[TRAIN] Epoch=14/35, Step=1705/7915, loss=0.687337, lr=6.5e-05, time_each_step=0.16s, eta=8:4:39\n",
      "2021-12-24 06:23:45 [INFO]\t[TRAIN] Epoch=14/35, Step=1905/7915, loss=0.384607, lr=6.5e-05, time_each_step=0.17s, eta=8:4:34\n",
      "2021-12-24 06:24:18 [INFO]\t[TRAIN] Epoch=14/35, Step=2105/7915, loss=0.718149, lr=6.5e-05, time_each_step=0.16s, eta=8:3:50\n",
      "2021-12-24 06:24:51 [INFO]\t[TRAIN] Epoch=14/35, Step=2305/7915, loss=0.48996, lr=6.5e-05, time_each_step=0.17s, eta=8:3:35\n",
      "2021-12-24 06:25:24 [INFO]\t[TRAIN] Epoch=14/35, Step=2505/7915, loss=0.355835, lr=6.5e-05, time_each_step=0.16s, eta=8:2:53\n",
      "2021-12-24 06:25:57 [INFO]\t[TRAIN] Epoch=14/35, Step=2705/7915, loss=1.001347, lr=6.5e-05, time_each_step=0.16s, eta=8:2:17\n",
      "2021-12-24 06:26:30 [INFO]\t[TRAIN] Epoch=14/35, Step=2905/7915, loss=0.670544, lr=6.5e-05, time_each_step=0.16s, eta=8:1:37\n",
      "2021-12-24 06:27:03 [INFO]\t[TRAIN] Epoch=14/35, Step=3105/7915, loss=0.794092, lr=6.5e-05, time_each_step=0.16s, eta=8:1:11\n",
      "2021-12-24 06:27:36 [INFO]\t[TRAIN] Epoch=14/35, Step=3305/7915, loss=0.284702, lr=6.5e-05, time_each_step=0.17s, eta=8:0:47\n",
      "2021-12-24 06:28:09 [INFO]\t[TRAIN] Epoch=14/35, Step=3505/7915, loss=0.29089, lr=6.5e-05, time_each_step=0.16s, eta=8:0:7\n",
      "2021-12-24 06:28:42 [INFO]\t[TRAIN] Epoch=14/35, Step=3705/7915, loss=0.656919, lr=6.5e-05, time_each_step=0.17s, eta=7:59:42\n",
      "2021-12-24 06:29:15 [INFO]\t[TRAIN] Epoch=14/35, Step=3905/7915, loss=0.372326, lr=6.5e-05, time_each_step=0.17s, eta=7:59:6\n",
      "2021-12-24 06:29:48 [INFO]\t[TRAIN] Epoch=14/35, Step=4105/7915, loss=0.635321, lr=6.4e-05, time_each_step=0.16s, eta=7:58:24\n",
      "2021-12-24 06:30:20 [INFO]\t[TRAIN] Epoch=14/35, Step=4305/7915, loss=0.516216, lr=6.4e-05, time_each_step=0.16s, eta=7:57:56\n",
      "2021-12-24 06:30:53 [INFO]\t[TRAIN] Epoch=14/35, Step=4505/7915, loss=0.879079, lr=6.4e-05, time_each_step=0.16s, eta=7:57:15\n",
      "2021-12-24 06:31:26 [INFO]\t[TRAIN] Epoch=14/35, Step=4705/7915, loss=0.355378, lr=6.4e-05, time_each_step=0.17s, eta=7:56:53\n",
      "2021-12-24 06:31:59 [INFO]\t[TRAIN] Epoch=14/35, Step=4905/7915, loss=1.308258, lr=6.4e-05, time_each_step=0.16s, eta=7:56:7\n",
      "2021-12-24 06:32:32 [INFO]\t[TRAIN] Epoch=14/35, Step=5105/7915, loss=0.174083, lr=6.4e-05, time_each_step=0.16s, eta=7:55:38\n",
      "2021-12-24 06:33:05 [INFO]\t[TRAIN] Epoch=14/35, Step=5305/7915, loss=0.388156, lr=6.4e-05, time_each_step=0.16s, eta=7:55:9\n",
      "2021-12-24 06:33:38 [INFO]\t[TRAIN] Epoch=14/35, Step=5505/7915, loss=0.229481, lr=6.4e-05, time_each_step=0.17s, eta=7:54:41\n",
      "2021-12-24 06:34:11 [INFO]\t[TRAIN] Epoch=14/35, Step=5705/7915, loss=0.989534, lr=6.4e-05, time_each_step=0.16s, eta=7:54:4\n",
      "2021-12-24 06:34:44 [INFO]\t[TRAIN] Epoch=14/35, Step=5905/7915, loss=0.658921, lr=6.4e-05, time_each_step=0.17s, eta=7:53:33\n",
      "2021-12-24 06:35:17 [INFO]\t[TRAIN] Epoch=14/35, Step=6105/7915, loss=0.384092, lr=6.4e-05, time_each_step=0.16s, eta=7:52:58\n",
      "2021-12-24 06:35:50 [INFO]\t[TRAIN] Epoch=14/35, Step=6305/7915, loss=0.612199, lr=6.4e-05, time_each_step=0.16s, eta=7:52:21\n",
      "2021-12-24 06:36:22 [INFO]\t[TRAIN] Epoch=14/35, Step=6505/7915, loss=0.697412, lr=6.4e-05, time_each_step=0.17s, eta=7:51:53\n",
      "2021-12-24 06:36:55 [INFO]\t[TRAIN] Epoch=14/35, Step=6705/7915, loss=0.966395, lr=6.4e-05, time_each_step=0.17s, eta=7:51:21\n",
      "2021-12-24 06:37:28 [INFO]\t[TRAIN] Epoch=14/35, Step=6905/7915, loss=0.837333, lr=6.3e-05, time_each_step=0.17s, eta=7:50:49\n",
      "2021-12-24 06:38:02 [INFO]\t[TRAIN] Epoch=14/35, Step=7105/7915, loss=0.309028, lr=6.3e-05, time_each_step=0.16s, eta=7:50:13\n",
      "2021-12-24 06:38:35 [INFO]\t[TRAIN] Epoch=14/35, Step=7305/7915, loss=0.477048, lr=6.3e-05, time_each_step=0.16s, eta=7:49:40\n",
      "2021-12-24 06:39:08 [INFO]\t[TRAIN] Epoch=14/35, Step=7505/7915, loss=0.495943, lr=6.3e-05, time_each_step=0.17s, eta=7:49:9\n",
      "2021-12-24 06:39:41 [INFO]\t[TRAIN] Epoch=14/35, Step=7705/7915, loss=0.434608, lr=6.3e-05, time_each_step=0.17s, eta=7:48:35\n",
      "2021-12-24 06:40:14 [INFO]\t[TRAIN] Epoch=14/35, Step=7905/7915, loss=0.97221, lr=6.3e-05, time_each_step=0.16s, eta=7:48:2\n",
      "2021-12-24 06:40:15 [INFO]\t[TRAIN] Epoch 14 finished, loss=0.554196, lr=6.4e-05 .\n",
      "2021-12-24 06:40:15 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 06:40:39 [INFO]\t[EVAL] Finished, Epoch=14, miou=0.554011, category_iou=[0.56888841 0.73510946 0.52618138 0.38586344], oacc=0.733025, category_acc=[0.69004496 0.85515423 0.76819929 0.54493583], kappa=0.630611, category_F1-score=[0.72521208 0.84733497 0.68953978 0.55685637] .\n",
      "2021-12-24 06:40:43 [INFO]\tModel saved in output/deeplab/epoch_14.\n",
      "2021-12-24 06:40:43 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.5577806704097794\n",
      "2021-12-24 06:41:17 [INFO]\t[TRAIN] Epoch=15/35, Step=190/7915, loss=0.402778, lr=6.3e-05, time_each_step=0.17s, eta=7:45:50\n",
      "2021-12-24 06:41:50 [INFO]\t[TRAIN] Epoch=15/35, Step=390/7915, loss=0.525078, lr=6.3e-05, time_each_step=0.16s, eta=7:44:53\n",
      "2021-12-24 06:42:23 [INFO]\t[TRAIN] Epoch=15/35, Step=590/7915, loss=0.253112, lr=6.3e-05, time_each_step=0.17s, eta=7:44:51\n",
      "2021-12-24 06:42:56 [INFO]\t[TRAIN] Epoch=15/35, Step=790/7915, loss=0.430384, lr=6.3e-05, time_each_step=0.17s, eta=7:44:23\n",
      "2021-12-24 06:43:29 [INFO]\t[TRAIN] Epoch=15/35, Step=990/7915, loss=0.714956, lr=6.3e-05, time_each_step=0.17s, eta=7:43:44\n",
      "2021-12-24 06:44:02 [INFO]\t[TRAIN] Epoch=15/35, Step=1190/7915, loss=0.28869, lr=6.3e-05, time_each_step=0.17s, eta=7:43:15\n",
      "2021-12-24 06:44:35 [INFO]\t[TRAIN] Epoch=15/35, Step=1390/7915, loss=0.42256, lr=6.3e-05, time_each_step=0.17s, eta=7:42:35\n",
      "2021-12-24 06:45:08 [INFO]\t[TRAIN] Epoch=15/35, Step=1590/7915, loss=0.752339, lr=6.3e-05, time_each_step=0.17s, eta=7:42:10\n",
      "2021-12-24 06:45:41 [INFO]\t[TRAIN] Epoch=15/35, Step=1790/7915, loss=0.252643, lr=6.3e-05, time_each_step=0.17s, eta=7:41:39\n",
      "2021-12-24 06:46:15 [INFO]\t[TRAIN] Epoch=15/35, Step=1990/7915, loss=0.43615, lr=6.2e-05, time_each_step=0.17s, eta=7:41:5\n",
      "2021-12-24 06:46:48 [INFO]\t[TRAIN] Epoch=15/35, Step=2190/7915, loss=0.507986, lr=6.2e-05, time_each_step=0.17s, eta=7:40:28\n",
      "2021-12-24 06:47:21 [INFO]\t[TRAIN] Epoch=15/35, Step=2390/7915, loss=0.899326, lr=6.2e-05, time_each_step=0.17s, eta=7:39:57\n",
      "2021-12-24 06:47:54 [INFO]\t[TRAIN] Epoch=15/35, Step=2590/7915, loss=0.254626, lr=6.2e-05, time_each_step=0.17s, eta=7:39:25\n",
      "2021-12-24 06:48:27 [INFO]\t[TRAIN] Epoch=15/35, Step=2790/7915, loss=0.79131, lr=6.2e-05, time_each_step=0.16s, eta=7:38:27\n",
      "2021-12-24 06:49:00 [INFO]\t[TRAIN] Epoch=15/35, Step=2990/7915, loss=0.129284, lr=6.2e-05, time_each_step=0.16s, eta=7:38:5\n",
      "2021-12-24 06:49:33 [INFO]\t[TRAIN] Epoch=15/35, Step=3190/7915, loss=0.37177, lr=6.2e-05, time_each_step=0.17s, eta=7:37:47\n",
      "2021-12-24 06:50:07 [INFO]\t[TRAIN] Epoch=15/35, Step=3390/7915, loss=0.284141, lr=6.2e-05, time_each_step=0.17s, eta=7:37:5\n",
      "2021-12-24 06:50:40 [INFO]\t[TRAIN] Epoch=15/35, Step=3590/7915, loss=0.666923, lr=6.2e-05, time_each_step=0.16s, eta=7:36:26\n",
      "2021-12-24 06:51:13 [INFO]\t[TRAIN] Epoch=15/35, Step=3790/7915, loss=0.953499, lr=6.2e-05, time_each_step=0.17s, eta=7:35:56\n",
      "2021-12-24 06:51:46 [INFO]\t[TRAIN] Epoch=15/35, Step=3990/7915, loss=0.243339, lr=6.2e-05, time_each_step=0.17s, eta=7:35:26\n",
      "2021-12-24 06:52:19 [INFO]\t[TRAIN] Epoch=15/35, Step=4190/7915, loss=1.183233, lr=6.2e-05, time_each_step=0.16s, eta=7:34:40\n",
      "2021-12-24 06:52:52 [INFO]\t[TRAIN] Epoch=15/35, Step=4390/7915, loss=0.30504, lr=6.2e-05, time_each_step=0.17s, eta=7:34:18\n",
      "2021-12-24 06:53:25 [INFO]\t[TRAIN] Epoch=15/35, Step=4590/7915, loss=0.613895, lr=6.2e-05, time_each_step=0.16s, eta=7:33:42\n",
      "2021-12-24 06:53:58 [INFO]\t[TRAIN] Epoch=15/35, Step=4790/7915, loss=0.644125, lr=6.2e-05, time_each_step=0.17s, eta=7:33:17\n",
      "2021-12-24 06:54:31 [INFO]\t[TRAIN] Epoch=15/35, Step=4990/7915, loss=0.640728, lr=6.1e-05, time_each_step=0.17s, eta=7:32:39\n",
      "2021-12-24 06:55:04 [INFO]\t[TRAIN] Epoch=15/35, Step=5190/7915, loss=0.551133, lr=6.1e-05, time_each_step=0.17s, eta=7:32:6\n",
      "2021-12-24 06:55:37 [INFO]\t[TRAIN] Epoch=15/35, Step=5390/7915, loss=0.553436, lr=6.1e-05, time_each_step=0.17s, eta=7:31:35\n",
      "2021-12-24 06:56:10 [INFO]\t[TRAIN] Epoch=15/35, Step=5590/7915, loss=0.605457, lr=6.1e-05, time_each_step=0.16s, eta=7:30:59\n",
      "2021-12-24 06:56:44 [INFO]\t[TRAIN] Epoch=15/35, Step=5790/7915, loss=0.287385, lr=6.1e-05, time_each_step=0.17s, eta=7:30:27\n",
      "2021-12-24 06:57:17 [INFO]\t[TRAIN] Epoch=15/35, Step=5990/7915, loss=0.511772, lr=6.1e-05, time_each_step=0.17s, eta=7:29:53\n",
      "2021-12-24 06:57:50 [INFO]\t[TRAIN] Epoch=15/35, Step=6190/7915, loss=0.315231, lr=6.1e-05, time_each_step=0.16s, eta=7:29:18\n",
      "2021-12-24 06:58:22 [INFO]\t[TRAIN] Epoch=15/35, Step=6390/7915, loss=0.96594, lr=6.1e-05, time_each_step=0.16s, eta=7:28:45\n",
      "2021-12-24 06:58:56 [INFO]\t[TRAIN] Epoch=15/35, Step=6590/7915, loss=0.224637, lr=6.1e-05, time_each_step=0.17s, eta=7:28:15\n",
      "2021-12-24 06:59:28 [INFO]\t[TRAIN] Epoch=15/35, Step=6790/7915, loss=0.50484, lr=6.1e-05, time_each_step=0.16s, eta=7:27:39\n",
      "2021-12-24 07:00:02 [INFO]\t[TRAIN] Epoch=15/35, Step=6990/7915, loss=0.642124, lr=6.1e-05, time_each_step=0.17s, eta=7:27:10\n",
      "2021-12-24 07:00:35 [INFO]\t[TRAIN] Epoch=15/35, Step=7190/7915, loss=0.836795, lr=6.1e-05, time_each_step=0.17s, eta=7:26:36\n",
      "2021-12-24 07:01:08 [INFO]\t[TRAIN] Epoch=15/35, Step=7390/7915, loss=0.541555, lr=6.1e-05, time_each_step=0.17s, eta=7:26:3\n",
      "2021-12-24 07:01:41 [INFO]\t[TRAIN] Epoch=15/35, Step=7590/7915, loss=0.275445, lr=6.1e-05, time_each_step=0.17s, eta=7:25:29\n",
      "2021-12-24 07:02:14 [INFO]\t[TRAIN] Epoch=15/35, Step=7790/7915, loss=0.208913, lr=6e-05, time_each_step=0.17s, eta=7:24:56\n",
      "2021-12-24 07:02:35 [INFO]\t[TRAIN] Epoch 15 finished, loss=0.53028, lr=6.2e-05 .\n",
      "2021-12-24 07:02:35 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 07:02:59 [INFO]\t[EVAL] Finished, Epoch=15, miou=0.555671, category_iou=[0.56402905 0.74195553 0.53039022 0.38630775], oacc=0.733078, category_acc=[0.70813324 0.85724561 0.75462697 0.52814832], kappa=0.631784, category_F1-score=[0.72125137 0.85186507 0.69314377 0.5573189 ] .\n",
      "2021-12-24 07:03:02 [INFO]\tModel saved in output/deeplab/epoch_15.\n",
      "2021-12-24 07:03:02 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.5577806704097794\n",
      "2021-12-24 07:03:18 [INFO]\t[TRAIN] Epoch=16/35, Step=75/7915, loss=0.625358, lr=6e-05, time_each_step=0.17s, eta=7:26:14\n",
      "2021-12-24 07:03:50 [INFO]\t[TRAIN] Epoch=16/35, Step=275/7915, loss=0.567706, lr=6e-05, time_each_step=0.16s, eta=7:25:20\n",
      "2021-12-24 07:04:23 [INFO]\t[TRAIN] Epoch=16/35, Step=475/7915, loss=0.4231, lr=6e-05, time_each_step=0.17s, eta=7:25:20\n",
      "2021-12-24 07:04:56 [INFO]\t[TRAIN] Epoch=16/35, Step=675/7915, loss=0.175711, lr=6e-05, time_each_step=0.17s, eta=7:24:35\n",
      "2021-12-24 07:05:29 [INFO]\t[TRAIN] Epoch=16/35, Step=875/7915, loss=0.42419, lr=6e-05, time_each_step=0.16s, eta=7:23:55\n",
      "2021-12-24 07:06:02 [INFO]\t[TRAIN] Epoch=16/35, Step=1075/7915, loss=0.691224, lr=6e-05, time_each_step=0.16s, eta=7:23:16\n",
      "2021-12-24 07:06:35 [INFO]\t[TRAIN] Epoch=16/35, Step=1275/7915, loss=0.242607, lr=6e-05, time_each_step=0.16s, eta=7:22:52\n",
      "2021-12-24 07:07:08 [INFO]\t[TRAIN] Epoch=16/35, Step=1475/7915, loss=0.530223, lr=6e-05, time_each_step=0.16s, eta=7:22:8\n",
      "2021-12-24 07:07:41 [INFO]\t[TRAIN] Epoch=16/35, Step=1675/7915, loss=0.151378, lr=6e-05, time_each_step=0.16s, eta=7:21:39\n",
      "2021-12-24 07:08:14 [INFO]\t[TRAIN] Epoch=16/35, Step=1875/7915, loss=0.581392, lr=6e-05, time_each_step=0.16s, eta=7:21:10\n",
      "2021-12-24 07:08:47 [INFO]\t[TRAIN] Epoch=16/35, Step=2075/7915, loss=0.363917, lr=6e-05, time_each_step=0.17s, eta=7:20:52\n",
      "2021-12-24 07:09:20 [INFO]\t[TRAIN] Epoch=16/35, Step=2275/7915, loss=1.420125, lr=6e-05, time_each_step=0.17s, eta=7:20:20\n",
      "2021-12-24 07:09:53 [INFO]\t[TRAIN] Epoch=16/35, Step=2475/7915, loss=0.289386, lr=6e-05, time_each_step=0.16s, eta=7:19:35\n",
      "2021-12-24 07:10:26 [INFO]\t[TRAIN] Epoch=16/35, Step=2675/7915, loss=0.47774, lr=6e-05, time_each_step=0.16s, eta=7:19:2\n",
      "2021-12-24 07:10:59 [INFO]\t[TRAIN] Epoch=16/35, Step=2875/7915, loss=0.745053, lr=5.9e-05, time_each_step=0.16s, eta=7:18:25\n",
      "2021-12-24 07:11:32 [INFO]\t[TRAIN] Epoch=16/35, Step=3075/7915, loss=1.574769, lr=5.9e-05, time_each_step=0.17s, eta=7:18:4\n",
      "2021-12-24 07:12:05 [INFO]\t[TRAIN] Epoch=16/35, Step=3275/7915, loss=0.202503, lr=5.9e-05, time_each_step=0.17s, eta=7:17:28\n",
      "2021-12-24 07:12:38 [INFO]\t[TRAIN] Epoch=16/35, Step=3475/7915, loss=1.008711, lr=5.9e-05, time_each_step=0.16s, eta=7:16:49\n",
      "2021-12-24 07:13:11 [INFO]\t[TRAIN] Epoch=16/35, Step=3675/7915, loss=0.264273, lr=5.9e-05, time_each_step=0.17s, eta=7:16:25\n",
      "2021-12-24 07:13:44 [INFO]\t[TRAIN] Epoch=16/35, Step=3875/7915, loss=0.772856, lr=5.9e-05, time_each_step=0.17s, eta=7:15:55\n",
      "2021-12-24 07:14:17 [INFO]\t[TRAIN] Epoch=16/35, Step=4075/7915, loss=0.500193, lr=5.9e-05, time_each_step=0.16s, eta=7:15:3\n",
      "2021-12-24 07:14:50 [INFO]\t[TRAIN] Epoch=16/35, Step=4275/7915, loss=1.056753, lr=5.9e-05, time_each_step=0.17s, eta=7:14:41\n",
      "2021-12-24 07:15:23 [INFO]\t[TRAIN] Epoch=16/35, Step=4475/7915, loss=0.357086, lr=5.9e-05, time_each_step=0.16s, eta=7:14:5\n",
      "2021-12-24 07:15:56 [INFO]\t[TRAIN] Epoch=16/35, Step=4675/7915, loss=0.444874, lr=5.9e-05, time_each_step=0.17s, eta=7:13:36\n",
      "2021-12-24 07:16:29 [INFO]\t[TRAIN] Epoch=16/35, Step=4875/7915, loss=0.349619, lr=5.9e-05, time_each_step=0.16s, eta=7:12:54\n",
      "2021-12-24 07:17:02 [INFO]\t[TRAIN] Epoch=16/35, Step=5075/7915, loss=0.668537, lr=5.9e-05, time_each_step=0.17s, eta=7:12:32\n",
      "2021-12-24 07:17:35 [INFO]\t[TRAIN] Epoch=16/35, Step=5275/7915, loss=0.281567, lr=5.9e-05, time_each_step=0.17s, eta=7:11:56\n",
      "2021-12-24 07:18:08 [INFO]\t[TRAIN] Epoch=16/35, Step=5475/7915, loss=0.656573, lr=5.9e-05, time_each_step=0.17s, eta=7:11:26\n",
      "2021-12-24 07:18:41 [INFO]\t[TRAIN] Epoch=16/35, Step=5675/7915, loss=0.490576, lr=5.8e-05, time_each_step=0.17s, eta=7:10:52\n",
      "2021-12-24 07:19:14 [INFO]\t[TRAIN] Epoch=16/35, Step=5875/7915, loss=0.751137, lr=5.8e-05, time_each_step=0.17s, eta=7:10:20\n",
      "2021-12-24 07:19:47 [INFO]\t[TRAIN] Epoch=16/35, Step=6075/7915, loss=0.374191, lr=5.8e-05, time_each_step=0.17s, eta=7:9:47\n",
      "2021-12-24 07:20:20 [INFO]\t[TRAIN] Epoch=16/35, Step=6275/7915, loss=0.381734, lr=5.8e-05, time_each_step=0.16s, eta=7:9:9\n",
      "2021-12-24 07:20:53 [INFO]\t[TRAIN] Epoch=16/35, Step=6475/7915, loss=0.719699, lr=5.8e-05, time_each_step=0.16s, eta=7:8:37\n",
      "2021-12-24 07:21:26 [INFO]\t[TRAIN] Epoch=16/35, Step=6675/7915, loss=0.624153, lr=5.8e-05, time_each_step=0.17s, eta=7:8:5\n",
      "2021-12-24 07:21:59 [INFO]\t[TRAIN] Epoch=16/35, Step=6875/7915, loss=0.399432, lr=5.8e-05, time_each_step=0.17s, eta=7:7:32\n",
      "2021-12-24 07:22:32 [INFO]\t[TRAIN] Epoch=16/35, Step=7075/7915, loss=0.315417, lr=5.8e-05, time_each_step=0.16s, eta=7:6:56\n",
      "2021-12-24 07:23:05 [INFO]\t[TRAIN] Epoch=16/35, Step=7275/7915, loss=0.618761, lr=5.8e-05, time_each_step=0.17s, eta=7:6:26\n",
      "2021-12-24 07:23:39 [INFO]\t[TRAIN] Epoch=16/35, Step=7475/7915, loss=0.333781, lr=5.8e-05, time_each_step=0.17s, eta=7:5:53\n",
      "2021-12-24 07:24:12 [INFO]\t[TRAIN] Epoch=16/35, Step=7675/7915, loss=0.51953, lr=5.8e-05, time_each_step=0.16s, eta=7:5:19\n",
      "2021-12-24 07:24:45 [INFO]\t[TRAIN] Epoch=16/35, Step=7875/7915, loss=0.389284, lr=5.8e-05, time_each_step=0.16s, eta=7:4:46\n",
      "2021-12-24 07:24:51 [INFO]\t[TRAIN] Epoch 16 finished, loss=0.510756, lr=5.9e-05 .\n",
      "2021-12-24 07:24:51 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 07:25:15 [INFO]\t[EVAL] Finished, Epoch=16, miou=0.362591, category_iou=[0.32774804 0.47908391 0.41724514 0.22628705], oacc=0.56245, category_acc=[0.6380832  0.52207703 0.72677966 0.46809144], kappa=0.372844, category_F1-score=[0.49369011 0.64781167 0.58881153 0.36906049] .\n",
      "2021-12-24 07:25:19 [INFO]\tModel saved in output/deeplab/epoch_16.\n",
      "2021-12-24 07:25:19 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.5577806704097794\n",
      "2021-12-24 07:25:48 [INFO]\t[TRAIN] Epoch=17/35, Step=160/7915, loss=0.183831, lr=5.8e-05, time_each_step=0.17s, eta=7:2:45\n",
      "2021-12-24 07:26:21 [INFO]\t[TRAIN] Epoch=17/35, Step=360/7915, loss=0.466471, lr=5.8e-05, time_each_step=0.17s, eta=7:2:10\n",
      "2021-12-24 07:26:54 [INFO]\t[TRAIN] Epoch=17/35, Step=560/7915, loss=0.249422, lr=5.8e-05, time_each_step=0.16s, eta=7:1:28\n",
      "2021-12-24 07:27:27 [INFO]\t[TRAIN] Epoch=17/35, Step=760/7915, loss=0.463366, lr=5.7e-05, time_each_step=0.16s, eta=7:0:57\n",
      "2021-12-24 07:28:00 [INFO]\t[TRAIN] Epoch=17/35, Step=960/7915, loss=0.112525, lr=5.7e-05, time_each_step=0.17s, eta=7:0:35\n",
      "2021-12-24 07:28:33 [INFO]\t[TRAIN] Epoch=17/35, Step=1160/7915, loss=0.514499, lr=5.7e-05, time_each_step=0.16s, eta=6:59:55\n",
      "2021-12-24 07:29:06 [INFO]\t[TRAIN] Epoch=17/35, Step=1360/7915, loss=0.313143, lr=5.7e-05, time_each_step=0.16s, eta=6:59:22\n",
      "2021-12-24 07:29:39 [INFO]\t[TRAIN] Epoch=17/35, Step=1560/7915, loss=0.305537, lr=5.7e-05, time_each_step=0.16s, eta=6:58:45\n",
      "2021-12-24 07:30:12 [INFO]\t[TRAIN] Epoch=17/35, Step=1760/7915, loss=0.244604, lr=5.7e-05, time_each_step=0.16s, eta=6:58:11\n",
      "2021-12-24 07:30:45 [INFO]\t[TRAIN] Epoch=17/35, Step=1960/7915, loss=0.554009, lr=5.7e-05, time_each_step=0.17s, eta=6:57:55\n",
      "2021-12-24 07:31:18 [INFO]\t[TRAIN] Epoch=17/35, Step=2160/7915, loss=0.979038, lr=5.7e-05, time_each_step=0.17s, eta=6:57:14\n",
      "2021-12-24 07:31:51 [INFO]\t[TRAIN] Epoch=17/35, Step=2360/7915, loss=0.35661, lr=5.7e-05, time_each_step=0.17s, eta=6:56:45\n",
      "2021-12-24 07:32:24 [INFO]\t[TRAIN] Epoch=17/35, Step=2560/7915, loss=0.998135, lr=5.7e-05, time_each_step=0.17s, eta=6:56:16\n",
      "2021-12-24 07:32:58 [INFO]\t[TRAIN] Epoch=17/35, Step=2760/7915, loss=0.273903, lr=5.7e-05, time_each_step=0.17s, eta=6:55:39\n",
      "2021-12-24 07:33:31 [INFO]\t[TRAIN] Epoch=17/35, Step=2960/7915, loss=0.490092, lr=5.7e-05, time_each_step=0.16s, eta=6:54:56\n",
      "2021-12-24 07:34:04 [INFO]\t[TRAIN] Epoch=17/35, Step=3160/7915, loss=0.592193, lr=5.7e-05, time_each_step=0.16s, eta=6:54:24\n",
      "2021-12-24 07:34:37 [INFO]\t[TRAIN] Epoch=17/35, Step=3360/7915, loss=0.540096, lr=5.7e-05, time_each_step=0.17s, eta=6:54:4\n",
      "2021-12-24 07:35:10 [INFO]\t[TRAIN] Epoch=17/35, Step=3560/7915, loss=0.666813, lr=5.6e-05, time_each_step=0.17s, eta=6:53:26\n",
      "2021-12-24 07:35:43 [INFO]\t[TRAIN] Epoch=17/35, Step=3760/7915, loss=0.365097, lr=5.6e-05, time_each_step=0.16s, eta=6:52:46\n",
      "2021-12-24 07:36:16 [INFO]\t[TRAIN] Epoch=17/35, Step=3960/7915, loss=0.663926, lr=5.6e-05, time_each_step=0.17s, eta=6:52:20\n",
      "2021-12-24 07:36:49 [INFO]\t[TRAIN] Epoch=17/35, Step=4160/7915, loss=0.516452, lr=5.6e-05, time_each_step=0.16s, eta=6:51:31\n",
      "2021-12-24 07:37:22 [INFO]\t[TRAIN] Epoch=17/35, Step=4360/7915, loss=0.293618, lr=5.6e-05, time_each_step=0.17s, eta=6:51:16\n",
      "2021-12-24 07:37:55 [INFO]\t[TRAIN] Epoch=17/35, Step=4560/7915, loss=0.923781, lr=5.6e-05, time_each_step=0.16s, eta=6:50:19\n",
      "2021-12-24 07:38:28 [INFO]\t[TRAIN] Epoch=17/35, Step=4760/7915, loss=0.337173, lr=5.6e-05, time_each_step=0.17s, eta=6:50:5\n",
      "2021-12-24 07:39:01 [INFO]\t[TRAIN] Epoch=17/35, Step=4960/7915, loss=0.334506, lr=5.6e-05, time_each_step=0.16s, eta=6:49:23\n",
      "2021-12-24 07:39:34 [INFO]\t[TRAIN] Epoch=17/35, Step=5160/7915, loss=0.544363, lr=5.6e-05, time_each_step=0.17s, eta=6:48:58\n",
      "2021-12-24 07:40:07 [INFO]\t[TRAIN] Epoch=17/35, Step=5360/7915, loss=0.185633, lr=5.6e-05, time_each_step=0.17s, eta=6:48:23\n",
      "2021-12-24 07:40:40 [INFO]\t[TRAIN] Epoch=17/35, Step=5560/7915, loss=0.210358, lr=5.6e-05, time_each_step=0.16s, eta=6:47:49\n",
      "2021-12-24 07:41:13 [INFO]\t[TRAIN] Epoch=17/35, Step=5760/7915, loss=0.248156, lr=5.6e-05, time_each_step=0.17s, eta=6:47:20\n",
      "2021-12-24 07:41:46 [INFO]\t[TRAIN] Epoch=17/35, Step=5960/7915, loss=1.423503, lr=5.6e-05, time_each_step=0.17s, eta=6:46:45\n",
      "2021-12-24 07:42:19 [INFO]\t[TRAIN] Epoch=17/35, Step=6160/7915, loss=0.256244, lr=5.6e-05, time_each_step=0.16s, eta=6:46:9\n",
      "2021-12-24 07:42:52 [INFO]\t[TRAIN] Epoch=17/35, Step=6360/7915, loss=0.561295, lr=5.6e-05, time_each_step=0.16s, eta=6:45:35\n",
      "2021-12-24 07:43:25 [INFO]\t[TRAIN] Epoch=17/35, Step=6560/7915, loss=0.169053, lr=5.5e-05, time_each_step=0.17s, eta=6:45:6\n",
      "2021-12-24 07:43:58 [INFO]\t[TRAIN] Epoch=17/35, Step=6760/7915, loss=0.425398, lr=5.5e-05, time_each_step=0.17s, eta=6:44:36\n",
      "2021-12-24 07:44:31 [INFO]\t[TRAIN] Epoch=17/35, Step=6960/7915, loss=0.25077, lr=5.5e-05, time_each_step=0.16s, eta=6:43:57\n",
      "2021-12-24 07:45:04 [INFO]\t[TRAIN] Epoch=17/35, Step=7160/7915, loss=0.276014, lr=5.5e-05, time_each_step=0.17s, eta=6:43:27\n",
      "2021-12-24 07:45:38 [INFO]\t[TRAIN] Epoch=17/35, Step=7360/7915, loss=0.771376, lr=5.5e-05, time_each_step=0.17s, eta=6:42:54\n",
      "2021-12-24 07:46:11 [INFO]\t[TRAIN] Epoch=17/35, Step=7560/7915, loss=0.406073, lr=5.5e-05, time_each_step=0.17s, eta=6:42:20\n",
      "2021-12-24 07:46:44 [INFO]\t[TRAIN] Epoch=17/35, Step=7760/7915, loss=0.515345, lr=5.5e-05, time_each_step=0.17s, eta=6:41:47\n",
      "2021-12-24 07:47:09 [INFO]\t[TRAIN] Epoch 17 finished, loss=0.49364, lr=5.6e-05 .\n",
      "2021-12-24 07:47:09 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 07:47:33 [INFO]\t[EVAL] Finished, Epoch=17, miou=0.518813, category_iou=[0.52974316 0.67170599 0.5293261  0.34447625], oacc=0.708144, category_acc=[0.68230843 0.75184187 0.72772774 0.60413911], kappa=0.591577, category_F1-score=[0.69259098 0.80361738 0.69223444 0.51243188] .\n",
      "2021-12-24 07:47:36 [INFO]\tModel saved in output/deeplab/epoch_17.\n",
      "2021-12-24 07:47:36 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_12, miou=0.5577806704097794\n",
      "2021-12-24 07:47:47 [INFO]\t[TRAIN] Epoch=18/35, Step=45/7915, loss=0.651349, lr=5.5e-05, time_each_step=0.16s, eta=6:40:59\n",
      "2021-12-24 07:48:20 [INFO]\t[TRAIN] Epoch=18/35, Step=245/7915, loss=0.513475, lr=5.5e-05, time_each_step=0.17s, eta=6:40:37\n",
      "2021-12-24 07:48:52 [INFO]\t[TRAIN] Epoch=18/35, Step=445/7915, loss=0.121761, lr=5.5e-05, time_each_step=0.17s, eta=6:40:15\n",
      "2021-12-24 07:49:25 [INFO]\t[TRAIN] Epoch=18/35, Step=645/7915, loss=0.3881, lr=5.5e-05, time_each_step=0.16s, eta=6:39:1\n",
      "2021-12-24 07:49:58 [INFO]\t[TRAIN] Epoch=18/35, Step=845/7915, loss=0.434011, lr=5.5e-05, time_each_step=0.17s, eta=6:39:2\n",
      "2021-12-24 07:50:31 [INFO]\t[TRAIN] Epoch=18/35, Step=1045/7915, loss=0.830252, lr=5.5e-05, time_each_step=0.16s, eta=6:38:8\n",
      "2021-12-24 07:51:04 [INFO]\t[TRAIN] Epoch=18/35, Step=1245/7915, loss=0.393408, lr=5.5e-05, time_each_step=0.16s, eta=6:37:39\n",
      "2021-12-24 07:51:36 [INFO]\t[TRAIN] Epoch=18/35, Step=1445/7915, loss=0.331332, lr=5.4e-05, time_each_step=0.16s, eta=6:37:9\n",
      "2021-12-24 07:52:09 [INFO]\t[TRAIN] Epoch=18/35, Step=1645/7915, loss=0.419461, lr=5.4e-05, time_each_step=0.16s, eta=6:36:25\n",
      "2021-12-24 07:52:42 [INFO]\t[TRAIN] Epoch=18/35, Step=1845/7915, loss=0.564084, lr=5.4e-05, time_each_step=0.16s, eta=6:35:59\n",
      "2021-12-24 07:53:15 [INFO]\t[TRAIN] Epoch=18/35, Step=2045/7915, loss=0.545342, lr=5.4e-05, time_each_step=0.17s, eta=6:35:36\n",
      "2021-12-24 07:53:48 [INFO]\t[TRAIN] Epoch=18/35, Step=2245/7915, loss=0.240228, lr=5.4e-05, time_each_step=0.16s, eta=6:34:53\n",
      "2021-12-24 07:54:21 [INFO]\t[TRAIN] Epoch=18/35, Step=2445/7915, loss=0.408795, lr=5.4e-05, time_each_step=0.17s, eta=6:34:35\n",
      "2021-12-24 07:54:55 [INFO]\t[TRAIN] Epoch=18/35, Step=2645/7915, loss=0.413057, lr=5.4e-05, time_each_step=0.16s, eta=6:33:56\n",
      "2021-12-24 07:55:28 [INFO]\t[TRAIN] Epoch=18/35, Step=2845/7915, loss=0.131762, lr=5.4e-05, time_each_step=0.16s, eta=6:33:11\n",
      "2021-12-24 07:56:00 [INFO]\t[TRAIN] Epoch=18/35, Step=3045/7915, loss=0.537624, lr=5.4e-05, time_each_step=0.16s, eta=6:32:47\n",
      "2021-12-24 07:56:33 [INFO]\t[TRAIN] Epoch=18/35, Step=3245/7915, loss=0.747519, lr=5.4e-05, time_each_step=0.17s, eta=6:32:27\n",
      "2021-12-24 07:57:06 [INFO]\t[TRAIN] Epoch=18/35, Step=3445/7915, loss=0.455121, lr=5.4e-05, time_each_step=0.17s, eta=6:31:45\n",
      "2021-12-24 07:57:39 [INFO]\t[TRAIN] Epoch=18/35, Step=3645/7915, loss=0.463849, lr=5.4e-05, time_each_step=0.16s, eta=6:31:9\n",
      "2021-12-24 07:58:12 [INFO]\t[TRAIN] Epoch=18/35, Step=3845/7915, loss=0.25946, lr=5.4e-05, time_each_step=0.16s, eta=6:30:37\n",
      "2021-12-24 07:58:45 [INFO]\t[TRAIN] Epoch=18/35, Step=4045/7915, loss=0.826652, lr=5.4e-05, time_each_step=0.16s, eta=6:29:53\n",
      "2021-12-24 07:59:18 [INFO]\t[TRAIN] Epoch=18/35, Step=4245/7915, loss=0.234462, lr=5.3e-05, time_each_step=0.16s, eta=6:29:28\n",
      "2021-12-24 07:59:51 [INFO]\t[TRAIN] Epoch=18/35, Step=4445/7915, loss=0.513881, lr=5.3e-05, time_each_step=0.17s, eta=6:29:6\n",
      "2021-12-24 08:00:23 [INFO]\t[TRAIN] Epoch=18/35, Step=4645/7915, loss=0.342132, lr=5.3e-05, time_each_step=0.17s, eta=6:28:26\n",
      "2021-12-24 08:00:56 [INFO]\t[TRAIN] Epoch=18/35, Step=4845/7915, loss=0.646591, lr=5.3e-05, time_each_step=0.17s, eta=6:27:58\n",
      "2021-12-24 08:01:29 [INFO]\t[TRAIN] Epoch=18/35, Step=5045/7915, loss=0.483596, lr=5.3e-05, time_each_step=0.17s, eta=6:27:25\n",
      "2021-12-24 08:02:03 [INFO]\t[TRAIN] Epoch=18/35, Step=5245/7915, loss=0.495779, lr=5.3e-05, time_each_step=0.16s, eta=6:26:46\n",
      "2021-12-24 08:02:36 [INFO]\t[TRAIN] Epoch=18/35, Step=5445/7915, loss=0.27063, lr=5.3e-05, time_each_step=0.16s, eta=6:26:7\n",
      "2021-12-24 08:03:09 [INFO]\t[TRAIN] Epoch=18/35, Step=5645/7915, loss=0.503575, lr=5.3e-05, time_each_step=0.17s, eta=6:25:43\n",
      "2021-12-24 08:03:42 [INFO]\t[TRAIN] Epoch=18/35, Step=5845/7915, loss=1.043977, lr=5.3e-05, time_each_step=0.16s, eta=6:25:6\n",
      "2021-12-24 08:04:15 [INFO]\t[TRAIN] Epoch=18/35, Step=6045/7915, loss=0.162704, lr=5.3e-05, time_each_step=0.16s, eta=6:24:34\n",
      "2021-12-24 08:04:48 [INFO]\t[TRAIN] Epoch=18/35, Step=6245/7915, loss=0.329265, lr=5.3e-05, time_each_step=0.17s, eta=6:24:3\n",
      "2021-12-24 08:05:20 [INFO]\t[TRAIN] Epoch=18/35, Step=6445/7915, loss=0.070855, lr=5.3e-05, time_each_step=0.17s, eta=6:23:29\n",
      "2021-12-24 08:05:53 [INFO]\t[TRAIN] Epoch=18/35, Step=6645/7915, loss=0.711055, lr=5.3e-05, time_each_step=0.17s, eta=6:22:57\n",
      "2021-12-24 08:06:26 [INFO]\t[TRAIN] Epoch=18/35, Step=6845/7915, loss=0.487125, lr=5.3e-05, time_each_step=0.17s, eta=6:22:23\n",
      "2021-12-24 08:06:59 [INFO]\t[TRAIN] Epoch=18/35, Step=7045/7915, loss=0.376413, lr=5.3e-05, time_each_step=0.17s, eta=6:21:52\n",
      "2021-12-24 08:07:32 [INFO]\t[TRAIN] Epoch=18/35, Step=7245/7915, loss=0.254766, lr=5.2e-05, time_each_step=0.17s, eta=6:21:17\n",
      "2021-12-24 08:08:06 [INFO]\t[TRAIN] Epoch=18/35, Step=7445/7915, loss=0.283228, lr=5.2e-05, time_each_step=0.17s, eta=6:20:44\n",
      "2021-12-24 08:08:39 [INFO]\t[TRAIN] Epoch=18/35, Step=7645/7915, loss=0.94612, lr=5.2e-05, time_each_step=0.16s, eta=6:20:10\n",
      "2021-12-24 08:09:11 [INFO]\t[TRAIN] Epoch=18/35, Step=7845/7915, loss=0.244135, lr=5.2e-05, time_each_step=0.16s, eta=6:19:38\n",
      "2021-12-24 08:09:23 [INFO]\t[TRAIN] Epoch 18 finished, loss=0.47841, lr=5.4e-05 .\n",
      "2021-12-24 08:09:23 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 08:09:46 [INFO]\t[EVAL] Finished, Epoch=18, miou=0.559029, category_iou=[0.56108651 0.74125949 0.54417683 0.38959289], oacc=0.736051, category_acc=[0.69693575 0.85283889 0.7590191  0.55175054], kappa=0.635071, category_F1-score=[0.71884102 0.85140612 0.70481155 0.56072954] .\n",
      "2021-12-24 08:09:50 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 08:09:54 [INFO]\tModel saved in output/deeplab/epoch_18.\n",
      "2021-12-24 08:09:54 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_18, miou=0.5590289297179429\n",
      "2021-12-24 08:10:19 [INFO]\t[TRAIN] Epoch=19/35, Step=130/7915, loss=0.343294, lr=5.2e-05, time_each_step=0.16s, eta=6:18:23\n",
      "2021-12-24 08:10:51 [INFO]\t[TRAIN] Epoch=19/35, Step=330/7915, loss=0.470506, lr=5.2e-05, time_each_step=0.16s, eta=6:18:3\n",
      "2021-12-24 08:11:24 [INFO]\t[TRAIN] Epoch=19/35, Step=530/7915, loss=0.340852, lr=5.2e-05, time_each_step=0.16s, eta=6:17:1\n",
      "2021-12-24 08:11:57 [INFO]\t[TRAIN] Epoch=19/35, Step=730/7915, loss=0.596764, lr=5.2e-05, time_each_step=0.17s, eta=6:17:13\n",
      "2021-12-24 08:12:30 [INFO]\t[TRAIN] Epoch=19/35, Step=930/7915, loss=0.358716, lr=5.2e-05, time_each_step=0.17s, eta=6:16:34\n",
      "2021-12-24 08:13:03 [INFO]\t[TRAIN] Epoch=19/35, Step=1130/7915, loss=0.53734, lr=5.2e-05, time_each_step=0.17s, eta=6:16:7\n",
      "2021-12-24 08:13:36 [INFO]\t[TRAIN] Epoch=19/35, Step=1330/7915, loss=0.711866, lr=5.2e-05, time_each_step=0.16s, eta=6:15:12\n",
      "2021-12-24 08:14:09 [INFO]\t[TRAIN] Epoch=19/35, Step=1530/7915, loss=0.249568, lr=5.2e-05, time_each_step=0.16s, eta=6:14:44\n",
      "2021-12-24 08:14:42 [INFO]\t[TRAIN] Epoch=19/35, Step=1730/7915, loss=0.701802, lr=5.2e-05, time_each_step=0.16s, eta=6:14:6\n",
      "2021-12-24 08:15:15 [INFO]\t[TRAIN] Epoch=19/35, Step=1930/7915, loss=0.14177, lr=5.2e-05, time_each_step=0.16s, eta=6:13:37\n",
      "2021-12-24 08:15:48 [INFO]\t[TRAIN] Epoch=19/35, Step=2130/7915, loss=0.295496, lr=5.1e-05, time_each_step=0.16s, eta=6:13:0\n",
      "2021-12-24 08:16:21 [INFO]\t[TRAIN] Epoch=19/35, Step=2330/7915, loss=0.533268, lr=5.1e-05, time_each_step=0.17s, eta=6:12:52\n",
      "2021-12-24 08:16:54 [INFO]\t[TRAIN] Epoch=19/35, Step=2530/7915, loss=0.849002, lr=5.1e-05, time_each_step=0.17s, eta=6:12:7\n",
      "2021-12-24 08:17:27 [INFO]\t[TRAIN] Epoch=19/35, Step=2730/7915, loss=0.064484, lr=5.1e-05, time_each_step=0.16s, eta=6:11:27\n",
      "2021-12-24 08:18:00 [INFO]\t[TRAIN] Epoch=19/35, Step=2930/7915, loss=0.494599, lr=5.1e-05, time_each_step=0.16s, eta=6:10:51\n",
      "2021-12-24 08:18:33 [INFO]\t[TRAIN] Epoch=19/35, Step=3130/7915, loss=0.48012, lr=5.1e-05, time_each_step=0.16s, eta=6:10:15\n",
      "2021-12-24 08:19:06 [INFO]\t[TRAIN] Epoch=19/35, Step=3330/7915, loss=0.219332, lr=5.1e-05, time_each_step=0.17s, eta=6:9:52\n",
      "2021-12-24 08:19:39 [INFO]\t[TRAIN] Epoch=19/35, Step=3530/7915, loss=0.82556, lr=5.1e-05, time_each_step=0.17s, eta=6:9:22\n",
      "2021-12-24 08:20:12 [INFO]\t[TRAIN] Epoch=19/35, Step=3730/7915, loss=0.518811, lr=5.1e-05, time_each_step=0.17s, eta=6:8:55\n",
      "2021-12-24 08:20:45 [INFO]\t[TRAIN] Epoch=19/35, Step=3930/7915, loss=0.581654, lr=5.1e-05, time_each_step=0.17s, eta=6:8:17\n",
      "2021-12-24 08:21:18 [INFO]\t[TRAIN] Epoch=19/35, Step=4130/7915, loss=0.459094, lr=5.1e-05, time_each_step=0.17s, eta=6:7:46\n",
      "2021-12-24 08:21:51 [INFO]\t[TRAIN] Epoch=19/35, Step=4330/7915, loss=0.284476, lr=5.1e-05, time_each_step=0.16s, eta=6:7:0\n",
      "2021-12-24 08:22:24 [INFO]\t[TRAIN] Epoch=19/35, Step=4530/7915, loss=0.391605, lr=5.1e-05, time_each_step=0.16s, eta=6:6:30\n",
      "2021-12-24 08:22:57 [INFO]\t[TRAIN] Epoch=19/35, Step=4730/7915, loss=0.106707, lr=5.1e-05, time_each_step=0.17s, eta=6:6:3\n",
      "2021-12-24 08:23:30 [INFO]\t[TRAIN] Epoch=19/35, Step=4930/7915, loss=0.230399, lr=5e-05, time_each_step=0.16s, eta=6:5:25\n",
      "2021-12-24 08:24:03 [INFO]\t[TRAIN] Epoch=19/35, Step=5130/7915, loss=0.250962, lr=5e-05, time_each_step=0.17s, eta=6:4:56\n",
      "2021-12-24 08:24:37 [INFO]\t[TRAIN] Epoch=19/35, Step=5330/7915, loss=0.185832, lr=5e-05, time_each_step=0.17s, eta=6:4:21\n",
      "2021-12-24 08:25:10 [INFO]\t[TRAIN] Epoch=19/35, Step=5530/7915, loss=0.56144, lr=5e-05, time_each_step=0.17s, eta=6:3:51\n",
      "2021-12-24 08:25:43 [INFO]\t[TRAIN] Epoch=19/35, Step=5730/7915, loss=0.702944, lr=5e-05, time_each_step=0.17s, eta=6:3:20\n",
      "2021-12-24 08:26:16 [INFO]\t[TRAIN] Epoch=19/35, Step=5930/7915, loss=0.803089, lr=5e-05, time_each_step=0.16s, eta=6:2:41\n",
      "2021-12-24 08:26:49 [INFO]\t[TRAIN] Epoch=19/35, Step=6130/7915, loss=0.17287, lr=5e-05, time_each_step=0.16s, eta=6:2:9\n",
      "2021-12-24 08:27:22 [INFO]\t[TRAIN] Epoch=19/35, Step=6330/7915, loss=0.315285, lr=5e-05, time_each_step=0.17s, eta=6:1:38\n",
      "2021-12-24 08:27:55 [INFO]\t[TRAIN] Epoch=19/35, Step=6530/7915, loss=0.191412, lr=5e-05, time_each_step=0.16s, eta=6:1:1\n",
      "2021-12-24 08:28:28 [INFO]\t[TRAIN] Epoch=19/35, Step=6730/7915, loss=0.506704, lr=5e-05, time_each_step=0.17s, eta=6:0:31\n",
      "2021-12-24 08:29:01 [INFO]\t[TRAIN] Epoch=19/35, Step=6930/7915, loss=0.197845, lr=5e-05, time_each_step=0.17s, eta=5:59:57\n",
      "2021-12-24 08:29:34 [INFO]\t[TRAIN] Epoch=19/35, Step=7130/7915, loss=0.43051, lr=5e-05, time_each_step=0.17s, eta=5:59:24\n",
      "2021-12-24 08:30:07 [INFO]\t[TRAIN] Epoch=19/35, Step=7330/7915, loss=0.360521, lr=5e-05, time_each_step=0.17s, eta=5:58:52\n",
      "2021-12-24 08:30:40 [INFO]\t[TRAIN] Epoch=19/35, Step=7530/7915, loss=0.802894, lr=5e-05, time_each_step=0.17s, eta=5:58:19\n",
      "2021-12-24 08:31:13 [INFO]\t[TRAIN] Epoch=19/35, Step=7730/7915, loss=0.545271, lr=5e-05, time_each_step=0.16s, eta=5:57:45\n",
      "2021-12-24 08:31:43 [INFO]\t[TRAIN] Epoch 19 finished, loss=0.45618, lr=5.1e-05 .\n",
      "2021-12-24 08:31:43 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 08:32:06 [INFO]\t[EVAL] Finished, Epoch=19, miou=0.558878, category_iou=[0.57025409 0.73631272 0.53899672 0.38994719], oacc=0.735877, category_acc=[0.69371368 0.85618909 0.78178514 0.54428897], kappa=0.63474, category_F1-score=[0.72632078 0.84813376 0.70045207 0.56109641] .\n",
      "2021-12-24 08:32:10 [INFO]\tModel saved in output/deeplab/epoch_19.\n",
      "2021-12-24 08:32:10 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_18, miou=0.5590289297179429\n",
      "2021-12-24 08:32:15 [INFO]\t[TRAIN] Epoch=20/35, Step=15/7915, loss=0.631217, lr=4.9e-05, time_each_step=0.31s, eta=6:14:39\n",
      "2021-12-24 08:32:48 [INFO]\t[TRAIN] Epoch=20/35, Step=215/7915, loss=0.247525, lr=4.9e-05, time_each_step=0.17s, eta=5:55:48\n",
      "2021-12-24 08:33:21 [INFO]\t[TRAIN] Epoch=20/35, Step=415/7915, loss=0.229884, lr=4.9e-05, time_each_step=0.16s, eta=5:54:53\n",
      "2021-12-24 08:33:53 [INFO]\t[TRAIN] Epoch=20/35, Step=615/7915, loss=0.808143, lr=4.9e-05, time_each_step=0.16s, eta=5:54:17\n",
      "2021-12-24 08:34:26 [INFO]\t[TRAIN] Epoch=20/35, Step=815/7915, loss=0.365241, lr=4.9e-05, time_each_step=0.16s, eta=5:53:49\n",
      "2021-12-24 08:34:59 [INFO]\t[TRAIN] Epoch=20/35, Step=1015/7915, loss=0.462351, lr=4.9e-05, time_each_step=0.17s, eta=5:53:24\n",
      "2021-12-24 08:35:32 [INFO]\t[TRAIN] Epoch=20/35, Step=1215/7915, loss=0.261353, lr=4.9e-05, time_each_step=0.16s, eta=5:52:23\n",
      "2021-12-24 08:36:05 [INFO]\t[TRAIN] Epoch=20/35, Step=1415/7915, loss=0.366656, lr=4.9e-05, time_each_step=0.17s, eta=5:52:32\n",
      "2021-12-24 08:36:38 [INFO]\t[TRAIN] Epoch=20/35, Step=1615/7915, loss=0.197867, lr=4.9e-05, time_each_step=0.17s, eta=5:52:0\n",
      "2021-12-24 08:37:11 [INFO]\t[TRAIN] Epoch=20/35, Step=1815/7915, loss=0.275956, lr=4.9e-05, time_each_step=0.17s, eta=5:51:10\n",
      "2021-12-24 08:37:45 [INFO]\t[TRAIN] Epoch=20/35, Step=2015/7915, loss=1.042018, lr=4.9e-05, time_each_step=0.17s, eta=5:50:47\n",
      "2021-12-24 08:38:17 [INFO]\t[TRAIN] Epoch=20/35, Step=2215/7915, loss=0.766768, lr=4.9e-05, time_each_step=0.16s, eta=5:49:50\n",
      "2021-12-24 08:38:51 [INFO]\t[TRAIN] Epoch=20/35, Step=2415/7915, loss=0.299584, lr=4.9e-05, time_each_step=0.17s, eta=5:49:43\n",
      "2021-12-24 08:39:24 [INFO]\t[TRAIN] Epoch=20/35, Step=2615/7915, loss=0.498841, lr=4.9e-05, time_each_step=0.17s, eta=5:49:5\n",
      "2021-12-24 08:39:57 [INFO]\t[TRAIN] Epoch=20/35, Step=2815/7915, loss=0.342607, lr=4.8e-05, time_each_step=0.16s, eta=5:48:22\n",
      "2021-12-24 08:40:30 [INFO]\t[TRAIN] Epoch=20/35, Step=3015/7915, loss=0.516009, lr=4.8e-05, time_each_step=0.17s, eta=5:47:55\n",
      "2021-12-24 08:41:03 [INFO]\t[TRAIN] Epoch=20/35, Step=3215/7915, loss=0.312424, lr=4.8e-05, time_each_step=0.17s, eta=5:47:29\n",
      "2021-12-24 08:41:36 [INFO]\t[TRAIN] Epoch=20/35, Step=3415/7915, loss=0.675693, lr=4.8e-05, time_each_step=0.16s, eta=5:46:44\n",
      "2021-12-24 08:42:10 [INFO]\t[TRAIN] Epoch=20/35, Step=3615/7915, loss=0.241332, lr=4.8e-05, time_each_step=0.17s, eta=5:46:16\n",
      "2021-12-24 08:42:43 [INFO]\t[TRAIN] Epoch=20/35, Step=3815/7915, loss=0.455397, lr=4.8e-05, time_each_step=0.16s, eta=5:45:28\n",
      "2021-12-24 08:43:16 [INFO]\t[TRAIN] Epoch=20/35, Step=4015/7915, loss=0.30595, lr=4.8e-05, time_each_step=0.16s, eta=5:44:59\n",
      "2021-12-24 08:43:49 [INFO]\t[TRAIN] Epoch=20/35, Step=4215/7915, loss=0.4645, lr=4.8e-05, time_each_step=0.17s, eta=5:44:36\n",
      "2021-12-24 08:44:22 [INFO]\t[TRAIN] Epoch=20/35, Step=4415/7915, loss=0.535319, lr=4.8e-05, time_each_step=0.17s, eta=5:44:11\n",
      "2021-12-24 08:44:54 [INFO]\t[TRAIN] Epoch=20/35, Step=4615/7915, loss=0.875903, lr=4.8e-05, time_each_step=0.16s, eta=5:43:21\n",
      "2021-12-24 08:45:28 [INFO]\t[TRAIN] Epoch=20/35, Step=4815/7915, loss=0.280783, lr=4.8e-05, time_each_step=0.17s, eta=5:42:57\n",
      "2021-12-24 08:46:01 [INFO]\t[TRAIN] Epoch=20/35, Step=5015/7915, loss=0.438569, lr=4.8e-05, time_each_step=0.17s, eta=5:42:28\n",
      "2021-12-24 08:46:34 [INFO]\t[TRAIN] Epoch=20/35, Step=5215/7915, loss=0.319972, lr=4.8e-05, time_each_step=0.16s, eta=5:41:48\n",
      "2021-12-24 08:47:07 [INFO]\t[TRAIN] Epoch=20/35, Step=5415/7915, loss=0.301448, lr=4.8e-05, time_each_step=0.17s, eta=5:41:19\n",
      "2021-12-24 08:47:40 [INFO]\t[TRAIN] Epoch=20/35, Step=5615/7915, loss=0.523766, lr=4.7e-05, time_each_step=0.17s, eta=5:40:48\n",
      "2021-12-24 08:48:13 [INFO]\t[TRAIN] Epoch=20/35, Step=5815/7915, loss=0.340405, lr=4.7e-05, time_each_step=0.17s, eta=5:40:11\n",
      "2021-12-24 08:48:46 [INFO]\t[TRAIN] Epoch=20/35, Step=6015/7915, loss=0.228757, lr=4.7e-05, time_each_step=0.16s, eta=5:39:31\n",
      "2021-12-24 08:49:19 [INFO]\t[TRAIN] Epoch=20/35, Step=6215/7915, loss=0.280228, lr=4.7e-05, time_each_step=0.17s, eta=5:39:7\n",
      "2021-12-24 08:49:52 [INFO]\t[TRAIN] Epoch=20/35, Step=6415/7915, loss=0.264605, lr=4.7e-05, time_each_step=0.16s, eta=5:38:27\n",
      "2021-12-24 08:50:25 [INFO]\t[TRAIN] Epoch=20/35, Step=6615/7915, loss=0.547459, lr=4.7e-05, time_each_step=0.16s, eta=5:37:57\n",
      "2021-12-24 08:50:59 [INFO]\t[TRAIN] Epoch=20/35, Step=6815/7915, loss=0.137213, lr=4.7e-05, time_each_step=0.17s, eta=5:37:25\n",
      "2021-12-24 08:51:32 [INFO]\t[TRAIN] Epoch=20/35, Step=7015/7915, loss=0.475713, lr=4.7e-05, time_each_step=0.16s, eta=5:36:52\n",
      "2021-12-24 08:52:05 [INFO]\t[TRAIN] Epoch=20/35, Step=7215/7915, loss=0.334732, lr=4.7e-05, time_each_step=0.17s, eta=5:36:19\n",
      "2021-12-24 08:52:38 [INFO]\t[TRAIN] Epoch=20/35, Step=7415/7915, loss=0.479498, lr=4.7e-05, time_each_step=0.17s, eta=5:35:46\n",
      "2021-12-24 08:53:11 [INFO]\t[TRAIN] Epoch=20/35, Step=7615/7915, loss=0.452939, lr=4.7e-05, time_each_step=0.17s, eta=5:35:13\n",
      "2021-12-24 08:53:44 [INFO]\t[TRAIN] Epoch=20/35, Step=7815/7915, loss=0.36507, lr=4.7e-05, time_each_step=0.16s, eta=5:34:40\n",
      "2021-12-24 08:54:00 [INFO]\t[TRAIN] Epoch 20 finished, loss=0.44437, lr=4.8e-05 .\n",
      "2021-12-24 08:54:00 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 08:54:24 [INFO]\t[EVAL] Finished, Epoch=20, miou=0.564751, category_iou=[0.56957329 0.7446808  0.54108027 0.40367098], oacc=0.742273, category_acc=[0.72888961 0.83812071 0.72468656 0.57555001], kappa=0.643637, category_F1-score=[0.72576833 0.8536585  0.70220907 0.57516467] .\n",
      "2021-12-24 08:54:28 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 08:54:32 [INFO]\tModel saved in output/deeplab/epoch_20.\n",
      "2021-12-24 08:54:32 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_20, miou=0.5647513345388591\n",
      "2021-12-24 08:54:52 [INFO]\t[TRAIN] Epoch=21/35, Step=100/7915, loss=0.231386, lr=4.7e-05, time_each_step=0.17s, eta=5:35:13\n",
      "2021-12-24 08:55:25 [INFO]\t[TRAIN] Epoch=21/35, Step=300/7915, loss=0.436559, lr=4.7e-05, time_each_step=0.16s, eta=5:34:19\n",
      "2021-12-24 08:55:58 [INFO]\t[TRAIN] Epoch=21/35, Step=500/7915, loss=0.080717, lr=4.6e-05, time_each_step=0.17s, eta=5:34:6\n",
      "2021-12-24 08:56:31 [INFO]\t[TRAIN] Epoch=21/35, Step=700/7915, loss=0.510854, lr=4.6e-05, time_each_step=0.17s, eta=5:33:36\n",
      "2021-12-24 08:57:04 [INFO]\t[TRAIN] Epoch=21/35, Step=900/7915, loss=0.420827, lr=4.6e-05, time_each_step=0.17s, eta=5:33:1\n",
      "2021-12-24 08:57:37 [INFO]\t[TRAIN] Epoch=21/35, Step=1100/7915, loss=0.34177, lr=4.6e-05, time_each_step=0.17s, eta=5:32:31\n",
      "2021-12-24 08:58:10 [INFO]\t[TRAIN] Epoch=21/35, Step=1300/7915, loss=0.572519, lr=4.6e-05, time_each_step=0.17s, eta=5:32:3\n",
      "2021-12-24 08:58:43 [INFO]\t[TRAIN] Epoch=21/35, Step=1500/7915, loss=0.482057, lr=4.6e-05, time_each_step=0.16s, eta=5:31:15\n",
      "2021-12-24 08:59:17 [INFO]\t[TRAIN] Epoch=21/35, Step=1700/7915, loss=0.776779, lr=4.6e-05, time_each_step=0.16s, eta=5:30:27\n",
      "2021-12-24 08:59:50 [INFO]\t[TRAIN] Epoch=21/35, Step=1900/7915, loss=0.266051, lr=4.6e-05, time_each_step=0.17s, eta=5:30:32\n",
      "2021-12-24 09:00:23 [INFO]\t[TRAIN] Epoch=21/35, Step=2100/7915, loss=0.633622, lr=4.6e-05, time_each_step=0.17s, eta=5:29:48\n",
      "2021-12-24 09:00:56 [INFO]\t[TRAIN] Epoch=21/35, Step=2300/7915, loss=0.287898, lr=4.6e-05, time_each_step=0.17s, eta=5:29:32\n",
      "2021-12-24 09:01:30 [INFO]\t[TRAIN] Epoch=21/35, Step=2500/7915, loss=0.203397, lr=4.6e-05, time_each_step=0.17s, eta=5:28:53\n",
      "2021-12-24 09:02:03 [INFO]\t[TRAIN] Epoch=21/35, Step=2700/7915, loss=0.693048, lr=4.6e-05, time_each_step=0.17s, eta=5:28:8\n",
      "2021-12-24 09:02:36 [INFO]\t[TRAIN] Epoch=21/35, Step=2900/7915, loss=0.387455, lr=4.6e-05, time_each_step=0.16s, eta=5:27:19\n",
      "2021-12-24 09:03:09 [INFO]\t[TRAIN] Epoch=21/35, Step=3100/7915, loss=0.046978, lr=4.6e-05, time_each_step=0.16s, eta=5:26:52\n",
      "2021-12-24 09:03:42 [INFO]\t[TRAIN] Epoch=21/35, Step=3300/7915, loss=0.215833, lr=4.5e-05, time_each_step=0.16s, eta=5:26:21\n",
      "2021-12-24 09:04:15 [INFO]\t[TRAIN] Epoch=21/35, Step=3500/7915, loss=0.506903, lr=4.5e-05, time_each_step=0.17s, eta=5:26:2\n",
      "2021-12-24 09:04:49 [INFO]\t[TRAIN] Epoch=21/35, Step=3700/7915, loss=0.295849, lr=4.5e-05, time_each_step=0.17s, eta=5:25:27\n",
      "2021-12-24 09:05:22 [INFO]\t[TRAIN] Epoch=21/35, Step=3900/7915, loss=0.173254, lr=4.5e-05, time_each_step=0.17s, eta=5:24:55\n",
      "2021-12-24 09:05:55 [INFO]\t[TRAIN] Epoch=21/35, Step=4100/7915, loss=0.238088, lr=4.5e-05, time_each_step=0.17s, eta=5:24:17\n",
      "2021-12-24 09:06:28 [INFO]\t[TRAIN] Epoch=21/35, Step=4300/7915, loss=0.305598, lr=4.5e-05, time_each_step=0.17s, eta=5:23:46\n",
      "2021-12-24 09:07:01 [INFO]\t[TRAIN] Epoch=21/35, Step=4500/7915, loss=0.299096, lr=4.5e-05, time_each_step=0.16s, eta=5:22:50\n",
      "2021-12-24 09:07:34 [INFO]\t[TRAIN] Epoch=21/35, Step=4700/7915, loss=0.751922, lr=4.5e-05, time_each_step=0.17s, eta=5:22:33\n",
      "2021-12-24 09:08:07 [INFO]\t[TRAIN] Epoch=21/35, Step=4900/7915, loss=0.168437, lr=4.5e-05, time_each_step=0.17s, eta=5:22:5\n",
      "2021-12-24 09:08:40 [INFO]\t[TRAIN] Epoch=21/35, Step=5100/7915, loss=0.260348, lr=4.5e-05, time_each_step=0.16s, eta=5:21:24\n",
      "2021-12-24 09:09:14 [INFO]\t[TRAIN] Epoch=21/35, Step=5300/7915, loss=0.116452, lr=4.5e-05, time_each_step=0.17s, eta=5:20:56\n",
      "2021-12-24 09:09:47 [INFO]\t[TRAIN] Epoch=21/35, Step=5500/7915, loss=0.685656, lr=4.5e-05, time_each_step=0.17s, eta=5:20:23\n",
      "2021-12-24 09:10:20 [INFO]\t[TRAIN] Epoch=21/35, Step=5700/7915, loss=0.403922, lr=4.5e-05, time_each_step=0.17s, eta=5:19:47\n",
      "2021-12-24 09:10:53 [INFO]\t[TRAIN] Epoch=21/35, Step=5900/7915, loss=0.284888, lr=4.5e-05, time_each_step=0.17s, eta=5:19:19\n",
      "2021-12-24 09:11:27 [INFO]\t[TRAIN] Epoch=21/35, Step=6100/7915, loss=0.504978, lr=4.4e-05, time_each_step=0.16s, eta=5:18:39\n",
      "2021-12-24 09:12:00 [INFO]\t[TRAIN] Epoch=21/35, Step=6300/7915, loss=0.365034, lr=4.4e-05, time_each_step=0.17s, eta=5:18:8\n",
      "2021-12-24 09:12:33 [INFO]\t[TRAIN] Epoch=21/35, Step=6500/7915, loss=0.652185, lr=4.4e-05, time_each_step=0.17s, eta=5:17:37\n",
      "2021-12-24 09:13:06 [INFO]\t[TRAIN] Epoch=21/35, Step=6700/7915, loss=0.771419, lr=4.4e-05, time_each_step=0.17s, eta=5:17:3\n",
      "2021-12-24 09:13:39 [INFO]\t[TRAIN] Epoch=21/35, Step=6900/7915, loss=1.007461, lr=4.4e-05, time_each_step=0.17s, eta=5:16:32\n",
      "2021-12-24 09:14:13 [INFO]\t[TRAIN] Epoch=21/35, Step=7100/7915, loss=0.440469, lr=4.4e-05, time_each_step=0.17s, eta=5:15:57\n",
      "2021-12-24 09:14:46 [INFO]\t[TRAIN] Epoch=21/35, Step=7300/7915, loss=0.166533, lr=4.4e-05, time_each_step=0.17s, eta=5:15:24\n",
      "2021-12-24 09:15:20 [INFO]\t[TRAIN] Epoch=21/35, Step=7500/7915, loss=0.671453, lr=4.4e-05, time_each_step=0.17s, eta=5:14:51\n",
      "2021-12-24 09:15:53 [INFO]\t[TRAIN] Epoch=21/35, Step=7700/7915, loss=0.200645, lr=4.4e-05, time_each_step=0.16s, eta=5:14:16\n",
      "2021-12-24 09:16:26 [INFO]\t[TRAIN] Epoch=21/35, Step=7900/7915, loss=0.674807, lr=4.4e-05, time_each_step=0.16s, eta=5:13:44\n",
      "2021-12-24 09:16:28 [INFO]\t[TRAIN] Epoch 21 finished, loss=0.427815, lr=4.5e-05 .\n",
      "2021-12-24 09:16:28 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:24<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 09:16:53 [INFO]\t[EVAL] Finished, Epoch=21, miou=0.55452, category_iou=[0.56758728 0.72424982 0.53386556 0.39237703], oacc=0.732797, category_acc=[0.70744071 0.84823321 0.70576158 0.56819947], kappa=0.631345, category_F1-score=[0.72415398 0.84007527 0.69610476 0.56360744] .\n",
      "2021-12-24 09:16:56 [INFO]\tModel saved in output/deeplab/epoch_21.\n",
      "2021-12-24 09:16:56 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_20, miou=0.5647513345388591\n",
      "2021-12-24 09:17:30 [INFO]\t[TRAIN] Epoch=22/35, Step=185/7915, loss=0.444774, lr=4.4e-05, time_each_step=0.16s, eta=5:12:57\n",
      "2021-12-24 09:18:03 [INFO]\t[TRAIN] Epoch=22/35, Step=385/7915, loss=0.536557, lr=4.4e-05, time_each_step=0.16s, eta=5:12:25\n",
      "2021-12-24 09:18:36 [INFO]\t[TRAIN] Epoch=22/35, Step=585/7915, loss=0.293349, lr=4.4e-05, time_each_step=0.16s, eta=5:11:49\n",
      "2021-12-24 09:19:09 [INFO]\t[TRAIN] Epoch=22/35, Step=785/7915, loss=0.257002, lr=4.4e-05, time_each_step=0.17s, eta=5:11:41\n",
      "2021-12-24 09:19:43 [INFO]\t[TRAIN] Epoch=22/35, Step=985/7915, loss=0.368782, lr=4.3e-05, time_each_step=0.17s, eta=5:11:4\n",
      "2021-12-24 09:20:16 [INFO]\t[TRAIN] Epoch=22/35, Step=1185/7915, loss=0.250526, lr=4.3e-05, time_each_step=0.17s, eta=5:10:25\n",
      "2021-12-24 09:20:49 [INFO]\t[TRAIN] Epoch=22/35, Step=1385/7915, loss=0.219043, lr=4.3e-05, time_each_step=0.17s, eta=5:10:6\n",
      "2021-12-24 09:21:22 [INFO]\t[TRAIN] Epoch=22/35, Step=1585/7915, loss=0.204339, lr=4.3e-05, time_each_step=0.17s, eta=5:9:22\n",
      "2021-12-24 09:21:55 [INFO]\t[TRAIN] Epoch=22/35, Step=1785/7915, loss=0.616589, lr=4.3e-05, time_each_step=0.17s, eta=5:8:52\n",
      "2021-12-24 09:22:28 [INFO]\t[TRAIN] Epoch=22/35, Step=1985/7915, loss=0.252903, lr=4.3e-05, time_each_step=0.17s, eta=5:8:12\n",
      "2021-12-24 09:23:01 [INFO]\t[TRAIN] Epoch=22/35, Step=2185/7915, loss=0.681358, lr=4.3e-05, time_each_step=0.16s, eta=5:7:26\n",
      "2021-12-24 09:23:35 [INFO]\t[TRAIN] Epoch=22/35, Step=2385/7915, loss=0.70368, lr=4.3e-05, time_each_step=0.17s, eta=5:7:7\n",
      "2021-12-24 09:24:08 [INFO]\t[TRAIN] Epoch=22/35, Step=2585/7915, loss=0.173279, lr=4.3e-05, time_each_step=0.17s, eta=5:6:42\n",
      "2021-12-24 09:24:41 [INFO]\t[TRAIN] Epoch=22/35, Step=2785/7915, loss=0.674859, lr=4.3e-05, time_each_step=0.16s, eta=5:5:42\n",
      "2021-12-24 09:25:14 [INFO]\t[TRAIN] Epoch=22/35, Step=2985/7915, loss=0.369323, lr=4.3e-05, time_each_step=0.17s, eta=5:5:21\n",
      "2021-12-24 09:25:47 [INFO]\t[TRAIN] Epoch=22/35, Step=3185/7915, loss=0.195208, lr=4.3e-05, time_each_step=0.17s, eta=5:4:55\n",
      "2021-12-24 09:26:21 [INFO]\t[TRAIN] Epoch=22/35, Step=3385/7915, loss=0.595775, lr=4.3e-05, time_each_step=0.17s, eta=5:4:16\n",
      "2021-12-24 09:26:54 [INFO]\t[TRAIN] Epoch=22/35, Step=3585/7915, loss=0.219369, lr=4.3e-05, time_each_step=0.17s, eta=5:3:51\n",
      "2021-12-24 09:27:27 [INFO]\t[TRAIN] Epoch=22/35, Step=3785/7915, loss=0.298094, lr=4.2e-05, time_each_step=0.16s, eta=5:3:5\n",
      "2021-12-24 09:28:00 [INFO]\t[TRAIN] Epoch=22/35, Step=3985/7915, loss=0.116778, lr=4.2e-05, time_each_step=0.17s, eta=5:2:39\n",
      "2021-12-24 09:28:33 [INFO]\t[TRAIN] Epoch=22/35, Step=4185/7915, loss=0.774588, lr=4.2e-05, time_each_step=0.16s, eta=5:1:53\n",
      "2021-12-24 09:29:06 [INFO]\t[TRAIN] Epoch=22/35, Step=4385/7915, loss=0.62417, lr=4.2e-05, time_each_step=0.17s, eta=5:1:30\n",
      "2021-12-24 09:29:39 [INFO]\t[TRAIN] Epoch=22/35, Step=4585/7915, loss=0.224555, lr=4.2e-05, time_each_step=0.16s, eta=5:0:56\n",
      "2021-12-24 09:30:13 [INFO]\t[TRAIN] Epoch=22/35, Step=4785/7915, loss=0.265938, lr=4.2e-05, time_each_step=0.17s, eta=5:0:32\n",
      "2021-12-24 09:30:46 [INFO]\t[TRAIN] Epoch=22/35, Step=4985/7915, loss=1.189864, lr=4.2e-05, time_each_step=0.16s, eta=4:59:50\n",
      "2021-12-24 09:31:19 [INFO]\t[TRAIN] Epoch=22/35, Step=5185/7915, loss=0.393948, lr=4.2e-05, time_each_step=0.17s, eta=4:59:22\n",
      "2021-12-24 09:31:52 [INFO]\t[TRAIN] Epoch=22/35, Step=5385/7915, loss=0.459245, lr=4.2e-05, time_each_step=0.16s, eta=4:58:44\n",
      "2021-12-24 09:32:25 [INFO]\t[TRAIN] Epoch=22/35, Step=5585/7915, loss=0.153257, lr=4.2e-05, time_each_step=0.17s, eta=4:58:14\n",
      "2021-12-24 09:32:59 [INFO]\t[TRAIN] Epoch=22/35, Step=5785/7915, loss=0.244563, lr=4.2e-05, time_each_step=0.17s, eta=4:57:40\n",
      "2021-12-24 09:33:32 [INFO]\t[TRAIN] Epoch=22/35, Step=5985/7915, loss=0.12413, lr=4.2e-05, time_each_step=0.17s, eta=4:57:5\n",
      "2021-12-24 09:34:05 [INFO]\t[TRAIN] Epoch=22/35, Step=6185/7915, loss=0.241475, lr=4.2e-05, time_each_step=0.17s, eta=4:56:34\n",
      "2021-12-24 09:34:38 [INFO]\t[TRAIN] Epoch=22/35, Step=6385/7915, loss=0.594653, lr=4.2e-05, time_each_step=0.17s, eta=4:56:1\n",
      "2021-12-24 09:35:11 [INFO]\t[TRAIN] Epoch=22/35, Step=6585/7915, loss=0.704465, lr=4.1e-05, time_each_step=0.16s, eta=4:55:26\n",
      "2021-12-24 09:35:45 [INFO]\t[TRAIN] Epoch=22/35, Step=6785/7915, loss=0.572709, lr=4.1e-05, time_each_step=0.17s, eta=4:54:53\n",
      "2021-12-24 09:36:18 [INFO]\t[TRAIN] Epoch=22/35, Step=6985/7915, loss=0.194582, lr=4.1e-05, time_each_step=0.17s, eta=4:54:23\n",
      "2021-12-24 09:36:51 [INFO]\t[TRAIN] Epoch=22/35, Step=7185/7915, loss=0.419254, lr=4.1e-05, time_each_step=0.17s, eta=4:53:49\n",
      "2021-12-24 09:37:25 [INFO]\t[TRAIN] Epoch=22/35, Step=7385/7915, loss=1.379517, lr=4.1e-05, time_each_step=0.17s, eta=4:53:15\n",
      "2021-12-24 09:37:58 [INFO]\t[TRAIN] Epoch=22/35, Step=7585/7915, loss=0.443762, lr=4.1e-05, time_each_step=0.17s, eta=4:52:42\n",
      "2021-12-24 09:38:31 [INFO]\t[TRAIN] Epoch=22/35, Step=7785/7915, loss=0.168271, lr=4.1e-05, time_each_step=0.17s, eta=4:52:8\n",
      "2021-12-24 09:38:52 [INFO]\t[TRAIN] Epoch 22 finished, loss=0.413514, lr=4.2e-05 .\n",
      "2021-12-24 09:38:52 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:24<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 09:39:16 [INFO]\t[EVAL] Finished, Epoch=22, miou=0.565378, category_iou=[0.57696794 0.74324916 0.5434789  0.39781457], oacc=0.74143, category_acc=[0.70311086 0.85771788 0.77756669 0.55406376], kappa=0.642431, category_F1-score=[0.7317434  0.85271707 0.70422589 0.56919505] .\n",
      "2021-12-24 09:39:20 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 09:39:24 [INFO]\tModel saved in output/deeplab/epoch_22.\n",
      "2021-12-24 09:39:24 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_22, miou=0.565377642887361\n",
      "2021-12-24 09:39:39 [INFO]\t[TRAIN] Epoch=23/35, Step=70/7915, loss=0.274084, lr=4.1e-05, time_each_step=0.17s, eta=4:51:42\n",
      "2021-12-24 09:40:12 [INFO]\t[TRAIN] Epoch=23/35, Step=270/7915, loss=0.196887, lr=4.1e-05, time_each_step=0.17s, eta=4:51:6\n",
      "2021-12-24 09:40:45 [INFO]\t[TRAIN] Epoch=23/35, Step=470/7915, loss=1.905131, lr=4.1e-05, time_each_step=0.17s, eta=4:50:39\n",
      "2021-12-24 09:41:18 [INFO]\t[TRAIN] Epoch=23/35, Step=670/7915, loss=0.722828, lr=4.1e-05, time_each_step=0.17s, eta=4:50:7\n",
      "2021-12-24 09:41:51 [INFO]\t[TRAIN] Epoch=23/35, Step=870/7915, loss=0.280831, lr=4.1e-05, time_each_step=0.17s, eta=4:49:34\n",
      "2021-12-24 09:42:24 [INFO]\t[TRAIN] Epoch=23/35, Step=1070/7915, loss=0.391291, lr=4.1e-05, time_each_step=0.17s, eta=4:49:6\n",
      "2021-12-24 09:42:57 [INFO]\t[TRAIN] Epoch=23/35, Step=1270/7915, loss=0.069178, lr=4.1e-05, time_each_step=0.17s, eta=4:48:24\n",
      "2021-12-24 09:43:31 [INFO]\t[TRAIN] Epoch=23/35, Step=1470/7915, loss=0.717299, lr=4e-05, time_each_step=0.16s, eta=4:47:42\n",
      "2021-12-24 09:44:04 [INFO]\t[TRAIN] Epoch=23/35, Step=1670/7915, loss=0.787625, lr=4e-05, time_each_step=0.17s, eta=4:47:22\n",
      "2021-12-24 09:44:37 [INFO]\t[TRAIN] Epoch=23/35, Step=1870/7915, loss=0.665239, lr=4e-05, time_each_step=0.17s, eta=4:46:41\n",
      "2021-12-24 09:45:10 [INFO]\t[TRAIN] Epoch=23/35, Step=2070/7915, loss=0.265996, lr=4e-05, time_each_step=0.17s, eta=4:46:10\n",
      "2021-12-24 09:45:43 [INFO]\t[TRAIN] Epoch=23/35, Step=2270/7915, loss=0.74466, lr=4e-05, time_each_step=0.17s, eta=4:45:53\n",
      "2021-12-24 09:46:16 [INFO]\t[TRAIN] Epoch=23/35, Step=2470/7915, loss=0.393325, lr=4e-05, time_each_step=0.17s, eta=4:45:19\n",
      "2021-12-24 09:46:50 [INFO]\t[TRAIN] Epoch=23/35, Step=2670/7915, loss=0.455345, lr=4e-05, time_each_step=0.17s, eta=4:44:45\n",
      "2021-12-24 09:47:23 [INFO]\t[TRAIN] Epoch=23/35, Step=2870/7915, loss=0.357617, lr=4e-05, time_each_step=0.17s, eta=4:43:57\n",
      "2021-12-24 09:47:56 [INFO]\t[TRAIN] Epoch=23/35, Step=3070/7915, loss=0.580781, lr=4e-05, time_each_step=0.17s, eta=4:43:33\n",
      "2021-12-24 09:48:29 [INFO]\t[TRAIN] Epoch=23/35, Step=3270/7915, loss=0.404898, lr=4e-05, time_each_step=0.17s, eta=4:42:56\n",
      "2021-12-24 09:49:02 [INFO]\t[TRAIN] Epoch=23/35, Step=3470/7915, loss=1.329018, lr=4e-05, time_each_step=0.17s, eta=4:42:18\n",
      "2021-12-24 09:49:35 [INFO]\t[TRAIN] Epoch=23/35, Step=3670/7915, loss=0.384992, lr=4e-05, time_each_step=0.17s, eta=4:41:54\n",
      "2021-12-24 09:50:09 [INFO]\t[TRAIN] Epoch=23/35, Step=3870/7915, loss=0.563099, lr=4e-05, time_each_step=0.17s, eta=4:41:21\n",
      "2021-12-24 09:50:42 [INFO]\t[TRAIN] Epoch=23/35, Step=4070/7915, loss=0.565956, lr=4e-05, time_each_step=0.17s, eta=4:40:38\n",
      "2021-12-24 09:51:15 [INFO]\t[TRAIN] Epoch=23/35, Step=4270/7915, loss=0.469539, lr=3.9e-05, time_each_step=0.17s, eta=4:40:9\n",
      "2021-12-24 09:51:48 [INFO]\t[TRAIN] Epoch=23/35, Step=4470/7915, loss=0.521899, lr=3.9e-05, time_each_step=0.17s, eta=4:39:35\n",
      "2021-12-24 09:52:21 [INFO]\t[TRAIN] Epoch=23/35, Step=4670/7915, loss=0.613503, lr=3.9e-05, time_each_step=0.17s, eta=4:39:4\n",
      "2021-12-24 09:52:54 [INFO]\t[TRAIN] Epoch=23/35, Step=4870/7915, loss=0.18048, lr=3.9e-05, time_each_step=0.16s, eta=4:38:22\n",
      "2021-12-24 09:53:28 [INFO]\t[TRAIN] Epoch=23/35, Step=5070/7915, loss=1.097269, lr=3.9e-05, time_each_step=0.17s, eta=4:38:3\n",
      "2021-12-24 09:54:01 [INFO]\t[TRAIN] Epoch=23/35, Step=5270/7915, loss=0.601155, lr=3.9e-05, time_each_step=0.17s, eta=4:37:26\n",
      "2021-12-24 09:54:34 [INFO]\t[TRAIN] Epoch=23/35, Step=5470/7915, loss=0.131888, lr=3.9e-05, time_each_step=0.17s, eta=4:36:49\n",
      "2021-12-24 09:55:07 [INFO]\t[TRAIN] Epoch=23/35, Step=5670/7915, loss=0.586303, lr=3.9e-05, time_each_step=0.17s, eta=4:36:15\n",
      "2021-12-24 09:55:41 [INFO]\t[TRAIN] Epoch=23/35, Step=5870/7915, loss=0.293306, lr=3.9e-05, time_each_step=0.17s, eta=4:35:41\n",
      "2021-12-24 09:56:14 [INFO]\t[TRAIN] Epoch=23/35, Step=6070/7915, loss=0.291059, lr=3.9e-05, time_each_step=0.17s, eta=4:35:10\n",
      "2021-12-24 09:56:47 [INFO]\t[TRAIN] Epoch=23/35, Step=6270/7915, loss=0.499106, lr=3.9e-05, time_each_step=0.16s, eta=4:34:31\n",
      "2021-12-24 09:57:20 [INFO]\t[TRAIN] Epoch=23/35, Step=6470/7915, loss=0.937166, lr=3.9e-05, time_each_step=0.17s, eta=4:34:1\n",
      "2021-12-24 09:57:53 [INFO]\t[TRAIN] Epoch=23/35, Step=6670/7915, loss=0.248863, lr=3.9e-05, time_each_step=0.17s, eta=4:33:29\n",
      "2021-12-24 09:58:26 [INFO]\t[TRAIN] Epoch=23/35, Step=6870/7915, loss=0.567034, lr=3.9e-05, time_each_step=0.17s, eta=4:32:56\n",
      "2021-12-24 09:59:00 [INFO]\t[TRAIN] Epoch=23/35, Step=7070/7915, loss=0.437706, lr=3.8e-05, time_each_step=0.17s, eta=4:32:23\n",
      "2021-12-24 09:59:33 [INFO]\t[TRAIN] Epoch=23/35, Step=7270/7915, loss=0.409868, lr=3.8e-05, time_each_step=0.17s, eta=4:31:50\n",
      "2021-12-24 10:00:06 [INFO]\t[TRAIN] Epoch=23/35, Step=7470/7915, loss=0.358443, lr=3.8e-05, time_each_step=0.17s, eta=4:31:17\n",
      "2021-12-24 10:00:40 [INFO]\t[TRAIN] Epoch=23/35, Step=7670/7915, loss=0.261527, lr=3.8e-05, time_each_step=0.16s, eta=4:30:43\n",
      "2021-12-24 10:01:13 [INFO]\t[TRAIN] Epoch=23/35, Step=7870/7915, loss=0.183117, lr=3.8e-05, time_each_step=0.16s, eta=4:30:10\n",
      "2021-12-24 10:01:20 [INFO]\t[TRAIN] Epoch 23 finished, loss=0.396842, lr=4e-05 .\n",
      "2021-12-24 10:01:20 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:24<00:00, 17.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 10:01:44 [INFO]\t[EVAL] Finished, Epoch=23, miou=0.570989, category_iou=[0.5785123  0.74222438 0.55640434 0.40681614], oacc=0.74489, category_acc=[0.70722343 0.86772419 0.73871122 0.5761512 ], kappa=0.648086, category_F1-score=[0.73298421 0.85204224 0.71498687 0.57835011] .\n",
      "2021-12-24 10:01:48 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 10:01:52 [INFO]\tModel saved in output/deeplab/epoch_23.\n",
      "2021-12-24 10:01:52 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_23, miou=0.570989288073111\n",
      "2021-12-24 10:02:21 [INFO]\t[TRAIN] Epoch=24/35, Step=155/7915, loss=0.184289, lr=3.8e-05, time_each_step=0.16s, eta=4:29:3\n",
      "2021-12-24 10:02:54 [INFO]\t[TRAIN] Epoch=24/35, Step=355/7915, loss=0.329849, lr=3.8e-05, time_each_step=0.17s, eta=4:28:33\n",
      "2021-12-24 10:03:27 [INFO]\t[TRAIN] Epoch=24/35, Step=555/7915, loss=1.016503, lr=3.8e-05, time_each_step=0.16s, eta=4:27:40\n",
      "2021-12-24 10:04:00 [INFO]\t[TRAIN] Epoch=24/35, Step=755/7915, loss=0.061754, lr=3.8e-05, time_each_step=0.16s, eta=4:27:19\n",
      "2021-12-24 10:04:33 [INFO]\t[TRAIN] Epoch=24/35, Step=955/7915, loss=0.299178, lr=3.8e-05, time_each_step=0.16s, eta=4:26:46\n",
      "2021-12-24 10:05:06 [INFO]\t[TRAIN] Epoch=24/35, Step=1155/7915, loss=0.982381, lr=3.8e-05, time_each_step=0.16s, eta=4:26:17\n",
      "2021-12-24 10:05:39 [INFO]\t[TRAIN] Epoch=24/35, Step=1355/7915, loss=0.250032, lr=3.8e-05, time_each_step=0.16s, eta=4:25:45\n",
      "2021-12-24 10:06:12 [INFO]\t[TRAIN] Epoch=24/35, Step=1555/7915, loss=0.684201, lr=3.8e-05, time_each_step=0.16s, eta=4:25:4\n",
      "2021-12-24 10:06:44 [INFO]\t[TRAIN] Epoch=24/35, Step=1755/7915, loss=0.28813, lr=3.8e-05, time_each_step=0.16s, eta=4:24:30\n",
      "2021-12-24 10:07:17 [INFO]\t[TRAIN] Epoch=24/35, Step=1955/7915, loss=1.167981, lr=3.7e-05, time_each_step=0.17s, eta=4:24:24\n",
      "2021-12-24 10:07:50 [INFO]\t[TRAIN] Epoch=24/35, Step=2155/7915, loss=0.409954, lr=3.7e-05, time_each_step=0.16s, eta=4:23:25\n",
      "2021-12-24 10:08:24 [INFO]\t[TRAIN] Epoch=24/35, Step=2355/7915, loss=0.407634, lr=3.7e-05, time_each_step=0.17s, eta=4:23:2\n",
      "2021-12-24 10:08:57 [INFO]\t[TRAIN] Epoch=24/35, Step=2555/7915, loss=0.240173, lr=3.7e-05, time_each_step=0.17s, eta=4:22:29\n",
      "2021-12-24 10:09:30 [INFO]\t[TRAIN] Epoch=24/35, Step=2755/7915, loss=0.29362, lr=3.7e-05, time_each_step=0.16s, eta=4:21:55\n",
      "2021-12-24 10:10:03 [INFO]\t[TRAIN] Epoch=24/35, Step=2955/7915, loss=0.316107, lr=3.7e-05, time_each_step=0.16s, eta=4:21:21\n",
      "2021-12-24 10:10:35 [INFO]\t[TRAIN] Epoch=24/35, Step=3155/7915, loss=0.407087, lr=3.7e-05, time_each_step=0.16s, eta=4:20:47\n",
      "2021-12-24 10:11:09 [INFO]\t[TRAIN] Epoch=24/35, Step=3355/7915, loss=0.424869, lr=3.7e-05, time_each_step=0.17s, eta=4:20:24\n",
      "2021-12-24 10:11:42 [INFO]\t[TRAIN] Epoch=24/35, Step=3555/7915, loss=0.535337, lr=3.7e-05, time_each_step=0.17s, eta=4:19:44\n",
      "2021-12-24 10:12:15 [INFO]\t[TRAIN] Epoch=24/35, Step=3755/7915, loss=0.213508, lr=3.7e-05, time_each_step=0.17s, eta=4:19:16\n",
      "2021-12-24 10:12:48 [INFO]\t[TRAIN] Epoch=24/35, Step=3955/7915, loss=0.346507, lr=3.7e-05, time_each_step=0.17s, eta=4:18:41\n",
      "2021-12-24 10:13:21 [INFO]\t[TRAIN] Epoch=24/35, Step=4155/7915, loss=0.425004, lr=3.7e-05, time_each_step=0.16s, eta=4:17:55\n",
      "2021-12-24 10:13:54 [INFO]\t[TRAIN] Epoch=24/35, Step=4355/7915, loss=0.417814, lr=3.7e-05, time_each_step=0.16s, eta=4:17:31\n",
      "2021-12-24 10:14:27 [INFO]\t[TRAIN] Epoch=24/35, Step=4555/7915, loss=0.155386, lr=3.7e-05, time_each_step=0.16s, eta=4:16:50\n",
      "2021-12-24 10:15:00 [INFO]\t[TRAIN] Epoch=24/35, Step=4755/7915, loss=0.498566, lr=3.6e-05, time_each_step=0.17s, eta=4:16:36\n",
      "2021-12-24 10:15:33 [INFO]\t[TRAIN] Epoch=24/35, Step=4955/7915, loss=0.313814, lr=3.6e-05, time_each_step=0.16s, eta=4:15:45\n",
      "2021-12-24 10:16:06 [INFO]\t[TRAIN] Epoch=24/35, Step=5155/7915, loss=0.409208, lr=3.6e-05, time_each_step=0.17s, eta=4:15:27\n",
      "2021-12-24 10:16:40 [INFO]\t[TRAIN] Epoch=24/35, Step=5355/7915, loss=0.846835, lr=3.6e-05, time_each_step=0.17s, eta=4:14:49\n",
      "2021-12-24 10:17:13 [INFO]\t[TRAIN] Epoch=24/35, Step=5555/7915, loss=0.513994, lr=3.6e-05, time_each_step=0.16s, eta=4:14:8\n",
      "2021-12-24 10:17:46 [INFO]\t[TRAIN] Epoch=24/35, Step=5755/7915, loss=0.094612, lr=3.6e-05, time_each_step=0.17s, eta=4:13:41\n",
      "2021-12-24 10:18:19 [INFO]\t[TRAIN] Epoch=24/35, Step=5955/7915, loss=0.311611, lr=3.6e-05, time_each_step=0.17s, eta=4:13:9\n",
      "2021-12-24 10:18:52 [INFO]\t[TRAIN] Epoch=24/35, Step=6155/7915, loss=0.239074, lr=3.6e-05, time_each_step=0.16s, eta=4:12:34\n",
      "2021-12-24 10:19:25 [INFO]\t[TRAIN] Epoch=24/35, Step=6355/7915, loss=0.964202, lr=3.6e-05, time_each_step=0.17s, eta=4:12:2\n",
      "2021-12-24 10:19:58 [INFO]\t[TRAIN] Epoch=24/35, Step=6555/7915, loss=0.326676, lr=3.6e-05, time_each_step=0.17s, eta=4:11:30\n",
      "2021-12-24 10:20:31 [INFO]\t[TRAIN] Epoch=24/35, Step=6755/7915, loss=0.335156, lr=3.6e-05, time_each_step=0.16s, eta=4:10:55\n",
      "2021-12-24 10:21:04 [INFO]\t[TRAIN] Epoch=24/35, Step=6955/7915, loss=0.223375, lr=3.6e-05, time_each_step=0.17s, eta=4:10:24\n",
      "2021-12-24 10:21:38 [INFO]\t[TRAIN] Epoch=24/35, Step=7155/7915, loss=0.446602, lr=3.6e-05, time_each_step=0.17s, eta=4:9:51\n",
      "2021-12-24 10:22:11 [INFO]\t[TRAIN] Epoch=24/35, Step=7355/7915, loss=0.559269, lr=3.5e-05, time_each_step=0.17s, eta=4:9:18\n",
      "2021-12-24 10:22:44 [INFO]\t[TRAIN] Epoch=24/35, Step=7555/7915, loss=0.515043, lr=3.5e-05, time_each_step=0.16s, eta=4:8:44\n",
      "2021-12-24 10:23:17 [INFO]\t[TRAIN] Epoch=24/35, Step=7755/7915, loss=0.184257, lr=3.5e-05, time_each_step=0.17s, eta=4:8:11\n",
      "2021-12-24 10:23:44 [INFO]\t[TRAIN] Epoch 24 finished, loss=0.389362, lr=3.7e-05 .\n",
      "2021-12-24 10:23:44 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:24<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 10:24:08 [INFO]\t[EVAL] Finished, Epoch=24, miou=0.565937, category_iou=[0.57740735 0.74988709 0.54321547 0.39323747], oacc=0.744945, category_acc=[0.69779749 0.85306752 0.73341524 0.60232942], kappa=0.646233, category_F1-score=[0.73209669 0.85706911 0.7040047  0.56449453] .\n",
      "2021-12-24 10:24:11 [INFO]\tModel saved in output/deeplab/epoch_24.\n",
      "2021-12-24 10:24:11 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_23, miou=0.570989288073111\n",
      "2021-12-24 10:24:21 [INFO]\t[TRAIN] Epoch=25/35, Step=40/7915, loss=0.287917, lr=3.5e-05, time_each_step=0.17s, eta=4:5:59\n",
      "2021-12-24 10:24:54 [INFO]\t[TRAIN] Epoch=25/35, Step=240/7915, loss=0.40531, lr=3.5e-05, time_each_step=0.16s, eta=4:4:28\n",
      "2021-12-24 10:25:27 [INFO]\t[TRAIN] Epoch=25/35, Step=440/7915, loss=0.766948, lr=3.5e-05, time_each_step=0.17s, eta=4:4:14\n",
      "2021-12-24 10:26:00 [INFO]\t[TRAIN] Epoch=25/35, Step=640/7915, loss=0.300585, lr=3.5e-05, time_each_step=0.16s, eta=4:3:29\n",
      "2021-12-24 10:26:33 [INFO]\t[TRAIN] Epoch=25/35, Step=840/7915, loss=0.296513, lr=3.5e-05, time_each_step=0.16s, eta=4:2:55\n",
      "2021-12-24 10:27:06 [INFO]\t[TRAIN] Epoch=25/35, Step=1040/7915, loss=0.513061, lr=3.5e-05, time_each_step=0.17s, eta=4:2:33\n",
      "2021-12-24 10:27:39 [INFO]\t[TRAIN] Epoch=25/35, Step=1240/7915, loss=0.403349, lr=3.5e-05, time_each_step=0.16s, eta=4:1:55\n",
      "2021-12-24 10:28:12 [INFO]\t[TRAIN] Epoch=25/35, Step=1440/7915, loss=0.342606, lr=3.5e-05, time_each_step=0.16s, eta=4:1:6\n",
      "2021-12-24 10:28:44 [INFO]\t[TRAIN] Epoch=25/35, Step=1640/7915, loss=0.488651, lr=3.5e-05, time_each_step=0.16s, eta=4:0:41\n",
      "2021-12-24 10:29:17 [INFO]\t[TRAIN] Epoch=25/35, Step=1840/7915, loss=0.679219, lr=3.5e-05, time_each_step=0.16s, eta=4:0:12\n",
      "2021-12-24 10:29:50 [INFO]\t[TRAIN] Epoch=25/35, Step=2040/7915, loss=0.473171, lr=3.5e-05, time_each_step=0.16s, eta=3:59:42\n",
      "2021-12-24 10:30:23 [INFO]\t[TRAIN] Epoch=25/35, Step=2240/7915, loss=0.113475, lr=3.4e-05, time_each_step=0.16s, eta=3:59:12\n",
      "2021-12-24 10:30:56 [INFO]\t[TRAIN] Epoch=25/35, Step=2440/7915, loss=0.355946, lr=3.4e-05, time_each_step=0.17s, eta=3:58:56\n",
      "2021-12-24 10:31:30 [INFO]\t[TRAIN] Epoch=25/35, Step=2640/7915, loss=0.329261, lr=3.4e-05, time_each_step=0.17s, eta=3:58:9\n",
      "2021-12-24 10:32:02 [INFO]\t[TRAIN] Epoch=25/35, Step=2840/7915, loss=0.315405, lr=3.4e-05, time_each_step=0.16s, eta=3:57:30\n",
      "2021-12-24 10:32:35 [INFO]\t[TRAIN] Epoch=25/35, Step=3040/7915, loss=0.354668, lr=3.4e-05, time_each_step=0.17s, eta=3:57:4\n",
      "2021-12-24 10:33:08 [INFO]\t[TRAIN] Epoch=25/35, Step=3240/7915, loss=0.168777, lr=3.4e-05, time_each_step=0.16s, eta=3:56:25\n",
      "2021-12-24 10:33:41 [INFO]\t[TRAIN] Epoch=25/35, Step=3440/7915, loss=0.477345, lr=3.4e-05, time_each_step=0.16s, eta=3:55:54\n",
      "2021-12-24 10:34:14 [INFO]\t[TRAIN] Epoch=25/35, Step=3640/7915, loss=0.279581, lr=3.4e-05, time_each_step=0.17s, eta=3:55:26\n",
      "2021-12-24 10:34:47 [INFO]\t[TRAIN] Epoch=25/35, Step=3840/7915, loss=0.371334, lr=3.4e-05, time_each_step=0.16s, eta=3:54:47\n",
      "2021-12-24 10:35:20 [INFO]\t[TRAIN] Epoch=25/35, Step=4040/7915, loss=0.542297, lr=3.4e-05, time_each_step=0.16s, eta=3:54:10\n",
      "2021-12-24 10:35:52 [INFO]\t[TRAIN] Epoch=25/35, Step=4240/7915, loss=0.124318, lr=3.4e-05, time_each_step=0.16s, eta=3:53:36\n",
      "2021-12-24 10:36:25 [INFO]\t[TRAIN] Epoch=25/35, Step=4440/7915, loss=0.316656, lr=3.4e-05, time_each_step=0.16s, eta=3:53:8\n",
      "2021-12-24 10:36:58 [INFO]\t[TRAIN] Epoch=25/35, Step=4640/7915, loss=0.173036, lr=3.4e-05, time_each_step=0.17s, eta=3:52:45\n",
      "2021-12-24 10:37:31 [INFO]\t[TRAIN] Epoch=25/35, Step=4840/7915, loss=0.458127, lr=3.4e-05, time_each_step=0.16s, eta=3:52:0\n",
      "2021-12-24 10:38:04 [INFO]\t[TRAIN] Epoch=25/35, Step=5040/7915, loss=0.248366, lr=3.3e-05, time_each_step=0.16s, eta=3:51:29\n",
      "2021-12-24 10:38:37 [INFO]\t[TRAIN] Epoch=25/35, Step=5240/7915, loss=0.115504, lr=3.3e-05, time_each_step=0.16s, eta=3:50:57\n",
      "2021-12-24 10:39:10 [INFO]\t[TRAIN] Epoch=25/35, Step=5440/7915, loss=0.640925, lr=3.3e-05, time_each_step=0.16s, eta=3:50:20\n",
      "2021-12-24 10:39:43 [INFO]\t[TRAIN] Epoch=25/35, Step=5640/7915, loss=0.60393, lr=3.3e-05, time_each_step=0.17s, eta=3:49:58\n",
      "2021-12-24 10:40:16 [INFO]\t[TRAIN] Epoch=25/35, Step=5840/7915, loss=0.252533, lr=3.3e-05, time_each_step=0.16s, eta=3:49:18\n",
      "2021-12-24 10:40:49 [INFO]\t[TRAIN] Epoch=25/35, Step=6040/7915, loss=0.255306, lr=3.3e-05, time_each_step=0.16s, eta=3:48:45\n",
      "2021-12-24 10:41:22 [INFO]\t[TRAIN] Epoch=25/35, Step=6240/7915, loss=1.02934, lr=3.3e-05, time_each_step=0.17s, eta=3:48:17\n",
      "2021-12-24 10:41:55 [INFO]\t[TRAIN] Epoch=25/35, Step=6440/7915, loss=0.395896, lr=3.3e-05, time_each_step=0.17s, eta=3:47:41\n",
      "2021-12-24 10:42:28 [INFO]\t[TRAIN] Epoch=25/35, Step=6640/7915, loss=0.482069, lr=3.3e-05, time_each_step=0.17s, eta=3:47:9\n",
      "2021-12-24 10:43:01 [INFO]\t[TRAIN] Epoch=25/35, Step=6840/7915, loss=0.241146, lr=3.3e-05, time_each_step=0.16s, eta=3:46:33\n",
      "2021-12-24 10:43:34 [INFO]\t[TRAIN] Epoch=25/35, Step=7040/7915, loss=0.288949, lr=3.3e-05, time_each_step=0.17s, eta=3:46:1\n",
      "2021-12-24 10:44:08 [INFO]\t[TRAIN] Epoch=25/35, Step=7240/7915, loss=0.377737, lr=3.3e-05, time_each_step=0.17s, eta=3:45:29\n",
      "2021-12-24 10:44:41 [INFO]\t[TRAIN] Epoch=25/35, Step=7440/7915, loss=0.37282, lr=3.3e-05, time_each_step=0.16s, eta=3:44:54\n",
      "2021-12-24 10:45:14 [INFO]\t[TRAIN] Epoch=25/35, Step=7640/7915, loss=0.233118, lr=3.2e-05, time_each_step=0.16s, eta=3:44:21\n",
      "2021-12-24 10:45:47 [INFO]\t[TRAIN] Epoch=25/35, Step=7840/7915, loss=0.294341, lr=3.2e-05, time_each_step=0.17s, eta=3:43:49\n",
      "2021-12-24 10:45:59 [INFO]\t[TRAIN] Epoch 25 finished, loss=0.377737, lr=3.4e-05 .\n",
      "2021-12-24 10:45:59 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 10:46:22 [INFO]\t[EVAL] Finished, Epoch=25, miou=0.570197, category_iou=[0.59103328 0.74004211 0.55895348 0.39075941], oacc=0.747893, category_acc=[0.69445377 0.85344865 0.75858288 0.60692978], kappa=0.650013, category_F1-score=[0.74295527 0.85060253 0.71708808 0.56193674] .\n",
      "2021-12-24 10:46:26 [INFO]\tModel saved in output/deeplab/epoch_25.\n",
      "2021-12-24 10:46:26 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_23, miou=0.570989288073111\n",
      "2021-12-24 10:46:50 [INFO]\t[TRAIN] Epoch=26/35, Step=125/7915, loss=0.303938, lr=3.2e-05, time_each_step=0.16s, eta=3:41:49\n",
      "2021-12-24 10:47:22 [INFO]\t[TRAIN] Epoch=26/35, Step=325/7915, loss=0.435041, lr=3.2e-05, time_each_step=0.17s, eta=3:41:49\n",
      "2021-12-24 10:47:55 [INFO]\t[TRAIN] Epoch=26/35, Step=525/7915, loss=0.837106, lr=3.2e-05, time_each_step=0.16s, eta=3:40:47\n",
      "2021-12-24 10:48:28 [INFO]\t[TRAIN] Epoch=26/35, Step=725/7915, loss=0.581083, lr=3.2e-05, time_each_step=0.17s, eta=3:40:31\n",
      "2021-12-24 10:49:01 [INFO]\t[TRAIN] Epoch=26/35, Step=925/7915, loss=0.399304, lr=3.2e-05, time_each_step=0.17s, eta=3:40:4\n",
      "2021-12-24 10:49:34 [INFO]\t[TRAIN] Epoch=26/35, Step=1125/7915, loss=0.782102, lr=3.2e-05, time_each_step=0.16s, eta=3:39:21\n",
      "2021-12-24 10:50:07 [INFO]\t[TRAIN] Epoch=26/35, Step=1325/7915, loss=0.327727, lr=3.2e-05, time_each_step=0.17s, eta=3:38:50\n",
      "2021-12-24 10:50:40 [INFO]\t[TRAIN] Epoch=26/35, Step=1525/7915, loss=0.263202, lr=3.2e-05, time_each_step=0.16s, eta=3:38:13\n",
      "2021-12-24 10:51:13 [INFO]\t[TRAIN] Epoch=26/35, Step=1725/7915, loss=0.121066, lr=3.2e-05, time_each_step=0.17s, eta=3:37:51\n",
      "2021-12-24 10:51:47 [INFO]\t[TRAIN] Epoch=26/35, Step=1925/7915, loss=0.240712, lr=3.2e-05, time_each_step=0.17s, eta=3:37:18\n",
      "2021-12-24 10:52:20 [INFO]\t[TRAIN] Epoch=26/35, Step=2125/7915, loss=0.391116, lr=3.2e-05, time_each_step=0.16s, eta=3:36:18\n",
      "2021-12-24 10:52:53 [INFO]\t[TRAIN] Epoch=26/35, Step=2325/7915, loss=0.741808, lr=3.2e-05, time_each_step=0.17s, eta=3:36:5\n",
      "2021-12-24 10:53:26 [INFO]\t[TRAIN] Epoch=26/35, Step=2525/7915, loss=0.44674, lr=3.1e-05, time_each_step=0.17s, eta=3:35:35\n",
      "2021-12-24 10:53:59 [INFO]\t[TRAIN] Epoch=26/35, Step=2725/7915, loss=0.262907, lr=3.1e-05, time_each_step=0.16s, eta=3:34:45\n",
      "2021-12-24 10:54:32 [INFO]\t[TRAIN] Epoch=26/35, Step=2925/7915, loss=0.405794, lr=3.1e-05, time_each_step=0.16s, eta=3:34:18\n",
      "2021-12-24 10:55:05 [INFO]\t[TRAIN] Epoch=26/35, Step=3125/7915, loss=0.847829, lr=3.1e-05, time_each_step=0.17s, eta=3:33:56\n",
      "2021-12-24 10:55:38 [INFO]\t[TRAIN] Epoch=26/35, Step=3325/7915, loss=0.261667, lr=3.1e-05, time_each_step=0.17s, eta=3:33:20\n",
      "2021-12-24 10:56:11 [INFO]\t[TRAIN] Epoch=26/35, Step=3525/7915, loss=1.219299, lr=3.1e-05, time_each_step=0.16s, eta=3:32:45\n",
      "2021-12-24 10:56:44 [INFO]\t[TRAIN] Epoch=26/35, Step=3725/7915, loss=0.21393, lr=3.1e-05, time_each_step=0.17s, eta=3:32:21\n",
      "2021-12-24 10:57:17 [INFO]\t[TRAIN] Epoch=26/35, Step=3925/7915, loss=0.152438, lr=3.1e-05, time_each_step=0.16s, eta=3:31:37\n",
      "2021-12-24 10:57:50 [INFO]\t[TRAIN] Epoch=26/35, Step=4125/7915, loss=0.275275, lr=3.1e-05, time_each_step=0.16s, eta=3:30:56\n",
      "2021-12-24 10:58:22 [INFO]\t[TRAIN] Epoch=26/35, Step=4325/7915, loss=0.836825, lr=3.1e-05, time_each_step=0.16s, eta=3:30:27\n",
      "2021-12-24 10:58:55 [INFO]\t[TRAIN] Epoch=26/35, Step=4525/7915, loss=0.247136, lr=3.1e-05, time_each_step=0.16s, eta=3:29:57\n",
      "2021-12-24 10:59:28 [INFO]\t[TRAIN] Epoch=26/35, Step=4725/7915, loss=0.2535, lr=3.1e-05, time_each_step=0.16s, eta=3:29:25\n",
      "2021-12-24 11:00:01 [INFO]\t[TRAIN] Epoch=26/35, Step=4925/7915, loss=0.334583, lr=3.1e-05, time_each_step=0.16s, eta=3:28:46\n",
      "2021-12-24 11:00:34 [INFO]\t[TRAIN] Epoch=26/35, Step=5125/7915, loss=0.478074, lr=3e-05, time_each_step=0.17s, eta=3:28:24\n",
      "2021-12-24 11:01:08 [INFO]\t[TRAIN] Epoch=26/35, Step=5325/7915, loss=0.212417, lr=3e-05, time_each_step=0.17s, eta=3:27:52\n",
      "2021-12-24 11:01:41 [INFO]\t[TRAIN] Epoch=26/35, Step=5525/7915, loss=0.322815, lr=3e-05, time_each_step=0.17s, eta=3:27:17\n",
      "2021-12-24 11:02:14 [INFO]\t[TRAIN] Epoch=26/35, Step=5725/7915, loss=0.55943, lr=3e-05, time_each_step=0.17s, eta=3:26:46\n",
      "2021-12-24 11:02:47 [INFO]\t[TRAIN] Epoch=26/35, Step=5925/7915, loss=0.190494, lr=3e-05, time_each_step=0.16s, eta=3:26:8\n",
      "2021-12-24 11:03:20 [INFO]\t[TRAIN] Epoch=26/35, Step=6125/7915, loss=0.511566, lr=3e-05, time_each_step=0.17s, eta=3:25:38\n",
      "2021-12-24 11:03:53 [INFO]\t[TRAIN] Epoch=26/35, Step=6325/7915, loss=0.512589, lr=3e-05, time_each_step=0.16s, eta=3:25:2\n",
      "2021-12-24 11:04:26 [INFO]\t[TRAIN] Epoch=26/35, Step=6525/7915, loss=0.171219, lr=3e-05, time_each_step=0.17s, eta=3:24:31\n",
      "2021-12-24 11:05:00 [INFO]\t[TRAIN] Epoch=26/35, Step=6725/7915, loss=0.689245, lr=3e-05, time_each_step=0.16s, eta=3:23:56\n",
      "2021-12-24 11:05:33 [INFO]\t[TRAIN] Epoch=26/35, Step=6925/7915, loss=0.469624, lr=3e-05, time_each_step=0.17s, eta=3:23:26\n",
      "2021-12-24 11:06:06 [INFO]\t[TRAIN] Epoch=26/35, Step=7125/7915, loss=0.181095, lr=3e-05, time_each_step=0.17s, eta=3:22:53\n",
      "2021-12-24 11:06:39 [INFO]\t[TRAIN] Epoch=26/35, Step=7325/7915, loss=0.170862, lr=3e-05, time_each_step=0.16s, eta=3:22:18\n",
      "2021-12-24 11:07:12 [INFO]\t[TRAIN] Epoch=26/35, Step=7525/7915, loss=0.637047, lr=3e-05, time_each_step=0.17s, eta=3:21:46\n",
      "2021-12-24 11:07:45 [INFO]\t[TRAIN] Epoch=26/35, Step=7725/7915, loss=0.269818, lr=3e-05, time_each_step=0.17s, eta=3:21:13\n",
      "2021-12-24 11:08:17 [INFO]\t[TRAIN] Epoch 26 finished, loss=0.369922, lr=3.1e-05 .\n",
      "2021-12-24 11:08:17 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 11:08:41 [INFO]\t[EVAL] Finished, Epoch=26, miou=0.567666, category_iou=[0.58326813 0.73842291 0.55456123 0.39441005], oacc=0.74497, category_acc=[0.68895748 0.85505975 0.76292538 0.59881515], kappa=0.646182, category_F1-score=[0.73679008 0.84953196 0.71346335 0.56570168] .\n",
      "2021-12-24 11:08:44 [INFO]\tModel saved in output/deeplab/epoch_26.\n",
      "2021-12-24 11:08:44 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_23, miou=0.570989288073111\n",
      "2021-12-24 11:08:49 [INFO]\t[TRAIN] Epoch=27/35, Step=10/7915, loss=0.248318, lr=2.9e-05, time_each_step=0.32s, eta=3:40:22\n",
      "2021-12-24 11:09:22 [INFO]\t[TRAIN] Epoch=27/35, Step=210/7915, loss=0.260042, lr=2.9e-05, time_each_step=0.16s, eta=3:19:58\n",
      "2021-12-24 11:09:55 [INFO]\t[TRAIN] Epoch=27/35, Step=410/7915, loss=0.316094, lr=2.9e-05, time_each_step=0.16s, eta=3:19:17\n",
      "2021-12-24 11:10:28 [INFO]\t[TRAIN] Epoch=27/35, Step=610/7915, loss=0.211513, lr=2.9e-05, time_each_step=0.16s, eta=3:18:31\n",
      "2021-12-24 11:11:01 [INFO]\t[TRAIN] Epoch=27/35, Step=810/7915, loss=0.109579, lr=2.9e-05, time_each_step=0.16s, eta=3:18:13\n",
      "2021-12-24 11:11:34 [INFO]\t[TRAIN] Epoch=27/35, Step=1010/7915, loss=0.282851, lr=2.9e-05, time_each_step=0.16s, eta=3:17:46\n",
      "2021-12-24 11:12:07 [INFO]\t[TRAIN] Epoch=27/35, Step=1210/7915, loss=0.295026, lr=2.9e-05, time_each_step=0.16s, eta=3:16:53\n",
      "2021-12-24 11:12:40 [INFO]\t[TRAIN] Epoch=27/35, Step=1410/7915, loss=0.897605, lr=2.9e-05, time_each_step=0.17s, eta=3:16:48\n",
      "2021-12-24 11:13:13 [INFO]\t[TRAIN] Epoch=27/35, Step=1610/7915, loss=0.357558, lr=2.9e-05, time_each_step=0.17s, eta=3:16:24\n",
      "2021-12-24 11:13:46 [INFO]\t[TRAIN] Epoch=27/35, Step=1810/7915, loss=0.128786, lr=2.9e-05, time_each_step=0.17s, eta=3:15:42\n",
      "2021-12-24 11:14:19 [INFO]\t[TRAIN] Epoch=27/35, Step=2010/7915, loss=0.515123, lr=2.9e-05, time_each_step=0.17s, eta=3:15:21\n",
      "2021-12-24 11:14:52 [INFO]\t[TRAIN] Epoch=27/35, Step=2210/7915, loss=0.689134, lr=2.9e-05, time_each_step=0.16s, eta=3:14:4\n",
      "2021-12-24 11:15:25 [INFO]\t[TRAIN] Epoch=27/35, Step=2410/7915, loss=0.063126, lr=2.9e-05, time_each_step=0.17s, eta=3:14:18\n",
      "2021-12-24 11:15:59 [INFO]\t[TRAIN] Epoch=27/35, Step=2610/7915, loss=0.304738, lr=2.8e-05, time_each_step=0.17s, eta=3:13:36\n",
      "2021-12-24 11:16:31 [INFO]\t[TRAIN] Epoch=27/35, Step=2810/7915, loss=0.228689, lr=2.8e-05, time_each_step=0.16s, eta=3:12:40\n",
      "2021-12-24 11:17:04 [INFO]\t[TRAIN] Epoch=27/35, Step=3010/7915, loss=0.146338, lr=2.8e-05, time_each_step=0.17s, eta=3:12:25\n",
      "2021-12-24 11:17:37 [INFO]\t[TRAIN] Epoch=27/35, Step=3210/7915, loss=0.535764, lr=2.8e-05, time_each_step=0.17s, eta=3:11:55\n",
      "2021-12-24 11:18:11 [INFO]\t[TRAIN] Epoch=27/35, Step=3410/7915, loss=0.633367, lr=2.8e-05, time_each_step=0.17s, eta=3:11:25\n",
      "2021-12-24 11:18:43 [INFO]\t[TRAIN] Epoch=27/35, Step=3610/7915, loss=0.353641, lr=2.8e-05, time_each_step=0.16s, eta=3:10:38\n",
      "2021-12-24 11:19:16 [INFO]\t[TRAIN] Epoch=27/35, Step=3810/7915, loss=0.381728, lr=2.8e-05, time_each_step=0.16s, eta=3:9:59\n",
      "2021-12-24 11:19:50 [INFO]\t[TRAIN] Epoch=27/35, Step=4010/7915, loss=0.954264, lr=2.8e-05, time_each_step=0.16s, eta=3:9:35\n",
      "2021-12-24 11:20:22 [INFO]\t[TRAIN] Epoch=27/35, Step=4210/7915, loss=0.186896, lr=2.8e-05, time_each_step=0.17s, eta=3:9:7\n",
      "2021-12-24 11:20:55 [INFO]\t[TRAIN] Epoch=27/35, Step=4410/7915, loss=1.051237, lr=2.8e-05, time_each_step=0.17s, eta=3:8:32\n",
      "2021-12-24 11:21:28 [INFO]\t[TRAIN] Epoch=27/35, Step=4610/7915, loss=0.119324, lr=2.8e-05, time_each_step=0.16s, eta=3:7:44\n",
      "2021-12-24 11:22:01 [INFO]\t[TRAIN] Epoch=27/35, Step=4810/7915, loss=0.258368, lr=2.8e-05, time_each_step=0.17s, eta=3:7:27\n",
      "2021-12-24 11:22:34 [INFO]\t[TRAIN] Epoch=27/35, Step=5010/7915, loss=0.274903, lr=2.8e-05, time_each_step=0.17s, eta=3:6:59\n",
      "2021-12-24 11:23:08 [INFO]\t[TRAIN] Epoch=27/35, Step=5210/7915, loss=0.43664, lr=2.8e-05, time_each_step=0.17s, eta=3:6:18\n",
      "2021-12-24 11:23:41 [INFO]\t[TRAIN] Epoch=27/35, Step=5410/7915, loss=0.372561, lr=2.7e-05, time_each_step=0.16s, eta=3:5:42\n",
      "2021-12-24 11:24:14 [INFO]\t[TRAIN] Epoch=27/35, Step=5610/7915, loss=0.532895, lr=2.7e-05, time_each_step=0.17s, eta=3:5:17\n",
      "2021-12-24 11:24:47 [INFO]\t[TRAIN] Epoch=27/35, Step=5810/7915, loss=0.388406, lr=2.7e-05, time_each_step=0.17s, eta=3:4:42\n",
      "2021-12-24 11:25:20 [INFO]\t[TRAIN] Epoch=27/35, Step=6010/7915, loss=0.347209, lr=2.7e-05, time_each_step=0.16s, eta=3:3:57\n",
      "2021-12-24 11:25:53 [INFO]\t[TRAIN] Epoch=27/35, Step=6210/7915, loss=0.23392, lr=2.7e-05, time_each_step=0.17s, eta=3:3:37\n",
      "2021-12-24 11:26:26 [INFO]\t[TRAIN] Epoch=27/35, Step=6410/7915, loss=0.203885, lr=2.7e-05, time_each_step=0.16s, eta=3:2:59\n",
      "2021-12-24 11:26:59 [INFO]\t[TRAIN] Epoch=27/35, Step=6610/7915, loss=0.39821, lr=2.7e-05, time_each_step=0.17s, eta=3:2:28\n",
      "2021-12-24 11:27:32 [INFO]\t[TRAIN] Epoch=27/35, Step=6810/7915, loss=0.530538, lr=2.7e-05, time_each_step=0.16s, eta=3:1:53\n",
      "2021-12-24 11:28:05 [INFO]\t[TRAIN] Epoch=27/35, Step=7010/7915, loss=0.351943, lr=2.7e-05, time_each_step=0.17s, eta=3:1:23\n",
      "2021-12-24 11:28:38 [INFO]\t[TRAIN] Epoch=27/35, Step=7210/7915, loss=0.252856, lr=2.7e-05, time_each_step=0.17s, eta=3:0:48\n",
      "2021-12-24 11:29:12 [INFO]\t[TRAIN] Epoch=27/35, Step=7410/7915, loss=0.367606, lr=2.7e-05, time_each_step=0.17s, eta=3:0:15\n",
      "2021-12-24 11:29:45 [INFO]\t[TRAIN] Epoch=27/35, Step=7610/7915, loss=0.092359, lr=2.7e-05, time_each_step=0.17s, eta=2:59:42\n",
      "2021-12-24 11:30:18 [INFO]\t[TRAIN] Epoch=27/35, Step=7810/7915, loss=0.239639, lr=2.7e-05, time_each_step=0.16s, eta=2:59:9\n",
      "2021-12-24 11:30:35 [INFO]\t[TRAIN] Epoch 27 finished, loss=0.356746, lr=2.8e-05 .\n",
      "2021-12-24 11:30:35 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 11:30:59 [INFO]\t[EVAL] Finished, Epoch=27, miou=0.567214, category_iou=[0.58289351 0.73962859 0.5462532  0.40008136], oacc=0.743337, category_acc=[0.72297627 0.84618228 0.75646656 0.55996805], kappa=0.645199, category_F1-score=[0.73649112 0.85032931 0.70655078 0.57151158] .\n",
      "2021-12-24 11:31:02 [INFO]\tModel saved in output/deeplab/epoch_27.\n",
      "2021-12-24 11:31:02 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_23, miou=0.570989288073111\n",
      "2021-12-24 11:31:21 [INFO]\t[TRAIN] Epoch=28/35, Step=95/7915, loss=0.641917, lr=2.6e-05, time_each_step=0.16s, eta=2:58:3\n",
      "2021-12-24 11:31:54 [INFO]\t[TRAIN] Epoch=28/35, Step=295/7915, loss=0.286104, lr=2.6e-05, time_each_step=0.16s, eta=2:57:21\n",
      "2021-12-24 11:32:27 [INFO]\t[TRAIN] Epoch=28/35, Step=495/7915, loss=0.703054, lr=2.6e-05, time_each_step=0.16s, eta=2:56:42\n",
      "2021-12-24 11:33:00 [INFO]\t[TRAIN] Epoch=28/35, Step=695/7915, loss=0.15552, lr=2.6e-05, time_each_step=0.16s, eta=2:56:13\n",
      "2021-12-24 11:33:33 [INFO]\t[TRAIN] Epoch=28/35, Step=895/7915, loss=0.431385, lr=2.6e-05, time_each_step=0.16s, eta=2:55:45\n",
      "2021-12-24 11:34:06 [INFO]\t[TRAIN] Epoch=28/35, Step=1095/7915, loss=0.392286, lr=2.6e-05, time_each_step=0.17s, eta=2:55:29\n",
      "2021-12-24 11:34:39 [INFO]\t[TRAIN] Epoch=28/35, Step=1295/7915, loss=0.22403, lr=2.6e-05, time_each_step=0.17s, eta=2:54:54\n",
      "2021-12-24 11:35:12 [INFO]\t[TRAIN] Epoch=28/35, Step=1495/7915, loss=0.206802, lr=2.6e-05, time_each_step=0.16s, eta=2:54:6\n",
      "2021-12-24 11:35:45 [INFO]\t[TRAIN] Epoch=28/35, Step=1695/7915, loss=0.474577, lr=2.6e-05, time_each_step=0.16s, eta=2:53:32\n",
      "2021-12-24 11:36:18 [INFO]\t[TRAIN] Epoch=28/35, Step=1895/7915, loss=0.362327, lr=2.6e-05, time_each_step=0.17s, eta=2:53:9\n",
      "2021-12-24 11:36:51 [INFO]\t[TRAIN] Epoch=28/35, Step=2095/7915, loss=0.27746, lr=2.6e-05, time_each_step=0.16s, eta=2:52:30\n",
      "2021-12-24 11:37:24 [INFO]\t[TRAIN] Epoch=28/35, Step=2295/7915, loss=0.4335, lr=2.6e-05, time_each_step=0.17s, eta=2:52:13\n",
      "2021-12-24 11:37:57 [INFO]\t[TRAIN] Epoch=28/35, Step=2495/7915, loss=0.387098, lr=2.6e-05, time_each_step=0.17s, eta=2:51:28\n",
      "2021-12-24 11:38:30 [INFO]\t[TRAIN] Epoch=28/35, Step=2695/7915, loss=0.533327, lr=2.5e-05, time_each_step=0.17s, eta=2:51:4\n",
      "2021-12-24 11:39:04 [INFO]\t[TRAIN] Epoch=28/35, Step=2895/7915, loss=0.562322, lr=2.5e-05, time_each_step=0.17s, eta=2:50:27\n",
      "2021-12-24 11:39:37 [INFO]\t[TRAIN] Epoch=28/35, Step=3095/7915, loss=0.3323, lr=2.5e-05, time_each_step=0.16s, eta=2:49:48\n",
      "2021-12-24 11:40:10 [INFO]\t[TRAIN] Epoch=28/35, Step=3295/7915, loss=0.117828, lr=2.5e-05, time_each_step=0.17s, eta=2:49:18\n",
      "2021-12-24 11:40:43 [INFO]\t[TRAIN] Epoch=28/35, Step=3495/7915, loss=0.549547, lr=2.5e-05, time_each_step=0.16s, eta=2:48:42\n",
      "2021-12-24 11:41:16 [INFO]\t[TRAIN] Epoch=28/35, Step=3695/7915, loss=0.60047, lr=2.5e-05, time_each_step=0.17s, eta=2:48:18\n",
      "2021-12-24 11:41:49 [INFO]\t[TRAIN] Epoch=28/35, Step=3895/7915, loss=0.264044, lr=2.5e-05, time_each_step=0.17s, eta=2:47:47\n",
      "2021-12-24 11:42:22 [INFO]\t[TRAIN] Epoch=28/35, Step=4095/7915, loss=0.090819, lr=2.5e-05, time_each_step=0.16s, eta=2:46:57\n",
      "2021-12-24 11:42:55 [INFO]\t[TRAIN] Epoch=28/35, Step=4295/7915, loss=0.197385, lr=2.5e-05, time_each_step=0.16s, eta=2:46:24\n",
      "2021-12-24 11:43:28 [INFO]\t[TRAIN] Epoch=28/35, Step=4495/7915, loss=0.086599, lr=2.5e-05, time_each_step=0.17s, eta=2:46:1\n",
      "2021-12-24 11:44:01 [INFO]\t[TRAIN] Epoch=28/35, Step=4695/7915, loss=0.061587, lr=2.5e-05, time_each_step=0.17s, eta=2:45:31\n",
      "2021-12-24 11:44:34 [INFO]\t[TRAIN] Epoch=28/35, Step=4895/7915, loss=0.240987, lr=2.5e-05, time_each_step=0.16s, eta=2:44:51\n",
      "2021-12-24 11:45:07 [INFO]\t[TRAIN] Epoch=28/35, Step=5095/7915, loss=0.323924, lr=2.5e-05, time_each_step=0.17s, eta=2:44:20\n",
      "2021-12-24 11:45:40 [INFO]\t[TRAIN] Epoch=28/35, Step=5295/7915, loss=0.639865, lr=2.4e-05, time_each_step=0.17s, eta=2:43:50\n",
      "2021-12-24 11:46:13 [INFO]\t[TRAIN] Epoch=28/35, Step=5495/7915, loss=0.564205, lr=2.4e-05, time_each_step=0.17s, eta=2:43:13\n",
      "2021-12-24 11:46:47 [INFO]\t[TRAIN] Epoch=28/35, Step=5695/7915, loss=0.326492, lr=2.4e-05, time_each_step=0.17s, eta=2:42:43\n",
      "2021-12-24 11:47:20 [INFO]\t[TRAIN] Epoch=28/35, Step=5895/7915, loss=0.300508, lr=2.4e-05, time_each_step=0.17s, eta=2:42:11\n",
      "2021-12-24 11:47:53 [INFO]\t[TRAIN] Epoch=28/35, Step=6095/7915, loss=0.35057, lr=2.4e-05, time_each_step=0.17s, eta=2:41:34\n",
      "2021-12-24 11:48:26 [INFO]\t[TRAIN] Epoch=28/35, Step=6295/7915, loss=0.274876, lr=2.4e-05, time_each_step=0.17s, eta=2:41:1\n",
      "2021-12-24 11:48:59 [INFO]\t[TRAIN] Epoch=28/35, Step=6495/7915, loss=0.477374, lr=2.4e-05, time_each_step=0.17s, eta=2:40:30\n",
      "2021-12-24 11:49:32 [INFO]\t[TRAIN] Epoch=28/35, Step=6695/7915, loss=0.555449, lr=2.4e-05, time_each_step=0.17s, eta=2:39:57\n",
      "2021-12-24 11:50:05 [INFO]\t[TRAIN] Epoch=28/35, Step=6895/7915, loss=0.160263, lr=2.4e-05, time_each_step=0.17s, eta=2:39:23\n",
      "2021-12-24 11:50:38 [INFO]\t[TRAIN] Epoch=28/35, Step=7095/7915, loss=0.260585, lr=2.4e-05, time_each_step=0.17s, eta=2:38:49\n",
      "2021-12-24 11:51:12 [INFO]\t[TRAIN] Epoch=28/35, Step=7295/7915, loss=0.350709, lr=2.4e-05, time_each_step=0.16s, eta=2:38:15\n",
      "2021-12-24 11:51:45 [INFO]\t[TRAIN] Epoch=28/35, Step=7495/7915, loss=0.338445, lr=2.4e-05, time_each_step=0.17s, eta=2:37:43\n",
      "2021-12-24 11:52:18 [INFO]\t[TRAIN] Epoch=28/35, Step=7695/7915, loss=0.297555, lr=2.4e-05, time_each_step=0.16s, eta=2:37:9\n",
      "2021-12-24 11:52:50 [INFO]\t[TRAIN] Epoch=28/35, Step=7895/7915, loss=0.324165, lr=2.4e-05, time_each_step=0.16s, eta=2:36:36\n",
      "2021-12-24 11:52:54 [INFO]\t[TRAIN] Epoch 28 finished, loss=0.348565, lr=2.5e-05 .\n",
      "2021-12-24 11:52:54 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 11:53:18 [INFO]\t[EVAL] Finished, Epoch=28, miou=0.574606, category_iou=[0.59476671 0.75338304 0.54429625 0.40597828], oacc=0.752008, category_acc=[0.71757029 0.84620644 0.76929866 0.59185385], kappa=0.655751, category_F1-score=[0.74589808 0.85934792 0.7049117  0.57750292] .\n",
      "2021-12-24 11:53:22 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 11:53:25 [INFO]\tModel saved in output/deeplab/epoch_28.\n",
      "2021-12-24 11:53:25 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_28, miou=0.5746060701440677\n",
      "2021-12-24 11:53:58 [INFO]\t[TRAIN] Epoch=29/35, Step=180/7915, loss=0.306532, lr=2.3e-05, time_each_step=0.17s, eta=2:36:5\n",
      "2021-12-24 11:54:31 [INFO]\t[TRAIN] Epoch=29/35, Step=380/7915, loss=0.773949, lr=2.3e-05, time_each_step=0.16s, eta=2:35:31\n",
      "2021-12-24 11:55:04 [INFO]\t[TRAIN] Epoch=29/35, Step=580/7915, loss=0.703882, lr=2.3e-05, time_each_step=0.16s, eta=2:34:37\n",
      "2021-12-24 11:55:37 [INFO]\t[TRAIN] Epoch=29/35, Step=780/7915, loss=0.303577, lr=2.3e-05, time_each_step=0.16s, eta=2:34:13\n",
      "2021-12-24 11:56:10 [INFO]\t[TRAIN] Epoch=29/35, Step=980/7915, loss=0.460042, lr=2.3e-05, time_each_step=0.16s, eta=2:33:32\n",
      "2021-12-24 11:56:43 [INFO]\t[TRAIN] Epoch=29/35, Step=1180/7915, loss=0.510339, lr=2.3e-05, time_each_step=0.17s, eta=2:33:35\n",
      "2021-12-24 11:57:16 [INFO]\t[TRAIN] Epoch=29/35, Step=1380/7915, loss=0.425264, lr=2.3e-05, time_each_step=0.17s, eta=2:32:56\n",
      "2021-12-24 11:57:49 [INFO]\t[TRAIN] Epoch=29/35, Step=1580/7915, loss=0.518352, lr=2.3e-05, time_each_step=0.17s, eta=2:32:35\n",
      "2021-12-24 11:58:22 [INFO]\t[TRAIN] Epoch=29/35, Step=1780/7915, loss=0.173913, lr=2.3e-05, time_each_step=0.17s, eta=2:32:2\n",
      "2021-12-24 11:58:55 [INFO]\t[TRAIN] Epoch=29/35, Step=1980/7915, loss=0.301661, lr=2.3e-05, time_each_step=0.17s, eta=2:31:25\n",
      "2021-12-24 11:59:28 [INFO]\t[TRAIN] Epoch=29/35, Step=2180/7915, loss=0.324576, lr=2.3e-05, time_each_step=0.16s, eta=2:30:26\n",
      "2021-12-24 12:00:01 [INFO]\t[TRAIN] Epoch=29/35, Step=2380/7915, loss=0.166472, lr=2.3e-05, time_each_step=0.17s, eta=2:30:11\n",
      "2021-12-24 12:00:35 [INFO]\t[TRAIN] Epoch=29/35, Step=2580/7915, loss=0.217898, lr=2.3e-05, time_each_step=0.17s, eta=2:29:37\n",
      "2021-12-24 12:01:08 [INFO]\t[TRAIN] Epoch=29/35, Step=2780/7915, loss=0.135665, lr=2.2e-05, time_each_step=0.16s, eta=2:28:45\n",
      "2021-12-24 12:01:41 [INFO]\t[TRAIN] Epoch=29/35, Step=2980/7915, loss=0.26569, lr=2.2e-05, time_each_step=0.16s, eta=2:28:14\n",
      "2021-12-24 12:02:14 [INFO]\t[TRAIN] Epoch=29/35, Step=3180/7915, loss=0.596316, lr=2.2e-05, time_each_step=0.17s, eta=2:28:1\n",
      "2021-12-24 12:02:47 [INFO]\t[TRAIN] Epoch=29/35, Step=3380/7915, loss=0.377361, lr=2.2e-05, time_each_step=0.16s, eta=2:27:17\n",
      "2021-12-24 12:03:20 [INFO]\t[TRAIN] Epoch=29/35, Step=3580/7915, loss=0.657147, lr=2.2e-05, time_each_step=0.17s, eta=2:26:45\n",
      "2021-12-24 12:03:53 [INFO]\t[TRAIN] Epoch=29/35, Step=3780/7915, loss=0.154899, lr=2.2e-05, time_each_step=0.16s, eta=2:26:7\n",
      "2021-12-24 12:04:27 [INFO]\t[TRAIN] Epoch=29/35, Step=3980/7915, loss=0.586516, lr=2.2e-05, time_each_step=0.17s, eta=2:25:38\n",
      "2021-12-24 12:04:59 [INFO]\t[TRAIN] Epoch=29/35, Step=4180/7915, loss=0.346346, lr=2.2e-05, time_each_step=0.16s, eta=2:24:47\n",
      "2021-12-24 12:05:32 [INFO]\t[TRAIN] Epoch=29/35, Step=4380/7915, loss=0.213278, lr=2.2e-05, time_each_step=0.17s, eta=2:24:34\n",
      "2021-12-24 12:06:05 [INFO]\t[TRAIN] Epoch=29/35, Step=4580/7915, loss=0.592388, lr=2.2e-05, time_each_step=0.17s, eta=2:24:0\n",
      "2021-12-24 12:06:38 [INFO]\t[TRAIN] Epoch=29/35, Step=4780/7915, loss=0.251426, lr=2.2e-05, time_each_step=0.17s, eta=2:23:33\n",
      "2021-12-24 12:07:11 [INFO]\t[TRAIN] Epoch=29/35, Step=4980/7915, loss=0.470209, lr=2.2e-05, time_each_step=0.17s, eta=2:22:54\n",
      "2021-12-24 12:07:44 [INFO]\t[TRAIN] Epoch=29/35, Step=5180/7915, loss=0.483775, lr=2.2e-05, time_each_step=0.17s, eta=2:22:24\n",
      "2021-12-24 12:08:18 [INFO]\t[TRAIN] Epoch=29/35, Step=5380/7915, loss=0.683341, lr=2.1e-05, time_each_step=0.17s, eta=2:21:52\n",
      "2021-12-24 12:08:51 [INFO]\t[TRAIN] Epoch=29/35, Step=5580/7915, loss=0.369079, lr=2.1e-05, time_each_step=0.17s, eta=2:21:18\n",
      "2021-12-24 12:09:24 [INFO]\t[TRAIN] Epoch=29/35, Step=5780/7915, loss=0.891788, lr=2.1e-05, time_each_step=0.17s, eta=2:20:44\n",
      "2021-12-24 12:09:57 [INFO]\t[TRAIN] Epoch=29/35, Step=5980/7915, loss=0.313857, lr=2.1e-05, time_each_step=0.16s, eta=2:20:6\n",
      "2021-12-24 12:10:30 [INFO]\t[TRAIN] Epoch=29/35, Step=6180/7915, loss=1.060948, lr=2.1e-05, time_each_step=0.16s, eta=2:19:32\n",
      "2021-12-24 12:11:03 [INFO]\t[TRAIN] Epoch=29/35, Step=6380/7915, loss=0.385152, lr=2.1e-05, time_each_step=0.17s, eta=2:19:5\n",
      "2021-12-24 12:11:36 [INFO]\t[TRAIN] Epoch=29/35, Step=6580/7915, loss=0.230133, lr=2.1e-05, time_each_step=0.17s, eta=2:18:30\n",
      "2021-12-24 12:12:09 [INFO]\t[TRAIN] Epoch=29/35, Step=6780/7915, loss=0.107213, lr=2.1e-05, time_each_step=0.16s, eta=2:17:55\n",
      "2021-12-24 12:12:42 [INFO]\t[TRAIN] Epoch=29/35, Step=6980/7915, loss=0.682253, lr=2.1e-05, time_each_step=0.16s, eta=2:17:22\n",
      "2021-12-24 12:13:15 [INFO]\t[TRAIN] Epoch=29/35, Step=7180/7915, loss=0.32374, lr=2.1e-05, time_each_step=0.17s, eta=2:16:50\n",
      "2021-12-24 12:13:48 [INFO]\t[TRAIN] Epoch=29/35, Step=7380/7915, loss=0.208354, lr=2.1e-05, time_each_step=0.17s, eta=2:16:17\n",
      "2021-12-24 12:14:22 [INFO]\t[TRAIN] Epoch=29/35, Step=7580/7915, loss=0.431275, lr=2.1e-05, time_each_step=0.17s, eta=2:15:44\n",
      "2021-12-24 12:14:54 [INFO]\t[TRAIN] Epoch=29/35, Step=7780/7915, loss=0.165391, lr=2.1e-05, time_each_step=0.16s, eta=2:15:10\n",
      "2021-12-24 12:15:16 [INFO]\t[TRAIN] Epoch 29 finished, loss=0.340438, lr=2.2e-05 .\n",
      "2021-12-24 12:15:16 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 12:15:40 [INFO]\t[EVAL] Finished, Epoch=29, miou=0.572336, category_iou=[0.58770343 0.74608323 0.55771277 0.39784555], oacc=0.74853, category_acc=[0.70133247 0.85498653 0.77137465 0.58824132], kappa=0.651311, category_F1-score=[0.7403189  0.85457923 0.71606625 0.56922676] .\n",
      "2021-12-24 12:15:44 [INFO]\tModel saved in output/deeplab/epoch_29.\n",
      "2021-12-24 12:15:44 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_28, miou=0.5746060701440677\n",
      "2021-12-24 12:15:58 [INFO]\t[TRAIN] Epoch=30/35, Step=65/7915, loss=0.120407, lr=2e-05, time_each_step=0.17s, eta=2:13:38\n",
      "2021-12-24 12:16:31 [INFO]\t[TRAIN] Epoch=30/35, Step=265/7915, loss=0.357326, lr=2e-05, time_each_step=0.16s, eta=2:12:52\n",
      "2021-12-24 12:17:04 [INFO]\t[TRAIN] Epoch=30/35, Step=465/7915, loss=0.087784, lr=2e-05, time_each_step=0.17s, eta=2:12:54\n",
      "2021-12-24 12:17:37 [INFO]\t[TRAIN] Epoch=30/35, Step=665/7915, loss=0.08184, lr=2e-05, time_each_step=0.17s, eta=2:12:5\n",
      "2021-12-24 12:18:10 [INFO]\t[TRAIN] Epoch=30/35, Step=865/7915, loss=0.144291, lr=2e-05, time_each_step=0.16s, eta=2:11:16\n",
      "2021-12-24 12:18:43 [INFO]\t[TRAIN] Epoch=30/35, Step=1065/7915, loss=0.116823, lr=2e-05, time_each_step=0.17s, eta=2:10:56\n",
      "2021-12-24 12:19:16 [INFO]\t[TRAIN] Epoch=30/35, Step=1265/7915, loss=0.548866, lr=2e-05, time_each_step=0.17s, eta=2:10:33\n",
      "2021-12-24 12:19:49 [INFO]\t[TRAIN] Epoch=30/35, Step=1465/7915, loss=0.142418, lr=2e-05, time_each_step=0.17s, eta=2:9:48\n",
      "2021-12-24 12:20:22 [INFO]\t[TRAIN] Epoch=30/35, Step=1665/7915, loss=0.337104, lr=2e-05, time_each_step=0.17s, eta=2:9:27\n",
      "2021-12-24 12:20:55 [INFO]\t[TRAIN] Epoch=30/35, Step=1865/7915, loss=0.797627, lr=2e-05, time_each_step=0.16s, eta=2:8:37\n",
      "2021-12-24 12:21:29 [INFO]\t[TRAIN] Epoch=30/35, Step=2065/7915, loss=0.420882, lr=2e-05, time_each_step=0.17s, eta=2:8:19\n",
      "2021-12-24 12:22:02 [INFO]\t[TRAIN] Epoch=30/35, Step=2265/7915, loss=0.406007, lr=2e-05, time_each_step=0.17s, eta=2:7:45\n",
      "2021-12-24 12:22:35 [INFO]\t[TRAIN] Epoch=30/35, Step=2465/7915, loss=0.419685, lr=1.9e-05, time_each_step=0.17s, eta=2:7:16\n",
      "2021-12-24 12:23:08 [INFO]\t[TRAIN] Epoch=30/35, Step=2665/7915, loss=0.196213, lr=1.9e-05, time_each_step=0.17s, eta=2:6:41\n",
      "2021-12-24 12:23:41 [INFO]\t[TRAIN] Epoch=30/35, Step=2865/7915, loss=0.243147, lr=1.9e-05, time_each_step=0.17s, eta=2:5:56\n",
      "2021-12-24 12:24:15 [INFO]\t[TRAIN] Epoch=30/35, Step=3065/7915, loss=0.347316, lr=1.9e-05, time_each_step=0.17s, eta=2:5:29\n",
      "2021-12-24 12:24:48 [INFO]\t[TRAIN] Epoch=30/35, Step=3265/7915, loss=0.200939, lr=1.9e-05, time_each_step=0.17s, eta=2:4:55\n",
      "2021-12-24 12:25:21 [INFO]\t[TRAIN] Epoch=30/35, Step=3465/7915, loss=0.524893, lr=1.9e-05, time_each_step=0.17s, eta=2:4:17\n",
      "2021-12-24 12:25:54 [INFO]\t[TRAIN] Epoch=30/35, Step=3665/7915, loss=0.135696, lr=1.9e-05, time_each_step=0.17s, eta=2:3:52\n",
      "2021-12-24 12:26:27 [INFO]\t[TRAIN] Epoch=30/35, Step=3865/7915, loss=0.413761, lr=1.9e-05, time_each_step=0.17s, eta=2:3:11\n",
      "2021-12-24 12:27:00 [INFO]\t[TRAIN] Epoch=30/35, Step=4065/7915, loss=0.140936, lr=1.9e-05, time_each_step=0.16s, eta=2:2:32\n",
      "2021-12-24 12:27:33 [INFO]\t[TRAIN] Epoch=30/35, Step=4265/7915, loss=0.05978, lr=1.9e-05, time_each_step=0.17s, eta=2:2:10\n",
      "2021-12-24 12:28:06 [INFO]\t[TRAIN] Epoch=30/35, Step=4465/7915, loss=0.187023, lr=1.9e-05, time_each_step=0.17s, eta=2:1:35\n",
      "2021-12-24 12:28:39 [INFO]\t[TRAIN] Epoch=30/35, Step=4665/7915, loss=0.212345, lr=1.9e-05, time_each_step=0.17s, eta=2:1:0\n",
      "2021-12-24 12:29:12 [INFO]\t[TRAIN] Epoch=30/35, Step=4865/7915, loss=0.062921, lr=1.9e-05, time_each_step=0.16s, eta=2:0:17\n",
      "2021-12-24 12:29:45 [INFO]\t[TRAIN] Epoch=30/35, Step=5065/7915, loss=0.354224, lr=1.8e-05, time_each_step=0.17s, eta=1:59:55\n",
      "2021-12-24 12:30:18 [INFO]\t[TRAIN] Epoch=30/35, Step=5265/7915, loss=0.386975, lr=1.8e-05, time_each_step=0.17s, eta=1:59:22\n",
      "2021-12-24 12:30:51 [INFO]\t[TRAIN] Epoch=30/35, Step=5465/7915, loss=0.576105, lr=1.8e-05, time_each_step=0.17s, eta=1:58:48\n",
      "2021-12-24 12:31:24 [INFO]\t[TRAIN] Epoch=30/35, Step=5665/7915, loss=0.758852, lr=1.8e-05, time_each_step=0.16s, eta=1:58:13\n",
      "2021-12-24 12:31:57 [INFO]\t[TRAIN] Epoch=30/35, Step=5865/7915, loss=0.3101, lr=1.8e-05, time_each_step=0.17s, eta=1:57:40\n",
      "2021-12-24 12:32:30 [INFO]\t[TRAIN] Epoch=30/35, Step=6065/7915, loss=0.136205, lr=1.8e-05, time_each_step=0.17s, eta=1:57:8\n",
      "2021-12-24 12:33:03 [INFO]\t[TRAIN] Epoch=30/35, Step=6265/7915, loss=0.270544, lr=1.8e-05, time_each_step=0.17s, eta=1:56:36\n",
      "2021-12-24 12:33:36 [INFO]\t[TRAIN] Epoch=30/35, Step=6465/7915, loss=0.183972, lr=1.8e-05, time_each_step=0.17s, eta=1:56:2\n",
      "2021-12-24 12:34:10 [INFO]\t[TRAIN] Epoch=30/35, Step=6665/7915, loss=0.414465, lr=1.8e-05, time_each_step=0.17s, eta=1:55:30\n",
      "2021-12-24 12:34:42 [INFO]\t[TRAIN] Epoch=30/35, Step=6865/7915, loss=0.285881, lr=1.8e-05, time_each_step=0.17s, eta=1:54:55\n",
      "2021-12-24 12:35:16 [INFO]\t[TRAIN] Epoch=30/35, Step=7065/7915, loss=0.05893, lr=1.8e-05, time_each_step=0.17s, eta=1:54:22\n",
      "2021-12-24 12:35:49 [INFO]\t[TRAIN] Epoch=30/35, Step=7265/7915, loss=0.529409, lr=1.8e-05, time_each_step=0.16s, eta=1:53:47\n",
      "2021-12-24 12:36:22 [INFO]\t[TRAIN] Epoch=30/35, Step=7465/7915, loss=0.364963, lr=1.8e-05, time_each_step=0.17s, eta=1:53:17\n",
      "2021-12-24 12:36:55 [INFO]\t[TRAIN] Epoch=30/35, Step=7665/7915, loss=0.790041, lr=1.7e-05, time_each_step=0.17s, eta=1:52:43\n",
      "2021-12-24 12:37:28 [INFO]\t[TRAIN] Epoch=30/35, Step=7865/7915, loss=0.402779, lr=1.7e-05, time_each_step=0.16s, eta=1:52:10\n",
      "2021-12-24 12:37:36 [INFO]\t[TRAIN] Epoch 30 finished, loss=0.33132, lr=1.9e-05 .\n",
      "2021-12-24 12:37:36 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 12:38:00 [INFO]\t[EVAL] Finished, Epoch=30, miou=0.575911, category_iou=[0.59278102 0.75339874 0.55811979 0.39934262], oacc=0.753168, category_acc=[0.70098315 0.85014381 0.77786059 0.61018571], kappa=0.656787, category_F1-score=[0.74433461 0.85935814 0.71640164 0.57075746] .\n",
      "2021-12-24 12:38:04 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 12:38:07 [INFO]\tModel saved in output/deeplab/epoch_30.\n",
      "2021-12-24 12:38:07 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_30, miou=0.5759105425579919\n",
      "2021-12-24 12:38:35 [INFO]\t[TRAIN] Epoch=31/35, Step=150/7915, loss=0.194178, lr=1.7e-05, time_each_step=0.16s, eta=1:51:6\n",
      "2021-12-24 12:39:08 [INFO]\t[TRAIN] Epoch=31/35, Step=350/7915, loss=0.131445, lr=1.7e-05, time_each_step=0.16s, eta=1:50:47\n",
      "2021-12-24 12:39:41 [INFO]\t[TRAIN] Epoch=31/35, Step=550/7915, loss=0.120876, lr=1.7e-05, time_each_step=0.16s, eta=1:50:12\n",
      "2021-12-24 12:40:14 [INFO]\t[TRAIN] Epoch=31/35, Step=750/7915, loss=0.04675, lr=1.7e-05, time_each_step=0.17s, eta=1:49:57\n",
      "2021-12-24 12:40:47 [INFO]\t[TRAIN] Epoch=31/35, Step=950/7915, loss=0.077406, lr=1.7e-05, time_each_step=0.16s, eta=1:49:10\n",
      "2021-12-24 12:41:20 [INFO]\t[TRAIN] Epoch=31/35, Step=1150/7915, loss=0.315324, lr=1.7e-05, time_each_step=0.17s, eta=1:48:41\n",
      "2021-12-24 12:41:53 [INFO]\t[TRAIN] Epoch=31/35, Step=1350/7915, loss=0.432168, lr=1.7e-05, time_each_step=0.16s, eta=1:48:1\n",
      "2021-12-24 12:42:25 [INFO]\t[TRAIN] Epoch=31/35, Step=1550/7915, loss=0.153359, lr=1.7e-05, time_each_step=0.17s, eta=1:47:42\n",
      "2021-12-24 12:42:58 [INFO]\t[TRAIN] Epoch=31/35, Step=1750/7915, loss=0.666219, lr=1.7e-05, time_each_step=0.17s, eta=1:47:0\n",
      "2021-12-24 12:43:31 [INFO]\t[TRAIN] Epoch=31/35, Step=1950/7915, loss=0.172438, lr=1.7e-05, time_each_step=0.17s, eta=1:46:29\n",
      "2021-12-24 12:44:04 [INFO]\t[TRAIN] Epoch=31/35, Step=2150/7915, loss=0.377602, lr=1.7e-05, time_each_step=0.16s, eta=1:45:47\n",
      "2021-12-24 12:44:37 [INFO]\t[TRAIN] Epoch=31/35, Step=2350/7915, loss=0.286564, lr=1.6e-05, time_each_step=0.17s, eta=1:45:28\n",
      "2021-12-24 12:45:10 [INFO]\t[TRAIN] Epoch=31/35, Step=2550/7915, loss=0.454689, lr=1.6e-05, time_each_step=0.16s, eta=1:44:39\n",
      "2021-12-24 12:45:44 [INFO]\t[TRAIN] Epoch=31/35, Step=2750/7915, loss=0.306751, lr=1.6e-05, time_each_step=0.16s, eta=1:44:7\n",
      "2021-12-24 12:46:16 [INFO]\t[TRAIN] Epoch=31/35, Step=2950/7915, loss=0.257289, lr=1.6e-05, time_each_step=0.16s, eta=1:43:31\n",
      "2021-12-24 12:46:49 [INFO]\t[TRAIN] Epoch=31/35, Step=3150/7915, loss=0.320648, lr=1.6e-05, time_each_step=0.16s, eta=1:43:5\n",
      "2021-12-24 12:47:22 [INFO]\t[TRAIN] Epoch=31/35, Step=3350/7915, loss=0.091733, lr=1.6e-05, time_each_step=0.17s, eta=1:42:45\n",
      "2021-12-24 12:47:55 [INFO]\t[TRAIN] Epoch=31/35, Step=3550/7915, loss=0.192434, lr=1.6e-05, time_each_step=0.17s, eta=1:42:4\n",
      "2021-12-24 12:48:29 [INFO]\t[TRAIN] Epoch=31/35, Step=3750/7915, loss=0.400281, lr=1.6e-05, time_each_step=0.17s, eta=1:41:37\n",
      "2021-12-24 12:49:02 [INFO]\t[TRAIN] Epoch=31/35, Step=3950/7915, loss=0.584039, lr=1.6e-05, time_each_step=0.17s, eta=1:40:59\n",
      "2021-12-24 12:49:34 [INFO]\t[TRAIN] Epoch=31/35, Step=4150/7915, loss=0.384095, lr=1.6e-05, time_each_step=0.16s, eta=1:40:19\n",
      "2021-12-24 12:50:07 [INFO]\t[TRAIN] Epoch=31/35, Step=4350/7915, loss=0.048595, lr=1.6e-05, time_each_step=0.16s, eta=1:39:48\n",
      "2021-12-24 12:50:40 [INFO]\t[TRAIN] Epoch=31/35, Step=4550/7915, loss=0.228116, lr=1.6e-05, time_each_step=0.17s, eta=1:39:20\n",
      "2021-12-24 12:51:13 [INFO]\t[TRAIN] Epoch=31/35, Step=4750/7915, loss=0.211623, lr=1.5e-05, time_each_step=0.17s, eta=1:38:47\n",
      "2021-12-24 12:51:46 [INFO]\t[TRAIN] Epoch=31/35, Step=4950/7915, loss=0.258319, lr=1.5e-05, time_each_step=0.16s, eta=1:38:7\n",
      "2021-12-24 12:52:19 [INFO]\t[TRAIN] Epoch=31/35, Step=5150/7915, loss=0.630407, lr=1.5e-05, time_each_step=0.16s, eta=1:37:37\n",
      "2021-12-24 12:52:52 [INFO]\t[TRAIN] Epoch=31/35, Step=5350/7915, loss=0.177966, lr=1.5e-05, time_each_step=0.17s, eta=1:37:6\n",
      "2021-12-24 12:53:25 [INFO]\t[TRAIN] Epoch=31/35, Step=5550/7915, loss=0.238405, lr=1.5e-05, time_each_step=0.17s, eta=1:36:33\n",
      "2021-12-24 12:53:58 [INFO]\t[TRAIN] Epoch=31/35, Step=5750/7915, loss=0.317289, lr=1.5e-05, time_each_step=0.17s, eta=1:36:5\n",
      "2021-12-24 12:54:31 [INFO]\t[TRAIN] Epoch=31/35, Step=5950/7915, loss=0.17297, lr=1.5e-05, time_each_step=0.17s, eta=1:35:29\n",
      "2021-12-24 12:55:04 [INFO]\t[TRAIN] Epoch=31/35, Step=6150/7915, loss=0.104534, lr=1.5e-05, time_each_step=0.16s, eta=1:34:52\n",
      "2021-12-24 12:55:37 [INFO]\t[TRAIN] Epoch=31/35, Step=6350/7915, loss=0.078925, lr=1.5e-05, time_each_step=0.17s, eta=1:34:22\n",
      "2021-12-24 12:56:10 [INFO]\t[TRAIN] Epoch=31/35, Step=6550/7915, loss=0.106999, lr=1.5e-05, time_each_step=0.17s, eta=1:33:50\n",
      "2021-12-24 12:56:43 [INFO]\t[TRAIN] Epoch=31/35, Step=6750/7915, loss=0.481447, lr=1.5e-05, time_each_step=0.17s, eta=1:33:16\n",
      "2021-12-24 12:57:16 [INFO]\t[TRAIN] Epoch=31/35, Step=6950/7915, loss=0.465076, lr=1.5e-05, time_each_step=0.17s, eta=1:32:43\n",
      "2021-12-24 12:57:50 [INFO]\t[TRAIN] Epoch=31/35, Step=7150/7915, loss=0.148995, lr=1.5e-05, time_each_step=0.17s, eta=1:32:9\n",
      "2021-12-24 12:58:23 [INFO]\t[TRAIN] Epoch=31/35, Step=7350/7915, loss=0.493985, lr=1.4e-05, time_each_step=0.16s, eta=1:31:36\n",
      "2021-12-24 12:58:56 [INFO]\t[TRAIN] Epoch=31/35, Step=7550/7915, loss=0.180543, lr=1.4e-05, time_each_step=0.17s, eta=1:31:4\n",
      "2021-12-24 12:59:29 [INFO]\t[TRAIN] Epoch=31/35, Step=7750/7915, loss=0.200101, lr=1.4e-05, time_each_step=0.16s, eta=1:30:30\n",
      "2021-12-24 12:59:56 [INFO]\t[TRAIN] Epoch 31 finished, loss=0.324141, lr=1.6e-05 .\n",
      "2021-12-24 12:59:56 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 13:00:19 [INFO]\t[EVAL] Finished, Epoch=31, miou=0.576394, category_iou=[0.5933722  0.75074502 0.55623904 0.40522065], oacc=0.75213, category_acc=[0.71076499 0.85492962 0.76507211 0.59486945], kappa=0.656369, category_F1-score=[0.74480049 0.85762919 0.71485038 0.57673598] .\n",
      "2021-12-24 13:00:23 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 13:00:27 [INFO]\tModel saved in output/deeplab/epoch_31.\n",
      "2021-12-24 13:00:27 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_31, miou=0.5763942263225343\n",
      "2021-12-24 13:00:36 [INFO]\t[TRAIN] Epoch=32/35, Step=35/7915, loss=0.3965, lr=1.4e-05, time_each_step=0.17s, eta=1:29:53\n",
      "2021-12-24 13:01:08 [INFO]\t[TRAIN] Epoch=32/35, Step=235/7915, loss=0.223126, lr=1.4e-05, time_each_step=0.16s, eta=1:28:21\n",
      "2021-12-24 13:01:41 [INFO]\t[TRAIN] Epoch=32/35, Step=435/7915, loss=0.341864, lr=1.4e-05, time_each_step=0.16s, eta=1:27:48\n",
      "2021-12-24 13:02:14 [INFO]\t[TRAIN] Epoch=32/35, Step=635/7915, loss=0.67749, lr=1.4e-05, time_each_step=0.17s, eta=1:27:35\n",
      "2021-12-24 13:02:47 [INFO]\t[TRAIN] Epoch=32/35, Step=835/7915, loss=0.574467, lr=1.4e-05, time_each_step=0.16s, eta=1:26:55\n",
      "2021-12-24 13:03:20 [INFO]\t[TRAIN] Epoch=32/35, Step=1035/7915, loss=0.137523, lr=1.4e-05, time_each_step=0.17s, eta=1:26:27\n",
      "2021-12-24 13:03:53 [INFO]\t[TRAIN] Epoch=32/35, Step=1235/7915, loss=0.054219, lr=1.4e-05, time_each_step=0.16s, eta=1:25:44\n",
      "2021-12-24 13:04:26 [INFO]\t[TRAIN] Epoch=32/35, Step=1435/7915, loss=0.384009, lr=1.4e-05, time_each_step=0.16s, eta=1:25:12\n",
      "2021-12-24 13:04:59 [INFO]\t[TRAIN] Epoch=32/35, Step=1635/7915, loss=0.38233, lr=1.4e-05, time_each_step=0.17s, eta=1:25:3\n",
      "2021-12-24 13:05:32 [INFO]\t[TRAIN] Epoch=32/35, Step=1835/7915, loss=0.562318, lr=1.3e-05, time_each_step=0.17s, eta=1:24:13\n",
      "2021-12-24 13:06:05 [INFO]\t[TRAIN] Epoch=32/35, Step=2035/7915, loss=0.307685, lr=1.3e-05, time_each_step=0.17s, eta=1:23:41\n",
      "2021-12-24 13:06:38 [INFO]\t[TRAIN] Epoch=32/35, Step=2235/7915, loss=0.249033, lr=1.3e-05, time_each_step=0.16s, eta=1:23:4\n",
      "2021-12-24 13:07:11 [INFO]\t[TRAIN] Epoch=32/35, Step=2435/7915, loss=0.187773, lr=1.3e-05, time_each_step=0.17s, eta=1:22:37\n",
      "2021-12-24 13:07:44 [INFO]\t[TRAIN] Epoch=32/35, Step=2635/7915, loss=0.355442, lr=1.3e-05, time_each_step=0.16s, eta=1:21:57\n",
      "2021-12-24 13:08:17 [INFO]\t[TRAIN] Epoch=32/35, Step=2835/7915, loss=0.849225, lr=1.3e-05, time_each_step=0.17s, eta=1:21:32\n",
      "2021-12-24 13:08:50 [INFO]\t[TRAIN] Epoch=32/35, Step=3035/7915, loss=0.46708, lr=1.3e-05, time_each_step=0.17s, eta=1:20:55\n",
      "2021-12-24 13:09:23 [INFO]\t[TRAIN] Epoch=32/35, Step=3235/7915, loss=0.189103, lr=1.3e-05, time_each_step=0.16s, eta=1:20:21\n",
      "2021-12-24 13:09:56 [INFO]\t[TRAIN] Epoch=32/35, Step=3435/7915, loss=0.262306, lr=1.3e-05, time_each_step=0.17s, eta=1:19:53\n",
      "2021-12-24 13:10:29 [INFO]\t[TRAIN] Epoch=32/35, Step=3635/7915, loss=0.383063, lr=1.3e-05, time_each_step=0.17s, eta=1:19:20\n",
      "2021-12-24 13:11:02 [INFO]\t[TRAIN] Epoch=32/35, Step=3835/7915, loss=0.479745, lr=1.3e-05, time_each_step=0.16s, eta=1:18:40\n",
      "2021-12-24 13:11:36 [INFO]\t[TRAIN] Epoch=32/35, Step=4035/7915, loss=0.260987, lr=1.3e-05, time_each_step=0.16s, eta=1:17:57\n",
      "2021-12-24 13:12:08 [INFO]\t[TRAIN] Epoch=32/35, Step=4235/7915, loss=0.198013, lr=1.2e-05, time_each_step=0.16s, eta=1:17:34\n",
      "2021-12-24 13:12:41 [INFO]\t[TRAIN] Epoch=32/35, Step=4435/7915, loss=0.088188, lr=1.2e-05, time_each_step=0.17s, eta=1:17:5\n",
      "2021-12-24 13:13:14 [INFO]\t[TRAIN] Epoch=32/35, Step=4635/7915, loss=0.087977, lr=1.2e-05, time_each_step=0.16s, eta=1:16:29\n",
      "2021-12-24 13:13:47 [INFO]\t[TRAIN] Epoch=32/35, Step=4835/7915, loss=0.502683, lr=1.2e-05, time_each_step=0.16s, eta=1:15:51\n",
      "2021-12-24 13:14:20 [INFO]\t[TRAIN] Epoch=32/35, Step=5035/7915, loss=0.355862, lr=1.2e-05, time_each_step=0.16s, eta=1:15:22\n",
      "2021-12-24 13:14:53 [INFO]\t[TRAIN] Epoch=32/35, Step=5235/7915, loss=0.162353, lr=1.2e-05, time_each_step=0.17s, eta=1:14:54\n",
      "2021-12-24 13:15:26 [INFO]\t[TRAIN] Epoch=32/35, Step=5435/7915, loss=0.359179, lr=1.2e-05, time_each_step=0.16s, eta=1:14:15\n",
      "2021-12-24 13:15:59 [INFO]\t[TRAIN] Epoch=32/35, Step=5635/7915, loss=0.245762, lr=1.2e-05, time_each_step=0.17s, eta=1:13:53\n",
      "2021-12-24 13:16:32 [INFO]\t[TRAIN] Epoch=32/35, Step=5835/7915, loss=0.110902, lr=1.2e-05, time_each_step=0.16s, eta=1:13:11\n",
      "2021-12-24 13:17:05 [INFO]\t[TRAIN] Epoch=32/35, Step=6035/7915, loss=0.092445, lr=1.2e-05, time_each_step=0.16s, eta=1:12:34\n",
      "2021-12-24 13:17:37 [INFO]\t[TRAIN] Epoch=32/35, Step=6235/7915, loss=0.632559, lr=1.2e-05, time_each_step=0.17s, eta=1:12:7\n",
      "2021-12-24 13:18:10 [INFO]\t[TRAIN] Epoch=32/35, Step=6435/7915, loss=0.395042, lr=1.2e-05, time_each_step=0.16s, eta=1:11:33\n",
      "2021-12-24 13:18:44 [INFO]\t[TRAIN] Epoch=32/35, Step=6635/7915, loss=0.450619, lr=1.1e-05, time_each_step=0.17s, eta=1:11:1\n",
      "2021-12-24 13:19:17 [INFO]\t[TRAIN] Epoch=32/35, Step=6835/7915, loss=0.248912, lr=1.1e-05, time_each_step=0.16s, eta=1:10:26\n",
      "2021-12-24 13:19:50 [INFO]\t[TRAIN] Epoch=32/35, Step=7035/7915, loss=0.131114, lr=1.1e-05, time_each_step=0.17s, eta=1:9:56\n",
      "2021-12-24 13:20:23 [INFO]\t[TRAIN] Epoch=32/35, Step=7235/7915, loss=0.640075, lr=1.1e-05, time_each_step=0.17s, eta=1:9:22\n",
      "2021-12-24 13:20:56 [INFO]\t[TRAIN] Epoch=32/35, Step=7435/7915, loss=0.634325, lr=1.1e-05, time_each_step=0.17s, eta=1:8:49\n",
      "2021-12-24 13:21:29 [INFO]\t[TRAIN] Epoch=32/35, Step=7635/7915, loss=0.401457, lr=1.1e-05, time_each_step=0.16s, eta=1:8:15\n",
      "2021-12-24 13:22:02 [INFO]\t[TRAIN] Epoch=32/35, Step=7835/7915, loss=0.100792, lr=1.1e-05, time_each_step=0.16s, eta=1:7:42\n",
      "2021-12-24 13:22:15 [INFO]\t[TRAIN] Epoch 32 finished, loss=0.321507, lr=1.3e-05 .\n",
      "2021-12-24 13:22:15 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 13:22:39 [INFO]\t[EVAL] Finished, Epoch=32, miou=0.580056, category_iou=[0.59083362 0.75345715 0.56095016 0.41498232], oacc=0.754035, category_acc=[0.72597816 0.85152705 0.75948676 0.5910383 ], kappa=0.659542, category_F1-score=[0.7427975  0.85939613 0.71872911 0.58655478] .\n",
      "2021-12-24 13:22:43 [INFO]\tModel saved in output/deeplab/best_model.\n",
      "2021-12-24 13:22:46 [INFO]\tModel saved in output/deeplab/epoch_32.\n",
      "2021-12-24 13:22:46 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_32, miou=0.580055810853016\n",
      "2021-12-24 13:23:09 [INFO]\t[TRAIN] Epoch=33/35, Step=120/7915, loss=0.30384, lr=1.1e-05, time_each_step=0.16s, eta=1:6:16\n",
      "2021-12-24 13:23:42 [INFO]\t[TRAIN] Epoch=33/35, Step=320/7915, loss=0.594672, lr=1.1e-05, time_each_step=0.16s, eta=1:6:0\n",
      "2021-12-24 13:24:15 [INFO]\t[TRAIN] Epoch=33/35, Step=520/7915, loss=0.198757, lr=1.1e-05, time_each_step=0.16s, eta=1:5:12\n",
      "2021-12-24 13:24:48 [INFO]\t[TRAIN] Epoch=33/35, Step=720/7915, loss=0.329145, lr=1.1e-05, time_each_step=0.17s, eta=1:5:53\n",
      "2021-12-24 13:25:21 [INFO]\t[TRAIN] Epoch=33/35, Step=920/7915, loss=0.252262, lr=1.1e-05, time_each_step=0.17s, eta=1:4:29\n",
      "2021-12-24 13:25:54 [INFO]\t[TRAIN] Epoch=33/35, Step=1120/7915, loss=0.335615, lr=1e-05, time_each_step=0.16s, eta=1:3:46\n",
      "2021-12-24 13:26:26 [INFO]\t[TRAIN] Epoch=33/35, Step=1320/7915, loss=0.134163, lr=1e-05, time_each_step=0.16s, eta=1:3:13\n",
      "2021-12-24 13:26:59 [INFO]\t[TRAIN] Epoch=33/35, Step=1520/7915, loss=0.39509, lr=1e-05, time_each_step=0.17s, eta=1:2:47\n",
      "2021-12-24 13:27:32 [INFO]\t[TRAIN] Epoch=33/35, Step=1720/7915, loss=0.361537, lr=1e-05, time_each_step=0.16s, eta=1:2:3\n",
      "2021-12-24 13:28:05 [INFO]\t[TRAIN] Epoch=33/35, Step=1920/7915, loss=0.110924, lr=1e-05, time_each_step=0.16s, eta=1:1:38\n",
      "2021-12-24 13:28:38 [INFO]\t[TRAIN] Epoch=33/35, Step=2120/7915, loss=0.254476, lr=1e-05, time_each_step=0.16s, eta=1:0:53\n",
      "2021-12-24 13:29:11 [INFO]\t[TRAIN] Epoch=33/35, Step=2320/7915, loss=0.512468, lr=1e-05, time_each_step=0.17s, eta=1:0:36\n",
      "2021-12-24 13:29:45 [INFO]\t[TRAIN] Epoch=33/35, Step=2520/7915, loss=0.201044, lr=1e-05, time_each_step=0.17s, eta=1:0:6\n",
      "2021-12-24 13:30:18 [INFO]\t[TRAIN] Epoch=33/35, Step=2720/7915, loss=0.266415, lr=1e-05, time_each_step=0.16s, eta=0:59:24\n",
      "2021-12-24 13:30:51 [INFO]\t[TRAIN] Epoch=33/35, Step=2920/7915, loss=0.15277, lr=1e-05, time_each_step=0.17s, eta=0:58:59\n",
      "2021-12-24 13:31:23 [INFO]\t[TRAIN] Epoch=33/35, Step=3120/7915, loss=0.132776, lr=1e-05, time_each_step=0.16s, eta=0:58:17\n",
      "2021-12-24 13:31:57 [INFO]\t[TRAIN] Epoch=33/35, Step=3320/7915, loss=0.326887, lr=1e-05, time_each_step=0.17s, eta=0:57:48\n",
      "2021-12-24 13:32:30 [INFO]\t[TRAIN] Epoch=33/35, Step=3520/7915, loss=0.240131, lr=9e-06, time_each_step=0.16s, eta=0:57:14\n",
      "2021-12-24 13:33:03 [INFO]\t[TRAIN] Epoch=33/35, Step=3720/7915, loss=0.270096, lr=9e-06, time_each_step=0.17s, eta=0:56:48\n",
      "2021-12-24 13:33:36 [INFO]\t[TRAIN] Epoch=33/35, Step=3920/7915, loss=0.568785, lr=9e-06, time_each_step=0.17s, eta=0:56:15\n",
      "2021-12-24 13:34:09 [INFO]\t[TRAIN] Epoch=33/35, Step=4120/7915, loss=0.271547, lr=9e-06, time_each_step=0.16s, eta=0:55:35\n",
      "2021-12-24 13:34:42 [INFO]\t[TRAIN] Epoch=33/35, Step=4320/7915, loss=0.300595, lr=9e-06, time_each_step=0.17s, eta=0:55:5\n",
      "2021-12-24 13:35:15 [INFO]\t[TRAIN] Epoch=33/35, Step=4520/7915, loss=0.451049, lr=9e-06, time_each_step=0.16s, eta=0:54:27\n",
      "2021-12-24 13:35:48 [INFO]\t[TRAIN] Epoch=33/35, Step=4720/7915, loss=0.090121, lr=9e-06, time_each_step=0.16s, eta=0:53:52\n",
      "2021-12-24 13:36:21 [INFO]\t[TRAIN] Epoch=33/35, Step=4920/7915, loss=0.224036, lr=9e-06, time_each_step=0.16s, eta=0:53:16\n",
      "2021-12-24 13:36:54 [INFO]\t[TRAIN] Epoch=33/35, Step=5120/7915, loss=0.432082, lr=9e-06, time_each_step=0.17s, eta=0:52:55\n",
      "2021-12-24 13:37:27 [INFO]\t[TRAIN] Epoch=33/35, Step=5320/7915, loss=0.302685, lr=9e-06, time_each_step=0.16s, eta=0:52:16\n",
      "2021-12-24 13:38:00 [INFO]\t[TRAIN] Epoch=33/35, Step=5520/7915, loss=0.243162, lr=9e-06, time_each_step=0.16s, eta=0:51:41\n",
      "2021-12-24 13:38:33 [INFO]\t[TRAIN] Epoch=33/35, Step=5720/7915, loss=0.552397, lr=9e-06, time_each_step=0.16s, eta=0:51:10\n",
      "2021-12-24 13:39:06 [INFO]\t[TRAIN] Epoch=33/35, Step=5920/7915, loss=0.311075, lr=8e-06, time_each_step=0.16s, eta=0:50:39\n",
      "2021-12-24 13:39:39 [INFO]\t[TRAIN] Epoch=33/35, Step=6120/7915, loss=0.389904, lr=8e-06, time_each_step=0.17s, eta=0:50:8\n",
      "2021-12-24 13:40:12 [INFO]\t[TRAIN] Epoch=33/35, Step=6320/7915, loss=0.249305, lr=8e-06, time_each_step=0.16s, eta=0:49:30\n",
      "2021-12-24 13:40:45 [INFO]\t[TRAIN] Epoch=33/35, Step=6520/7915, loss=1.107563, lr=8e-06, time_each_step=0.17s, eta=0:49:2\n",
      "2021-12-24 13:41:18 [INFO]\t[TRAIN] Epoch=33/35, Step=6720/7915, loss=0.305252, lr=8e-06, time_each_step=0.16s, eta=0:48:23\n",
      "2021-12-24 13:41:51 [INFO]\t[TRAIN] Epoch=33/35, Step=6920/7915, loss=0.991434, lr=8e-06, time_each_step=0.17s, eta=0:47:55\n",
      "2021-12-24 13:42:24 [INFO]\t[TRAIN] Epoch=33/35, Step=7120/7915, loss=0.099655, lr=8e-06, time_each_step=0.17s, eta=0:47:21\n",
      "2021-12-24 13:42:57 [INFO]\t[TRAIN] Epoch=33/35, Step=7320/7915, loss=0.327042, lr=8e-06, time_each_step=0.17s, eta=0:46:48\n",
      "2021-12-24 13:43:31 [INFO]\t[TRAIN] Epoch=33/35, Step=7520/7915, loss=0.176876, lr=8e-06, time_each_step=0.17s, eta=0:46:15\n",
      "2021-12-24 13:44:04 [INFO]\t[TRAIN] Epoch=33/35, Step=7720/7915, loss=0.13857, lr=8e-06, time_each_step=0.16s, eta=0:45:41\n",
      "2021-12-24 13:44:35 [INFO]\t[TRAIN] Epoch 33 finished, loss=0.313968, lr=9e-06 .\n",
      "2021-12-24 13:44:35 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:24<00:00, 17.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 13:45:00 [INFO]\t[EVAL] Finished, Epoch=33, miou=0.579683, category_iou=[0.58943305 0.7530733  0.56845773 0.40776831], oacc=0.753973, category_acc=[0.72487867 0.84893886 0.75657569 0.59428048], kappa=0.659269, category_F1-score=[0.74168968 0.85914639 0.72486203 0.57931167] .\n",
      "2021-12-24 13:45:03 [INFO]\tModel saved in output/deeplab/epoch_33.\n",
      "2021-12-24 13:45:03 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_32, miou=0.580055810853016\n",
      "2021-12-24 13:45:07 [INFO]\t[TRAIN] Epoch=34/35, Step=5/7915, loss=0.283961, lr=8e-06, time_each_step=0.31s, eta=1:4:8\n",
      "2021-12-24 13:45:40 [INFO]\t[TRAIN] Epoch=34/35, Step=205/7915, loss=0.642239, lr=8e-06, time_each_step=0.17s, eta=0:43:58\n",
      "2021-12-24 13:46:13 [INFO]\t[TRAIN] Epoch=34/35, Step=405/7915, loss=0.065335, lr=7e-06, time_each_step=0.16s, eta=0:43:18\n",
      "2021-12-24 13:46:46 [INFO]\t[TRAIN] Epoch=34/35, Step=605/7915, loss=0.208989, lr=7e-06, time_each_step=0.16s, eta=0:42:42\n",
      "2021-12-24 13:47:19 [INFO]\t[TRAIN] Epoch=34/35, Step=805/7915, loss=0.135233, lr=7e-06, time_each_step=0.16s, eta=0:41:48\n",
      "2021-12-24 13:47:52 [INFO]\t[TRAIN] Epoch=34/35, Step=1005/7915, loss=0.146156, lr=7e-06, time_each_step=0.16s, eta=0:41:43\n",
      "2021-12-24 13:48:25 [INFO]\t[TRAIN] Epoch=34/35, Step=1205/7915, loss=0.130755, lr=7e-06, time_each_step=0.16s, eta=0:40:46\n",
      "2021-12-24 13:48:57 [INFO]\t[TRAIN] Epoch=34/35, Step=1405/7915, loss=0.099536, lr=7e-06, time_each_step=0.17s, eta=0:40:44\n",
      "2021-12-24 13:49:30 [INFO]\t[TRAIN] Epoch=34/35, Step=1605/7915, loss=0.186124, lr=7e-06, time_each_step=0.16s, eta=0:39:53\n",
      "2021-12-24 13:50:03 [INFO]\t[TRAIN] Epoch=34/35, Step=1805/7915, loss=0.182293, lr=7e-06, time_each_step=0.16s, eta=0:39:31\n",
      "2021-12-24 13:50:36 [INFO]\t[TRAIN] Epoch=34/35, Step=2005/7915, loss=0.537348, lr=7e-06, time_each_step=0.16s, eta=0:38:51\n",
      "2021-12-24 13:51:08 [INFO]\t[TRAIN] Epoch=34/35, Step=2205/7915, loss=0.33461, lr=7e-06, time_each_step=0.16s, eta=0:38:9\n",
      "2021-12-24 13:51:41 [INFO]\t[TRAIN] Epoch=34/35, Step=2405/7915, loss=0.535645, lr=7e-06, time_each_step=0.17s, eta=0:37:56\n",
      "2021-12-24 13:52:14 [INFO]\t[TRAIN] Epoch=34/35, Step=2605/7915, loss=0.468678, lr=6e-06, time_each_step=0.16s, eta=0:37:20\n",
      "2021-12-24 13:52:47 [INFO]\t[TRAIN] Epoch=34/35, Step=2805/7915, loss=0.262313, lr=6e-06, time_each_step=0.16s, eta=0:36:30\n",
      "2021-12-24 13:53:19 [INFO]\t[TRAIN] Epoch=34/35, Step=3005/7915, loss=0.279797, lr=6e-06, time_each_step=0.16s, eta=0:36:10\n",
      "2021-12-24 13:53:52 [INFO]\t[TRAIN] Epoch=34/35, Step=3205/7915, loss=0.701886, lr=6e-06, time_each_step=0.16s, eta=0:35:34\n",
      "2021-12-24 13:54:25 [INFO]\t[TRAIN] Epoch=34/35, Step=3405/7915, loss=0.338289, lr=6e-06, time_each_step=0.17s, eta=0:35:13\n",
      "2021-12-24 13:54:58 [INFO]\t[TRAIN] Epoch=34/35, Step=3605/7915, loss=0.159487, lr=6e-06, time_each_step=0.16s, eta=0:34:33\n",
      "2021-12-24 13:55:30 [INFO]\t[TRAIN] Epoch=34/35, Step=3805/7915, loss=0.23229, lr=6e-06, time_each_step=0.16s, eta=0:33:57\n",
      "2021-12-24 13:56:03 [INFO]\t[TRAIN] Epoch=34/35, Step=4005/7915, loss=0.196047, lr=6e-06, time_each_step=0.16s, eta=0:33:27\n",
      "2021-12-24 13:56:36 [INFO]\t[TRAIN] Epoch=34/35, Step=4205/7915, loss=0.332055, lr=6e-06, time_each_step=0.16s, eta=0:32:51\n",
      "2021-12-24 13:57:09 [INFO]\t[TRAIN] Epoch=34/35, Step=4405/7915, loss=0.110025, lr=6e-06, time_each_step=0.17s, eta=0:32:26\n",
      "2021-12-24 13:57:42 [INFO]\t[TRAIN] Epoch=34/35, Step=4605/7915, loss=0.353042, lr=6e-06, time_each_step=0.16s, eta=0:31:43\n",
      "2021-12-24 13:58:15 [INFO]\t[TRAIN] Epoch=34/35, Step=4805/7915, loss=0.157638, lr=5e-06, time_each_step=0.17s, eta=0:31:21\n",
      "2021-12-24 13:58:47 [INFO]\t[TRAIN] Epoch=34/35, Step=5005/7915, loss=0.193557, lr=5e-06, time_each_step=0.16s, eta=0:30:44\n",
      "2021-12-24 13:59:20 [INFO]\t[TRAIN] Epoch=34/35, Step=5205/7915, loss=0.378269, lr=5e-06, time_each_step=0.17s, eta=0:30:14\n",
      "2021-12-24 13:59:53 [INFO]\t[TRAIN] Epoch=34/35, Step=5405/7915, loss=0.506604, lr=5e-06, time_each_step=0.16s, eta=0:29:31\n",
      "2021-12-24 14:00:26 [INFO]\t[TRAIN] Epoch=34/35, Step=5605/7915, loss=0.520553, lr=5e-06, time_each_step=0.17s, eta=0:29:10\n",
      "2021-12-24 14:00:59 [INFO]\t[TRAIN] Epoch=34/35, Step=5805/7915, loss=0.158839, lr=5e-06, time_each_step=0.17s, eta=0:28:33\n",
      "2021-12-24 14:01:32 [INFO]\t[TRAIN] Epoch=34/35, Step=6005/7915, loss=0.493364, lr=5e-06, time_each_step=0.16s, eta=0:27:52\n",
      "2021-12-24 14:02:05 [INFO]\t[TRAIN] Epoch=34/35, Step=6205/7915, loss=0.389236, lr=5e-06, time_each_step=0.17s, eta=0:27:28\n",
      "2021-12-24 14:02:37 [INFO]\t[TRAIN] Epoch=34/35, Step=6405/7915, loss=0.13447, lr=5e-06, time_each_step=0.16s, eta=0:26:50\n",
      "2021-12-24 14:03:10 [INFO]\t[TRAIN] Epoch=34/35, Step=6605/7915, loss=0.016313, lr=5e-06, time_each_step=0.17s, eta=0:26:21\n",
      "2021-12-24 14:03:43 [INFO]\t[TRAIN] Epoch=34/35, Step=6805/7915, loss=0.089214, lr=5e-06, time_each_step=0.16s, eta=0:25:47\n",
      "2021-12-24 14:04:16 [INFO]\t[TRAIN] Epoch=34/35, Step=7005/7915, loss=0.587898, lr=4e-06, time_each_step=0.16s, eta=0:25:13\n",
      "2021-12-24 14:04:49 [INFO]\t[TRAIN] Epoch=34/35, Step=7205/7915, loss=0.241242, lr=4e-06, time_each_step=0.16s, eta=0:24:41\n",
      "2021-12-24 14:05:22 [INFO]\t[TRAIN] Epoch=34/35, Step=7405/7915, loss=0.168125, lr=4e-06, time_each_step=0.17s, eta=0:24:9\n",
      "2021-12-24 14:05:55 [INFO]\t[TRAIN] Epoch=34/35, Step=7605/7915, loss=0.425306, lr=4e-06, time_each_step=0.17s, eta=0:23:36\n",
      "2021-12-24 14:06:28 [INFO]\t[TRAIN] Epoch=34/35, Step=7805/7915, loss=0.395455, lr=4e-06, time_each_step=0.16s, eta=0:23:2\n",
      "2021-12-24 14:06:46 [INFO]\t[TRAIN] Epoch 34 finished, loss=0.313798, lr=6e-06 .\n",
      "2021-12-24 14:06:46 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:07:09 [INFO]\t[EVAL] Finished, Epoch=34, miou=0.578983, category_iou=[0.5906497  0.75154717 0.56261821 0.41111713], oacc=0.753399, category_acc=[0.72363811 0.84914337 0.76128262 0.59210564], kappa=0.658462, category_F1-score=[0.74265214 0.85815236 0.72009683 0.58268321] .\n",
      "2021-12-24 14:07:13 [INFO]\tModel saved in output/deeplab/epoch_34.\n",
      "2021-12-24 14:07:13 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_32, miou=0.580055810853016\n",
      "2021-12-24 14:07:31 [INFO]\t[TRAIN] Epoch=35/35, Step=90/7915, loss=0.419669, lr=4e-06, time_each_step=0.16s, eta=0:21:48\n",
      "2021-12-24 14:08:03 [INFO]\t[TRAIN] Epoch=35/35, Step=290/7915, loss=0.247526, lr=4e-06, time_each_step=0.16s, eta=0:21:0\n",
      "2021-12-24 14:08:36 [INFO]\t[TRAIN] Epoch=35/35, Step=490/7915, loss=0.411535, lr=4e-06, time_each_step=0.17s, eta=0:20:57\n",
      "2021-12-24 14:09:09 [INFO]\t[TRAIN] Epoch=35/35, Step=690/7915, loss=0.390602, lr=4e-06, time_each_step=0.16s, eta=0:19:59\n",
      "2021-12-24 14:09:42 [INFO]\t[TRAIN] Epoch=35/35, Step=890/7915, loss=0.701017, lr=4e-06, time_each_step=0.16s, eta=0:19:44\n",
      "2021-12-24 14:10:14 [INFO]\t[TRAIN] Epoch=35/35, Step=1090/7915, loss=0.110213, lr=4e-06, time_each_step=0.17s, eta=0:19:21\n",
      "2021-12-24 14:10:47 [INFO]\t[TRAIN] Epoch=35/35, Step=1290/7915, loss=0.07988, lr=3e-06, time_each_step=0.17s, eta=0:18:56\n",
      "2021-12-24 14:11:20 [INFO]\t[TRAIN] Epoch=35/35, Step=1490/7915, loss=0.07296, lr=3e-06, time_each_step=0.16s, eta=0:18:0\n",
      "2021-12-24 14:11:53 [INFO]\t[TRAIN] Epoch=35/35, Step=1690/7915, loss=0.362283, lr=3e-06, time_each_step=0.16s, eta=0:17:30\n",
      "2021-12-24 14:12:26 [INFO]\t[TRAIN] Epoch=35/35, Step=1890/7915, loss=0.247923, lr=3e-06, time_each_step=0.16s, eta=0:16:50\n",
      "2021-12-24 14:12:59 [INFO]\t[TRAIN] Epoch=35/35, Step=2090/7915, loss=0.572314, lr=3e-06, time_each_step=0.17s, eta=0:16:29\n",
      "2021-12-24 14:13:32 [INFO]\t[TRAIN] Epoch=35/35, Step=2290/7915, loss=0.295069, lr=3e-06, time_each_step=0.17s, eta=0:16:5\n",
      "2021-12-24 14:14:05 [INFO]\t[TRAIN] Epoch=35/35, Step=2490/7915, loss=0.360063, lr=3e-06, time_each_step=0.16s, eta=0:15:10\n",
      "2021-12-24 14:14:38 [INFO]\t[TRAIN] Epoch=35/35, Step=2690/7915, loss=0.19728, lr=3e-06, time_each_step=0.17s, eta=0:14:54\n",
      "2021-12-24 14:15:11 [INFO]\t[TRAIN] Epoch=35/35, Step=2890/7915, loss=0.253966, lr=3e-06, time_each_step=0.16s, eta=0:14:6\n",
      "2021-12-24 14:15:44 [INFO]\t[TRAIN] Epoch=35/35, Step=3090/7915, loss=0.218589, lr=3e-06, time_each_step=0.16s, eta=0:13:37\n",
      "2021-12-24 14:16:17 [INFO]\t[TRAIN] Epoch=35/35, Step=3290/7915, loss=0.22603, lr=3e-06, time_each_step=0.17s, eta=0:13:11\n",
      "2021-12-24 14:16:50 [INFO]\t[TRAIN] Epoch=35/35, Step=3490/7915, loss=0.075804, lr=2e-06, time_each_step=0.16s, eta=0:12:30\n",
      "2021-12-24 14:17:23 [INFO]\t[TRAIN] Epoch=35/35, Step=3690/7915, loss=0.496863, lr=2e-06, time_each_step=0.17s, eta=0:12:5\n",
      "2021-12-24 14:17:56 [INFO]\t[TRAIN] Epoch=35/35, Step=3890/7915, loss=0.317507, lr=2e-06, time_each_step=0.17s, eta=0:11:33\n",
      "2021-12-24 14:18:28 [INFO]\t[TRAIN] Epoch=35/35, Step=4090/7915, loss=0.324448, lr=2e-06, time_each_step=0.16s, eta=0:10:48\n",
      "2021-12-24 14:19:01 [INFO]\t[TRAIN] Epoch=35/35, Step=4290/7915, loss=0.638685, lr=2e-06, time_each_step=0.17s, eta=0:10:26\n",
      "2021-12-24 14:19:34 [INFO]\t[TRAIN] Epoch=35/35, Step=4490/7915, loss=0.435799, lr=2e-06, time_each_step=0.16s, eta=0:9:47\n",
      "2021-12-24 14:20:07 [INFO]\t[TRAIN] Epoch=35/35, Step=4690/7915, loss=0.073395, lr=2e-06, time_each_step=0.16s, eta=0:9:13\n",
      "2021-12-24 14:20:40 [INFO]\t[TRAIN] Epoch=35/35, Step=4890/7915, loss=0.25076, lr=2e-06, time_each_step=0.17s, eta=0:8:50\n",
      "2021-12-24 14:21:13 [INFO]\t[TRAIN] Epoch=35/35, Step=5090/7915, loss=0.91966, lr=2e-06, time_each_step=0.17s, eta=0:8:14\n",
      "2021-12-24 14:21:46 [INFO]\t[TRAIN] Epoch=35/35, Step=5290/7915, loss=0.276508, lr=2e-06, time_each_step=0.17s, eta=0:7:43\n",
      "2021-12-24 14:22:19 [INFO]\t[TRAIN] Epoch=35/35, Step=5490/7915, loss=0.091474, lr=1e-06, time_each_step=0.17s, eta=0:7:8\n",
      "2021-12-24 14:22:52 [INFO]\t[TRAIN] Epoch=35/35, Step=5690/7915, loss=0.072501, lr=1e-06, time_each_step=0.17s, eta=0:6:39\n",
      "2021-12-24 14:23:26 [INFO]\t[TRAIN] Epoch=35/35, Step=5890/7915, loss=0.177302, lr=1e-06, time_each_step=0.16s, eta=0:6:0\n",
      "2021-12-24 14:23:59 [INFO]\t[TRAIN] Epoch=35/35, Step=6090/7915, loss=0.381792, lr=1e-06, time_each_step=0.17s, eta=0:5:31\n",
      "2021-12-24 14:24:32 [INFO]\t[TRAIN] Epoch=35/35, Step=6290/7915, loss=0.623858, lr=1e-06, time_each_step=0.16s, eta=0:4:50\n",
      "2021-12-24 14:25:05 [INFO]\t[TRAIN] Epoch=35/35, Step=6490/7915, loss=0.198632, lr=1e-06, time_each_step=0.16s, eta=0:4:21\n",
      "2021-12-24 14:25:38 [INFO]\t[TRAIN] Epoch=35/35, Step=6690/7915, loss=0.507111, lr=1e-06, time_each_step=0.17s, eta=0:3:50\n",
      "2021-12-24 14:26:11 [INFO]\t[TRAIN] Epoch=35/35, Step=6890/7915, loss=0.350067, lr=1e-06, time_each_step=0.17s, eta=0:3:16\n",
      "2021-12-24 14:26:44 [INFO]\t[TRAIN] Epoch=35/35, Step=7090/7915, loss=0.409964, lr=1e-06, time_each_step=0.17s, eta=0:2:44\n",
      "2021-12-24 14:27:17 [INFO]\t[TRAIN] Epoch=35/35, Step=7290/7915, loss=0.344935, lr=0.0, time_each_step=0.17s, eta=0:2:10\n",
      "2021-12-24 14:27:50 [INFO]\t[TRAIN] Epoch=35/35, Step=7490/7915, loss=0.131003, lr=0.0, time_each_step=0.17s, eta=0:1:38\n",
      "2021-12-24 14:28:23 [INFO]\t[TRAIN] Epoch=35/35, Step=7690/7915, loss=0.223338, lr=0.0, time_each_step=0.16s, eta=0:1:3\n",
      "2021-12-24 14:28:56 [INFO]\t[TRAIN] Epoch=35/35, Step=7890/7915, loss=0.254427, lr=0.0, time_each_step=0.16s, eta=0:0:31\n",
      "2021-12-24 14:29:00 [INFO]\t[TRAIN] Epoch 35 finished, loss=0.311564, lr=2e-06 .\n",
      "2021-12-24 14:29:00 [INFO]\tStart to evaluating(total_samples=3332, total_steps=417)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [00:23<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:29:24 [INFO]\t[EVAL] Finished, Epoch=35, miou=0.579196, category_iou=[0.59165517 0.75213122 0.56015778 0.41284042], oacc=0.753537, category_acc=[0.71818547 0.85298608 0.7679899  0.59239097], kappa=0.658592, category_F1-score=[0.74344642 0.85853298 0.71807837 0.58441196] .\n",
      "2021-12-24 14:29:27 [INFO]\tModel saved in output/deeplab/epoch_35.\n",
      "2021-12-24 14:29:27 [INFO]\tCurrent evaluated best model in eval_dataset is epoch_32, miou=0.580055810853016\n"
     ]
    }
   ],
   "source": [
    "# 分割类别数\r\n",
    "num_classes = len(train_dataset.labels)\r\n",
    "\r\n",
    "# 构建DeepLabv3p分割器\r\n",
    "model = pdx.seg.DeepLabv3p(\r\n",
    "    num_classes=num_classes,  backbone='Xception65', use_bce_loss=False\r\n",
    ")\r\n",
    "\r\n",
    "# 模型训练\r\n",
    "model.train(\r\n",
    "    num_epochs=35,                 # 训练迭代轮数\r\n",
    "    train_dataset=train_dataset,  # 训练集读取\r\n",
    "    train_batch_size=8,           # 训练时批处理图片数\r\n",
    "    eval_dataset=eval_dataset,    # 验证集读取\r\n",
    "    learning_rate=0.0001,         # 学习率\r\n",
    "    save_interval_epochs=1,       # 保存模型间隔轮次  \r\n",
    "    save_dir='output/deeplab',    # 模型保存路径\r\n",
    "    log_interval_steps=200,       # 日志打印间隔\r\n",
    "    pretrain_weights='output/deeplab/best_model')  #加载预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.2 模型评估\n",
    "* eval_dataset (paddlex.datasets): 评估数据读取器。\n",
    "* batch_size (int): 评估时的batch大小。默认1。\n",
    "* epoch_id (int): 当前评估模型所在的训练轮数。\n",
    "* return_details (bool): 是否返回详细信息。默认False。\n",
    "* 最终提交结果的**checkpoint**使用的是/output/deeplab/路径下的**best_model**\n",
    "* 使用以下语句进行模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-24 14:57:32 [INFO]\tModel[DeepLabv3p] loaded.\n",
      "2021-12-24 14:57:32 [INFO]\tStart to evaluating(total_samples=3332, total_steps=3332)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3332/3332 [00:54<00:00, 60.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('miou', 0.5800556580059298),\n",
       "             ('category_iou',\n",
       "              array([0.59083346, 0.75345698, 0.56095016, 0.41498203])),\n",
       "             ('oacc', 0.7540352049867384),\n",
       "             ('category_acc',\n",
       "              array([0.72597807, 0.85152703, 0.75948676, 0.59103785])),\n",
       "             ('kappa', 0.6595423150372128),\n",
       "             ('category_F1-score',\n",
       "              array([0.74279738, 0.85939603, 0.71872911, 0.58655449]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\r\n",
    "model = pdx.load_model('./output/deeplab/best_model')\r\n",
    "\r\n",
    "# 模型评估\r\n",
    "model.evaluate(eval_dataset, batch_size=1, epoch_id=None, return_details=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3.3 模型预测\n",
    "**DeepLabv3p**模型预测接口。需要注意的是，只有在训练过程中定义了eval_dataset，模型在保存时才会将预测时的图像处理流程保存在DeepLabv3p.test_transforms和DeepLabv3p.eval_transforms中。如未在训练时定义eval_dataset，那在调用预测predict接口时，用户需要再重新定义test_transforms传入给predict接口。\n",
    "\n",
    "* img_file (str|np.ndarray): 预测图像路径或numpy数组(HWC排列，BGR格式)。\n",
    "* transforms (paddlex.seg.transforms): 数据预处理操作。\n",
    "* 将预测结果保存在/home/aistudio/路径下的result文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4608/4608 [01:17<00:00, 59.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\r\n",
    "import cv2\r\n",
    "\r\n",
    "test_base = 'img_testA/'    # 测试集路径\r\n",
    "out_base = 'result/'        # 预测结果保存路径\r\n",
    "\r\n",
    "# 是否存在结果保存路径，如不存在，则创建该路径\r\n",
    "if not os.path.exists(out_base):\r\n",
    "    os.makedirs(out_base)\r\n",
    "\r\n",
    "# 模型预测并保存预测图片\r\n",
    "for im in tqdm(os.listdir(test_base)):\r\n",
    "    if not im.endswith('.jpg'):\r\n",
    "        continue\r\n",
    "    pt = test_base + im\r\n",
    "    result = model.predict(pt)\r\n",
    "    cv2.imwrite(out_base+im.replace('jpg', 'png'), result['label_map'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: result/4123.png (deflated 81%)\r"
     ]
    }
   ],
   "source": [
    "# 由预测结果生成提交文件\r\n",
    "!zip -r result.zip result/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 四、总结与展望\n",
    "* 可以尝试按照其他比率划分数据集\n",
    "* 尝试丰富数据增强操作来改进\n",
    "* 尝试从增加网络深度的角度来改进模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 参考资料\n",
    "[常规赛：遥感影像地块分割baseline](https://aistudio.baidu.com/aistudio/projectdetail/1785557?channelType=0&channel=0)\n",
    "\n",
    "[使用 VisualDL 助力遥感影像地块分割（PaddleX 篇）](https://aistudio.baidu.com/aistudio/projectdetail/1224783?channelType=0&channel=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
